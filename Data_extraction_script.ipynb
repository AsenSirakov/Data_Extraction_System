{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3213ded3-cce5-494e-866c-b416be980eaf",
   "metadata": {},
   "source": [
    "# Dynamo Software (Data Extraction, Formatting, and Reporting assigment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e213b27e-06ed-419f-860d-244e56e07c3b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d2baa25-66e8-4c03-8d9c-d22b63079f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import psycopg2  # For PostgreSQL\n",
    "import pymysql   # For MySQL\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, PatternFill, Alignment\n",
    "import docx2txt  # For .docx files\n",
    "import PyPDF2    # For PDF files\n",
    "import csv\n",
    "import json\n",
    "import logging\n",
    "from dateutil import parser as date_parser  # For flexible date parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd4bdeb4-c011-4aa1-8a6c-84ace1e810f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configuration and Logging Setup\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger('financial_data_extractor')\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"database\": {\n",
    "        \"type\": \"postgresql\",  # Change to \"mysql\" if using MySQL\n",
    "        \"host\": \"localhost\",\n",
    "        \"port\": 5432,  # Change to 3306 for MySQL\n",
    "        \"database\": \"financial_data\",\n",
    "        \"user\": \"postgres\",\n",
    "        \"password\": \"SenkoSQL\"\n",
    "    },\n",
    "    \"extraction\": {\n",
    "        \"mandatory_fields\": [\n",
    "            \"as_of_date\",\n",
    "            \"original_security_name\",\n",
    "            \"investment_in_original\",\n",
    "            \"investment_in\",\n",
    "            \"investment_in_prior\",\n",
    "            \"currency\"\n",
    "        ],\n",
    "        \"additional_fields\": [\n",
    "            \"sector\",\n",
    "            \"risk_rating\",\n",
    "            \"maturity_date\",\n",
    "            \"yield_percentage\",\n",
    "            \"isin\",\n",
    "            \"cusip\",\n",
    "            \"asset_class\",\n",
    "            \"country\",\n",
    "            \"region\"\n",
    "        ],\n",
    "        # Field name variations for pattern matching\n",
    "        \"field_variations\": {\n",
    "            \"as_of_date\": [\n",
    "                r\"as[\\s_-]*of[\\s_-]*date\",\n",
    "                r\"valuation[\\s_-]*date\", \n",
    "                r\"report[\\s_-]*date\",\n",
    "                r\"date[\\s_-]*of[\\s_-]*valuation\",\n",
    "                r\"statement[\\s_-]*date\"\n",
    "            ],\n",
    "            \"original_security_name\": [\n",
    "                r\"original[\\s_-]*security[\\s_-]*name\",\n",
    "                r\"security[\\s_-]*name\", \n",
    "                r\"instrument[\\s_-]*name\",\n",
    "                r\"asset[\\s_-]*name\",\n",
    "                r\"investment[\\s_-]*name\"\n",
    "            ],\n",
    "            \"investment_in_original\": [\n",
    "                r\"investment[\\s_-]*in[\\s_-]*\\(original\\)\", \n",
    "                r\"original[\\s_-]*investment[\\s_-]*value\",\n",
    "                r\"initial[\\s_-]*investment\",\n",
    "                r\"acquisition[\\s_-]*cost\",\n",
    "                r\"purchase[\\s_-]*value\"\n",
    "            ],\n",
    "            \"investment_in\": [\n",
    "                r\"investment[\\s_-]*in(?!\\s*\\()\", \n",
    "                r\"current[\\s_-]*investment[\\s_-]*value\",\n",
    "                r\"market[\\s_-]*value\",\n",
    "                r\"current[\\s_-]*value\",\n",
    "                r\"present[\\s_-]*value\"\n",
    "            ],\n",
    "            \"investment_in_prior\": [\n",
    "                r\"investment[\\s_-]*in[\\s_-]*\\(prior\\)\", \n",
    "                r\"prior[\\s_-]*investment[\\s_-]*value\",\n",
    "                r\"previous[\\s_-]*value\",\n",
    "                r\"value[\\s_-]*previous[\\s_-]*period\",\n",
    "                r\"last[\\s_-]*period[\\s_-]*value\"\n",
    "            ],\n",
    "            \"currency\": [\n",
    "                r\"currency(?!\\s*type)\", \n",
    "                r\"currency[\\s_-]*type\",\n",
    "                r\"currency[\\s_-]*code\",\n",
    "                r\"denomination\",\n",
    "                r\"traded[\\s_-]*in\"\n",
    "            ],\n",
    "            \"sector\": [\n",
    "                r\"sector\",\n",
    "                r\"industry[\\s_-]*sector\",\n",
    "                r\"business[\\s_-]*sector\",\n",
    "                r\"market[\\s_-]*sector\"\n",
    "            ],\n",
    "            \"risk_rating\": [\n",
    "                r\"risk[\\s_-]*rating\",\n",
    "                r\"risk[\\s_-]*level\",\n",
    "                r\"risk[\\s_-]*assessment\",\n",
    "                r\"risk[\\s_-]*profile\"\n",
    "            ],\n",
    "            \"maturity_date\": [\n",
    "                r\"maturity[\\s_-]*date\",\n",
    "                r\"expiry[\\s_-]*date\",\n",
    "                r\"expiration[\\s_-]*date\",\n",
    "                r\"term[\\s_-]*end[\\s_-]*date\"\n",
    "            ],\n",
    "            \"yield_percentage\": [\n",
    "                r\"yield[\\s_-]*percentage\",\n",
    "                r\"yield[\\s_-]*rate\",\n",
    "                r\"yield[\\s_-]*\\%\",\n",
    "                r\"annual[\\s_-]*yield\",\n",
    "                r\"rate[\\s_-]*of[\\s_-]*return\"\n",
    "            ],\n",
    "            \"isin\": [\n",
    "                r\"isin\",\n",
    "                r\"international[\\s_-]*securities[\\s_-]*identification[\\s_-]*number\"\n",
    "            ],\n",
    "            \"cusip\": [\n",
    "                r\"cusip\",\n",
    "                r\"committee[\\s_-]*on[\\s_-]*uniform[\\s_-]*securities[\\s_-]*identification[\\s_-]*procedures\"\n",
    "            ],\n",
    "            \"asset_class\": [\n",
    "                r\"asset[\\s_-]*class\",\n",
    "                r\"asset[\\s_-]*type\",\n",
    "                r\"investment[\\s_-]*type\",\n",
    "                r\"instrument[\\s_-]*class\"\n",
    "            ],\n",
    "            \"country\": [\n",
    "                r\"country\",\n",
    "                r\"country[\\s_-]*of[\\s_-]*risk\",\n",
    "                r\"country[\\s_-]*of[\\s_-]*domicile\",\n",
    "                r\"domicile\"\n",
    "            ],\n",
    "            \"region\": [\n",
    "                r\"region\",\n",
    "                r\"geographic[\\s_-]*region\",\n",
    "                r\"market[\\s_-]*region\"\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"output\": {\n",
    "        \"excel_file\": \"extracted_financial_data.xlsx\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ae6ebaa-6934-480e-ab3d-540ee8be47ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 (revised): DocumentExtractor Class - Improved Field Extraction\n",
    "class DocumentExtractor:\n",
    "    \"\"\"Handle extraction of data from various document types with robust pattern matching\"\"\"\n",
    "    \n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.file_extension = os.path.splitext(file_path)[1].lower()\n",
    "        self.raw_text = \"\"\n",
    "        self.extracted_data = []\n",
    "        self.logger = logging.getLogger('financial_data_extractor.DocumentExtractor')\n",
    "        \n",
    "    def extract_text(self):\n",
    "        \"\"\"Extract raw text from document based on file extension\"\"\"\n",
    "        self.logger.info(f\"Extracting text from {self.file_path} (type: {self.file_extension})\")\n",
    "        \n",
    "        try:\n",
    "            if self.file_extension == \".docx\":\n",
    "                self.raw_text = docx2txt.process(self.file_path)\n",
    "            elif self.file_extension == \".pdf\":\n",
    "                with open(self.file_path, \"rb\") as file:\n",
    "                    pdf_reader = PyPDF2.PdfReader(file)\n",
    "                    for page_num in range(len(pdf_reader.pages)):\n",
    "                        page = pdf_reader.pages[page_num]\n",
    "                        self.raw_text += page.extract_text()\n",
    "            elif self.file_extension == \".txt\":\n",
    "                with open(self.file_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as file:\n",
    "                    self.raw_text = file.read()\n",
    "            elif self.file_extension == \".csv\":\n",
    "                with open(self.file_path, 'r', encoding='utf-8', errors=\"replace\") as file:\n",
    "                    reader = csv.reader(file)\n",
    "                    for row in reader:\n",
    "                        self.raw_text += ' '.join(row) + '\\n'\n",
    "            elif self.file_extension == \".json\":\n",
    "                with open(self.file_path, 'r', encoding='utf-8', errors=\"replace\") as file:\n",
    "                    data = json.load(file)\n",
    "                    # Convert JSON to text representation\n",
    "                    self.raw_text = json.dumps(data, indent=2)\n",
    "            else:\n",
    "                self.logger.error(f\"Unsupported file format: {self.file_extension}\")\n",
    "                raise ValueError(f\"Unsupported file format: {self.file_extension}\")\n",
    "            \n",
    "            self.logger.info(f\"Successfully extracted {len(self.raw_text)} characters of text\")\n",
    "            return self.raw_text\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error extracting text from file: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _build_field_pattern(self, field_name):\n",
    "        \"\"\"Build a comprehensive regex pattern for a field based on all its variations\"\"\"\n",
    "        variations = CONFIG[\"extraction\"][\"field_variations\"].get(field_name, [field_name.lower()])\n",
    "        pattern_parts = []\n",
    "        \n",
    "        for variation in variations:\n",
    "            # Match the field name followed by: colon, equals, dash, or space then colon\n",
    "            pattern_parts.append(f\"(?:{variation})\\\\s*[:=\\\\-]\\\\s*([^\\\\n:]+)\")\n",
    "        \n",
    "        # Join all variations with OR (|)\n",
    "        return '|'.join(pattern_parts)\n",
    "    \n",
    "    def _extract_date_global(self):\n",
    "        \"\"\"Extract a global as_of_date from the document\"\"\"\n",
    "        date_patterns = [\n",
    "            # Common date formats in headers or at document beginning\n",
    "            r\"(?:As of|Valuation|Report|Statement)(?:\\s+[Dd]ate)?:\\s+([0-9]{1,2}[\\\\/\\\\-\\\\.][0-9]{1,2}[\\\\/\\\\-\\\\.][0-9]{2,4})\",\n",
    "            r\"(?:As of|Valuation|Report|Statement)(?:\\s+[Dd]ate)?:\\s+([A-Za-z]+\\s+[0-9]{1,2},?\\s+[0-9]{2,4})\",\n",
    "            r\"[Dd]ate:\\s+([0-9]{1,2}[\\\\/\\\\-\\\\.][0-9]{1,2}[\\\\/\\\\-\\\\.][0-9]{2,4})\",\n",
    "            r\"[Dd]ate:\\s+([A-Za-z]+\\s+[0-9]{1,2},?\\s+[0-9]{2,4})\"\n",
    "        ]\n",
    "        \n",
    "        for pattern in date_patterns:\n",
    "            date_match = re.search(pattern, self.raw_text, re.IGNORECASE)\n",
    "            if date_match:\n",
    "                return date_match.group(1).strip()\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _identify_investment_sections(self):\n",
    "        \"\"\"Identify individual investment sections in the document using multiple patterns\"\"\"\n",
    "        # Try different section delimiter patterns\n",
    "        section_patterns = [\n",
    "            # Numbered investment sections\n",
    "            r\"(?:#{1,4}|Section|SECTION)\\s+(?:INVESTMENT|Investment|Asset|ASSET)\\s+(?:\\d+|\\w+)(?:\\s*:)?\\s*\\n(.*?)(?=(?:#{1,4}|Section|SECTION)\\s+(?:INVESTMENT|Investment|Asset|ASSET)\\s+(?:\\d+|\\w+)|$)\",\n",
    "            \n",
    "            # Sections with clear dividers\n",
    "            r\"(?:[-=*]{3,})\\n\\s*(?:INVESTMENT|Investment|Asset|ASSET)\\s+(?:\\d+|\\w+)\\s*\\n(?:[-=*]{3,})\\n(.*?)(?=(?:[-=*]{3,})\\n\\s*(?:INVESTMENT|Investment|Asset|ASSET)\\s+(?:\\d+|\\w+)|$)\",\n",
    "            \n",
    "            # Sections with empty line dividers\n",
    "            r\"\\n\\s*(?:INVESTMENT|Investment|Asset|ASSET)\\s+(?:\\d+|\\w+)\\s*\\n\\n(.*?)(?=\\n\\n\\s*(?:INVESTMENT|Investment|Asset|ASSET)\\s+(?:\\d+|\\w+)|$)\",\n",
    "            \n",
    "            # Named investment sections\n",
    "            r\"(?:Investment|INVESTMENT|Asset|ASSET)(?:\\s+in|\\s+name)?:\\s+([^\\n]+)\\n(.*?)(?=(?:Investment|INVESTMENT|Asset|ASSET)(?:\\s+in|\\s+name)?:\\s+|$)\"\n",
    "        ]\n",
    "        \n",
    "        for pattern in section_patterns:\n",
    "            sections = re.findall(pattern, self.raw_text, re.DOTALL | re.IGNORECASE)\n",
    "            if sections:\n",
    "                # If we found sections using this pattern, return them\n",
    "                if isinstance(sections[0], tuple):\n",
    "                    # If pattern captured multiple groups, use the last one\n",
    "                    return [s[-1] for s in sections]\n",
    "                return sections\n",
    "        \n",
    "        # If no sections found, return the whole document as one section\n",
    "        return [self.raw_text]\n",
    "    \n",
    "    def _extract_table_data(self):\n",
    "        \"\"\"Try to extract data from tabular formats in the document\"\"\"\n",
    "        # Look for tabular data patterns - simple CSV-like or fixed width formats\n",
    "        table_patterns = [\n",
    "            # Header row followed by data rows\n",
    "            r\"(?:Security\\s+Name|Asset\\s+Name|Investment)[\\s,|]+(?:Original|Initial)[\\s,|]+(?:Current|Market)[\\s,|]+(?:Prior|Previous)[\\s,|]+Currency\\s*\\n((?:.*\\n)+)\"\n",
    "        ]\n",
    "        \n",
    "        table_data = []\n",
    "        \n",
    "        for pattern in table_patterns:\n",
    "            matches = re.search(pattern, self.raw_text, re.IGNORECASE)\n",
    "            if matches:\n",
    "                table_content = matches.group(1)\n",
    "                rows = table_content.strip().split('\\n')\n",
    "                \n",
    "                for row in rows:\n",
    "                    # Split by common delimiters\n",
    "                    columns = re.split(r'\\s{2,}|,|\\||\\t', row.strip())\n",
    "                    if len(columns) >= 5:  # Expecting at least 5 columns for basic data\n",
    "                        data_dict = {}\n",
    "                        \n",
    "                        # Map columns to fields based on position\n",
    "                        # This is a simple heuristic and might need adjustment\n",
    "                        if len(columns) >= 1:\n",
    "                            data_dict[\"original_security_name\"] = columns[0].strip()\n",
    "                        if len(columns) >= 2:\n",
    "                            data_dict[\"investment_in_original\"] = columns[1].strip()\n",
    "                        if len(columns) >= 3:\n",
    "                            data_dict[\"investment_in\"] = columns[2].strip()\n",
    "                        if len(columns) >= 4:\n",
    "                            data_dict[\"investment_in_prior\"] = columns[3].strip()\n",
    "                        if len(columns) >= 5:\n",
    "                            data_dict[\"currency\"] = columns[4].strip()\n",
    "                        \n",
    "                        table_data.append(data_dict)\n",
    "        \n",
    "        return table_data\n",
    "    \n",
    "    def _clean_field_value(self, field, value):\n",
    "        \"\"\"Clean and standardize field values\"\"\"\n",
    "        if not value:\n",
    "            return value\n",
    "            \n",
    "        value = value.strip()\n",
    "        \n",
    "        # Standard field-specific cleaning\n",
    "        if field in [\"investment_in_original\", \"investment_in\", \"investment_in_prior\"]:\n",
    "            # Extract numeric part\n",
    "            matches = re.search(r'[-+]?[0-9,.]+(?:\\.[0-9]+)?', value)\n",
    "            if matches:\n",
    "                return matches.group(0).replace(',', '')\n",
    "                \n",
    "        elif field == \"currency\":\n",
    "            # Extract currency code\n",
    "            matches = re.search(r'\\b(USD|EUR|GBP|JPY|CHF|CAD|AUD|NZD|[A-Z]{3})\\b', value.upper())\n",
    "            if matches:\n",
    "                return matches.group(1)\n",
    "            return value.upper()\n",
    "            \n",
    "        elif field == \"yield_percentage\":\n",
    "            # Extract percentage value\n",
    "            matches = re.search(r'[-+]?[0-9,.]+(?:\\.[0-9]+)?', value)\n",
    "            if matches:\n",
    "                return matches.group(0).replace(',', '')\n",
    "                \n",
    "        return value\n",
    "    \n",
    "    def extract_data(self):\n",
    "        \"\"\"Extract structured data from the text using multiple strategies\"\"\"\n",
    "        # Make sure we have text to process\n",
    "        if not self.raw_text:\n",
    "            self.extract_text()\n",
    "        \n",
    "        self.logger.info(\"Starting data extraction\")\n",
    "        \n",
    "        # Initialize data dictionaries list\n",
    "        data_dicts = []\n",
    "        \n",
    "        # Global date - looks for the as_of_date field in the whole document\n",
    "        as_of_date = self._extract_date_global()\n",
    "        self.logger.info(f\"Global as_of_date extracted: {as_of_date}\")\n",
    "        \n",
    "        # First attempt: Try to extract data from tabular format\n",
    "        table_data = self._extract_table_data()\n",
    "        if table_data:\n",
    "            self.logger.info(f\"Extracted {len(table_data)} records from tabular format\")\n",
    "            \n",
    "            # Add the global date to each record\n",
    "            for record in table_data:\n",
    "                if as_of_date:\n",
    "                    record[\"as_of_date\"] = as_of_date\n",
    "            \n",
    "            data_dicts.extend(table_data)\n",
    "        \n",
    "        # Second attempt: Find investment sections and extract from each\n",
    "        if not data_dicts:\n",
    "            self.logger.info(\"No tabular data found, trying section-based extraction\")\n",
    "            investment_sections = self._identify_investment_sections()\n",
    "            self.logger.info(f\"Identified {len(investment_sections)} investment sections\")\n",
    "            \n",
    "            # Build patterns dictionary for all fields\n",
    "            field_patterns = {}\n",
    "            for field_name in CONFIG[\"extraction\"][\"mandatory_fields\"] + CONFIG[\"extraction\"][\"additional_fields\"]:\n",
    "                field_patterns[field_name] = self._build_field_pattern(field_name)\n",
    "            \n",
    "            # Process each investment section\n",
    "            for section in investment_sections:\n",
    "                data_dict = {}\n",
    "                \n",
    "                # Add the global date to each investment record\n",
    "                if as_of_date:\n",
    "                    data_dict[\"as_of_date\"] = as_of_date\n",
    "                \n",
    "                # Extract each field from the section\n",
    "                for field, pattern in field_patterns.items():\n",
    "                    match = re.search(pattern, section, re.IGNORECASE)\n",
    "                    if match:\n",
    "                        # Use the last group in case there are multiple capture groups\n",
    "                        data_dict[field] = match.group(match.lastindex or 1).strip()\n",
    "                \n",
    "                # Map field variations to standardized field names\n",
    "                # This is for fields that might be extracted with different names\n",
    "                field_mapping = {\n",
    "                    \"security_name\": \"original_security_name\",\n",
    "                    \"instrument_name\": \"original_security_name\",\n",
    "                    \"asset_name\": \"original_security_name\",\n",
    "                    \n",
    "                    \"original_investment_value\": \"investment_in_original\",\n",
    "                    \"initial_investment\": \"investment_in_original\",\n",
    "                    \"acquisition_cost\": \"investment_in_original\",\n",
    "                    \"purchase_value\": \"investment_in_original\",\n",
    "                    \n",
    "                    \"current_investment_value\": \"investment_in\",\n",
    "                    \"market_value\": \"investment_in\",\n",
    "                    \"current_value\": \"investment_in\",\n",
    "                    \"present_value\": \"investment_in\",\n",
    "                    \n",
    "                    \"prior_investment_value\": \"investment_in_prior\",\n",
    "                    \"previous_value\": \"investment_in_prior\",\n",
    "                    \"value_previous_period\": \"investment_in_prior\",\n",
    "                    \"last_period_value\": \"investment_in_prior\",\n",
    "                    \n",
    "                    \"currency_type\": \"currency\",\n",
    "                    \"currency_code\": \"currency\",\n",
    "                    \"denomination\": \"currency\",\n",
    "                    \n",
    "                    \"risk_level\": \"risk_rating\",\n",
    "                    \"risk_assessment\": \"risk_rating\",\n",
    "                    \"risk_profile\": \"risk_rating\",\n",
    "                    \n",
    "                    \"expiry_date\": \"maturity_date\",\n",
    "                    \"expiration_date\": \"maturity_date\",\n",
    "                    \"term_end_date\": \"maturity_date\",\n",
    "                    \n",
    "                    \"yield_rate\": \"yield_percentage\",\n",
    "                    \"yield\": \"yield_percentage\",\n",
    "                    \"annual_yield\": \"yield_percentage\",\n",
    "                    \"rate_of_return\": \"yield_percentage\"\n",
    "                }\n",
    "                \n",
    "                # Standardize field names\n",
    "                for old_field, new_field in field_mapping.items():\n",
    "                    if old_field in data_dict and old_field != new_field:\n",
    "                        if new_field not in data_dict or not data_dict[new_field]:\n",
    "                            data_dict[new_field] = data_dict[old_field]\n",
    "                        del data_dict[old_field]\n",
    "                \n",
    "                # Clean and standardize field values\n",
    "                for field, value in list(data_dict.items()):\n",
    "                    if value:\n",
    "                        data_dict[field] = self._clean_field_value(field, value)\n",
    "                \n",
    "                # Only add if we found at least one field\n",
    "                if len(data_dict) > 1 or (len(data_dict) == 1 and \"as_of_date\" not in data_dict):\n",
    "                    data_dicts.append(data_dict)\n",
    "        \n",
    "        # Third attempt: If no investment sections were found, try a more general approach\n",
    "        if not data_dicts:\n",
    "            self.logger.info(\"No investment sections found, trying general extraction\")\n",
    "            \n",
    "            # Create a record for the as_of_date if found\n",
    "            if as_of_date:\n",
    "                data_dicts.append({\"as_of_date\": as_of_date})\n",
    "            \n",
    "            # Build patterns dictionary\n",
    "            field_patterns = {}\n",
    "            for field_name in CONFIG[\"extraction\"][\"mandatory_fields\"] + CONFIG[\"extraction\"][\"additional_fields\"]:\n",
    "                field_patterns[field_name] = self._build_field_pattern(field_name)\n",
    "            \n",
    "            # Try to find individual fields across the whole document\n",
    "            for field, pattern in field_patterns.items():\n",
    "                matches = re.findall(pattern, self.raw_text, re.IGNORECASE)\n",
    "                for i, match in enumerate(matches):\n",
    "                    # Create new dictionaries as needed\n",
    "                    while i >= len(data_dicts):\n",
    "                        data_dicts.append({})\n",
    "                    \n",
    "                    # Handle tuple results from multiple capture groups\n",
    "                    if isinstance(match, tuple):\n",
    "                        # Find the first non-empty group\n",
    "                        for group in match:\n",
    "                            if group.strip():\n",
    "                                data_dict[field] = self._clean_field_value(field, group)\n",
    "                                break\n",
    "                    else:\n",
    "                        data_dicts[i][field] = self._clean_field_value(field, match)\n",
    "        \n",
    "        # Special handling for CSV or JSON files\n",
    "        if self.file_extension == \".csv\":\n",
    "            try:\n",
    "                with open(self.file_path, 'r', encoding='utf-8', errors=\"replace\") as file:\n",
    "                    reader = csv.DictReader(file)\n",
    "                    rows = list(reader)\n",
    "                \n",
    "                if rows:\n",
    "                    self.logger.info(f\"Extracted {len(rows)} records from CSV file\")\n",
    "                    \n",
    "                    # Map CSV headers to our field names\n",
    "                    field_mapping = {\n",
    "                        \"Security Name\": \"original_security_name\",\n",
    "                        \"Asset Name\": \"original_security_name\",\n",
    "                        \"Instrument Name\": \"original_security_name\",\n",
    "                        \"Security\": \"original_security_name\",\n",
    "                        \n",
    "                        \"Initial Investment\": \"investment_in_original\",\n",
    "                        \"Original Investment\": \"investment_in_original\",\n",
    "                        \"Acquisition Cost\": \"investment_in_original\",\n",
    "                        \"Purchase Value\": \"investment_in_original\",\n",
    "                        \n",
    "                        \"Market Value\": \"investment_in\",\n",
    "                        \"Current Value\": \"investment_in\",\n",
    "                        \"Present Value\": \"investment_in\",\n",
    "                        \"Current Investment\": \"investment_in\",\n",
    "                        \n",
    "                        \"Prior Value\": \"investment_in_prior\",\n",
    "                        \"Previous Value\": \"investment_in_prior\",\n",
    "                        \"Last Period Value\": \"investment_in_prior\",\n",
    "                        \"Prior Investment\": \"investment_in_prior\",\n",
    "                        \n",
    "                        \"Currency Type\": \"currency\",\n",
    "                        \"Currency Code\": \"currency\",\n",
    "                        \"Denomination\": \"currency\",\n",
    "                        \n",
    "                        \"Risk Level\": \"risk_rating\",\n",
    "                        \"Risk Assessment\": \"risk_rating\",\n",
    "                        \"Risk Profile\": \"risk_rating\",\n",
    "                        \n",
    "                        \"Expiry Date\": \"maturity_date\",\n",
    "                        \"Expiration Date\": \"maturity_date\",\n",
    "                        \"Term End Date\": \"maturity_date\",\n",
    "                        \n",
    "                        \"Yield Rate\": \"yield_percentage\",\n",
    "                        \"Yield\": \"yield_percentage\",\n",
    "                        \"Annual Yield\": \"yield_percentage\",\n",
    "                        \"Rate of Return\": \"yield_percentage\",\n",
    "                        \"Yield %\": \"yield_percentage\"\n",
    "                    }\n",
    "                    \n",
    "                    csv_data = []\n",
    "                    for row in rows:\n",
    "                        data_dict = {}\n",
    "                        \n",
    "                        # Add the global date if found\n",
    "                        if as_of_date:\n",
    "                            data_dict[\"as_of_date\"] = as_of_date\n",
    "                        \n",
    "                        # Map fields\n",
    "                        for csv_field, value in row.items():\n",
    "                            # Try to map the field to our standard field names\n",
    "                            target_field = field_mapping.get(csv_field, csv_field.lower().replace(' ', '_'))\n",
    "                            \n",
    "                            # Clean and standardize the value\n",
    "                            if value:\n",
    "                                data_dict[target_field] = self._clean_field_value(target_field, value)\n",
    "                        \n",
    "                        if len(data_dict) > 1 or (len(data_dict) == 1 and \"as_of_date\" not in data_dict):\n",
    "                            csv_data.append(data_dict)\n",
    "                    \n",
    "                    # If we found data in the CSV, use that instead\n",
    "                    if csv_data:\n",
    "                        data_dicts = csv_data\n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"Error processing CSV file: {str(e)}\")\n",
    "        \n",
    "        elif self.file_extension == \".json\":\n",
    "            try:\n",
    "                with open(self.file_path, 'r', encoding='utf-8', errors=\"replace\") as file:\n",
    "                    json_data = json.load(file)\n",
    "                \n",
    "                # Try to extract structured data from JSON\n",
    "                json_records = []\n",
    "                \n",
    "                # Look for common JSON structures\n",
    "                if isinstance(json_data, dict):\n",
    "                    # Case 1: {\"report_date\": \"...\", \"investments\": [{...}, {...}]}\n",
    "                    if \"investments\" in json_data and isinstance(json_data[\"investments\"], list):\n",
    "                        report_date = json_data.get(\"report_date\") or json_data.get(\"as_of_date\") or as_of_date\n",
    "                        \n",
    "                        for investment in json_data[\"investments\"]:\n",
    "                            data_dict = {\"as_of_date\": report_date} if report_date else {}\n",
    "                            \n",
    "                            # Map JSON fields to our standard fields\n",
    "                            field_mapping = {\n",
    "                                \"security_name\": \"original_security_name\",\n",
    "                                \"instrument_name\": \"original_security_name\",\n",
    "                                \"asset_name\": \"original_security_name\",\n",
    "                                \n",
    "                                \"investment_original\": \"investment_in_original\",\n",
    "                                \"original_investment\": \"investment_in_original\",\n",
    "                                \"investment_original\": \"investment_in_original\",\n",
    "                                \"original_investment\": \"investment_in_original\",\n",
    "                                \"initial_investment\": \"investment_in_original\",\n",
    "                                \"acquisition_cost\": \"investment_in_original\",\n",
    "                                \n",
    "                                \"investment_current\": \"investment_in\",\n",
    "                                \"current_investment\": \"investment_in\",\n",
    "                                \"market_value\": \"investment_in\",\n",
    "                                \"current_value\": \"investment_in\",\n",
    "                                \n",
    "                                \"investment_prior\": \"investment_in_prior\",\n",
    "                                \"prior_investment\": \"investment_in_prior\",\n",
    "                                \"previous_value\": \"investment_in_prior\",\n",
    "                                \"last_period_value\": \"investment_in_prior\"\n",
    "                            }\n",
    "                            \n",
    "                            for json_field, value in investment.items():\n",
    "                                # Map to standard field name if needed\n",
    "                                field_name = field_mapping.get(json_field, json_field)\n",
    "                                \n",
    "                                # Clean and standardize the value\n",
    "                                if value is not None:\n",
    "                                    data_dict[field_name] = self._clean_field_value(field_name, str(value))\n",
    "                            \n",
    "                            if data_dict:\n",
    "                                json_records.append(data_dict)\n",
    "                    \n",
    "                    # Case 2: {\"investments\": {\"investment1\": {...}, \"investment2\": {...}}}\n",
    "                    elif \"investments\" in json_data and isinstance(json_data[\"investments\"], dict):\n",
    "                        report_date = json_data.get(\"report_date\") or json_data.get(\"as_of_date\") or as_of_date\n",
    "                        \n",
    "                        for investment_name, investment_data in json_data[\"investments\"].items():\n",
    "                            data_dict = {\"as_of_date\": report_date} if report_date else {}\n",
    "                            data_dict[\"original_security_name\"] = investment_name\n",
    "                            \n",
    "                            for json_field, value in investment_data.items():\n",
    "                                if value is not None:\n",
    "                                    data_dict[json_field] = self._clean_field_value(json_field, str(value))\n",
    "                            \n",
    "                            if data_dict:\n",
    "                                json_records.append(data_dict)\n",
    "                \n",
    "                # Case 3: Direct list of investments\n",
    "                elif isinstance(json_data, list):\n",
    "                    for investment in json_data:\n",
    "                        if isinstance(investment, dict):\n",
    "                            data_dict = {}\n",
    "                            \n",
    "                            # Add the global date if found\n",
    "                            if as_of_date:\n",
    "                                data_dict[\"as_of_date\"] = as_of_date\n",
    "                            \n",
    "                            for json_field, value in investment.items():\n",
    "                                if value is not None:\n",
    "                                    data_dict[json_field] = self._clean_field_value(json_field, str(value))\n",
    "                            \n",
    "                            if data_dict:\n",
    "                                json_records.append(data_dict)\n",
    "                \n",
    "                # If we found records in the JSON, use them\n",
    "                if json_records:\n",
    "                    self.logger.info(f\"Extracted {len(json_records)} records from JSON file\")\n",
    "                    data_dicts = json_records\n",
    "            \n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"Error processing JSON file: {str(e)}\")\n",
    "        \n",
    "        # Final validation and cleanup\n",
    "        validated_data = []\n",
    "        for record in data_dicts:\n",
    "            # Only include records with at least some mandatory fields\n",
    "            mandatory_fields_count = sum(1 for field in CONFIG[\"extraction\"][\"mandatory_fields\"] if field in record and record[field])\n",
    "            \n",
    "            # Keep if we have as_of_date and at least one other mandatory field, or at least 2 mandatory fields\n",
    "            if (mandatory_fields_count >= 2) or (\"as_of_date\" in record and mandatory_fields_count >= 1):\n",
    "                validated_data.append(record)\n",
    "        \n",
    "        self.extracted_data = validated_data\n",
    "        self.logger.info(f\"Extracted {len(validated_data)} valid records with data\")\n",
    "        return validated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8d0e5df-f077-4138-9449-fa6ac9de6f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 (revised): DataProcessor Class - Improved Data Formatting\n",
    "class DataProcessor:\n",
    "    \"\"\"Process and format the extracted data with robust type handling and conversions\"\"\"\n",
    "    \n",
    "    def __init__(self, data_list):\n",
    "        self.raw_data = data_list\n",
    "        self.processed_data = []\n",
    "        self.extraction_stats = {}\n",
    "        self.logger = logging.getLogger('financial_data_extractor.DataProcessor')\n",
    "        \n",
    "    def _format_date(self, date_str):\n",
    "        \"\"\"Format a date string to MM/DD/YYYY, handling various input formats\"\"\"\n",
    "        if not date_str or str(date_str).lower() in [\"n/a\", \"na\", \"none\", \"null\"]:\n",
    "            return date_str\n",
    "            \n",
    "        try:\n",
    "            # Try parsing with dateutil for flexibility\n",
    "            date_obj = date_parser.parse(date_str, dayfirst=False, yearfirst=False, fuzzy=True)\n",
    "            return date_obj.strftime('%m/%d/%Y')\n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"Could not parse date '{date_str}': {str(e)}\")\n",
    "            return date_str\n",
    "    \n",
    "    def _format_currency(self, value_str):\n",
    "        \"\"\"Format a currency value to have 2 decimal places\"\"\"\n",
    "        if not value_str or str(value_str).lower() in [\"n/a\", \"na\", \"none\", \"null\"]:\n",
    "            return value_str\n",
    "            \n",
    "        try:\n",
    "            # Remove any non-numeric characters except decimal point and negative sign\n",
    "            clean_value = re.sub(r'[^\\d.-]', '', str(value_str))\n",
    "            # Format as currency with 2 decimal places\n",
    "            return \"{:.2f}\".format(float(clean_value))\n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"Could not process currency value '{value_str}': {str(e)}\")\n",
    "            return value_str\n",
    "    \n",
    "    def _format_percentage(self, value_str):\n",
    "        \"\"\"Format a percentage value to have 2 decimal places\"\"\"\n",
    "        if not value_str or str(value_str).lower() in [\"n/a\", \"na\", \"none\", \"null\"]:\n",
    "            return value_str\n",
    "            \n",
    "        try:\n",
    "            # Remove any non-numeric characters except decimal point and negative sign\n",
    "            clean_value = re.sub(r'[^\\d.-]', '', str(value_str))\n",
    "            # Format as percentage with 2 decimal places\n",
    "            return \"{:.2f}\".format(float(clean_value))\n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"Could not process percentage value '{value_str}': {str(e)}\")\n",
    "            return value_str\n",
    "    \n",
    "    def format_data(self):\n",
    "        \"\"\"Format all data according to US standards\"\"\"\n",
    "        self.logger.info(\"Formatting extracted data\")\n",
    "        \n",
    "        for item in self.raw_data:\n",
    "            processed_item = {}\n",
    "            \n",
    "            # Process date fields (MM/DD/YYYY)\n",
    "            for field in [f for f in item.keys() if 'date' in f.lower()]:\n",
    "                if field in item and item[field]:\n",
    "                    processed_item[field] = self._format_date(item[field])\n",
    "            \n",
    "            # Process currency fields (USD format with 2 decimal places)\n",
    "            for field in ['investment_in_original', 'investment_in', 'investment_in_prior']:\n",
    "                if field in item and item[field]:\n",
    "                    processed_item[field] = self._format_currency(item[field])\n",
    "            \n",
    "            # Process yield percentage\n",
    "            if 'yield_percentage' in item and item['yield_percentage']:\n",
    "                processed_item['yield_percentage'] = self._format_percentage(item['yield_percentage'])\n",
    "            \n",
    "            # Copy other fields as is\n",
    "            for field in item.keys():\n",
    "                if field not in processed_item and item[field]:\n",
    "                    processed_item[field] = item[field]\n",
    "            \n",
    "            self.processed_data.append(processed_item)\n",
    "        \n",
    "        self.logger.info(f\"Formatted {len(self.processed_data)} records\")\n",
    "        return self.processed_data\n",
    "    \n",
    "    def calculate_statistics(self):\n",
    "        \"\"\"Calculate extraction statistics\"\"\"\n",
    "        self.logger.info(\"Calculating extraction statistics\")\n",
    "        \n",
    "        total_records = len(self.processed_data)\n",
    "        if total_records == 0:\n",
    "            self.extraction_stats = {\n",
    "                \"total_records\": 0,\n",
    "                \"mandatory_fields_extracted\": 0,\n",
    "                \"mandatory_fields_percentage\": 0,\n",
    "                \"extraction_accuracy\": 0,\n",
    "                \"missing_fields\": CONFIG[\"extraction\"][\"mandatory_fields\"],\n",
    "                \"inconsistent_data\": [],\n",
    "                \"field_presence\": {}\n",
    "            }\n",
    "            return self.extraction_stats\n",
    "        \n",
    "        # Count mandatory fields\n",
    "        mandatory_fields = CONFIG[\"extraction\"][\"mandatory_fields\"]\n",
    "        mandatory_field_counts = {field: 0 for field in mandatory_fields}\n",
    "        \n",
    "        # Track presence of all fields\n",
    "        all_fields = set()\n",
    "        field_presence = {}\n",
    "        \n",
    "        for record in self.processed_data:\n",
    "            record_fields = set(record.keys())\n",
    "            all_fields.update(record_fields)\n",
    "            \n",
    "            for field in mandatory_fields:\n",
    "                if field in record and record[field]:\n",
    "                    mandatory_field_counts[field] += 1\n",
    "        \n",
    "        # Calculate field presence percentages\n",
    "        for field in all_fields:\n",
    "            count = sum(1 for record in self.processed_data if field in record and record[field])\n",
    "            field_presence[field] = {\n",
    "                \"count\": count,\n",
    "                \"percentage\": (count / total_records) * 100\n",
    "            }\n",
    "        \n",
    "        # Calculate percentages\n",
    "        total_mandatory_fields = len(mandatory_fields) * total_records\n",
    "        extracted_mandatory_fields = sum(mandatory_field_counts.values())\n",
    "        \n",
    "        mandatory_fields_percentage = (extracted_mandatory_fields / total_mandatory_fields) * 100 if total_mandatory_fields > 0 else 0\n",
    "        \n",
    "        # Identify missing and inconsistent data\n",
    "        missing_fields = []\n",
    "        for field, count in mandatory_field_counts.items():\n",
    "            if count < total_records:\n",
    "                missing_fields.append(f\"{field} ({total_records - count} missing)\")\n",
    "        \n",
    "        # Check for inconsistent data\n",
    "        inconsistent_data = []\n",
    "        \n",
    "        # Example check: Verify if currencies are consistent\n",
    "        currencies = set()\n",
    "        for record in self.processed_data:\n",
    "            if 'currency' in record and record['currency']:\n",
    "                currencies.add(record['currency'])\n",
    "        \n",
    "        if len(currencies) > 1:\n",
    "            inconsistent_data.append(f\"Multiple currencies detected: {', '.join(currencies)}\")\n",
    "        \n",
    "        # Check date formats for consistency\n",
    "        date_formats = set()\n",
    "        for record in self.processed_data:\n",
    "            if 'as_of_date' in record and record['as_of_date']:\n",
    "                date_formats.add(self._identify_date_format(record['as_of_date']))\n",
    "        \n",
    "        if len(date_formats) > 1:\n",
    "            inconsistent_data.append(f\"Multiple date formats detected: {', '.join(date_formats)}\")\n",
    "        \n",
    "        # Calculate overall extraction accuracy (weighted by importance)\n",
    "        # Give more weight to mandatory fields\n",
    "        mandatory_weight = 0.7\n",
    "        additional_weight = 0.3\n",
    "        \n",
    "        mandatory_accuracy = mandatory_fields_percentage\n",
    "        \n",
    "        # Additional fields accuracy (if any are found)\n",
    "        additional_fields = [f for f in all_fields if f not in mandatory_fields]\n",
    "        if additional_fields:\n",
    "            additional_fields_count = sum(field_presence[f][\"count\"] for f in additional_fields)\n",
    "            additional_fields_total = len(additional_fields) * total_records\n",
    "            additional_fields_percentage = (additional_fields_count / additional_fields_total) * 100 if additional_fields_total > 0 else 0\n",
    "            extraction_accuracy = (mandatory_accuracy * mandatory_weight) + (additional_fields_percentage * additional_weight)\n",
    "        else:\n",
    "            extraction_accuracy = mandatory_accuracy\n",
    "        \n",
    "        self.extraction_stats = {\n",
    "            \"total_records\": total_records,\n",
    "            \"mandatory_fields_extracted\": extracted_mandatory_fields,\n",
    "            \"mandatory_fields_percentage\": mandatory_fields_percentage,\n",
    "            \"extraction_accuracy\": extraction_accuracy,\n",
    "            \"missing_fields\": missing_fields,\n",
    "            \"inconsistent_data\": inconsistent_data,\n",
    "            \"field_presence\": field_presence\n",
    "        }\n",
    "        \n",
    "        self.logger.info(f\"Statistics calculated: {mandatory_fields_percentage:.2f}% mandatory fields extracted\")\n",
    "        return self.extraction_stats\n",
    "    \n",
    "    def _identify_date_format(self, date_str):\n",
    "        \"\"\"Identify the format of a date string\"\"\"\n",
    "        if not date_str or str(date_str).lower() in [\"n/a\", \"na\", \"none\", \"null\"]:\n",
    "            return \"N/A\"\n",
    "            \n",
    "        # Check for MM/DD/YYYY\n",
    "        if re.match(r'\\d{1,2}/\\d{1,2}/\\d{4}', date_str):\n",
    "            return \"MM/DD/YYYY\"\n",
    "        \n",
    "        # Check for DD/MM/YYYY\n",
    "        elif re.match(r'\\d{1,2}/\\d{1,2}/\\d{4}', date_str):\n",
    "            return \"DD/MM/YYYY\"\n",
    "        \n",
    "        # Check for YYYY-MM-DD\n",
    "        elif re.match(r'\\d{4}-\\d{1,2}-\\d{1,2}', date_str):\n",
    "            return \"YYYY-MM-DD\"\n",
    "        \n",
    "        # Check for Month DD, YYYY\n",
    "        elif re.match(r'[A-Za-z]+ \\d{1,2},?\\s+\\d{4}', date_str):\n",
    "            return \"Month DD, YYYY\"\n",
    "        \n",
    "        return \"Unknown format\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "560cb636-9cdf-42de-9954-e3577509987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 (revised): DataStorage Class - Database Connection Fix\n",
    "class DataStorage:\n",
    "    \"\"\"Store processed data in database and Excel file with error handling\"\"\"\n",
    "    \n",
    "    def __init__(self, processed_data, stats):\n",
    "        self.data = processed_data\n",
    "        self.stats = stats\n",
    "        self.db_config = CONFIG[\"database\"]\n",
    "        self.excel_file = CONFIG[\"output\"][\"excel_file\"]\n",
    "        self.logger = logging.getLogger('financial_data_extractor.DataStorage')\n",
    "        \n",
    "    def create_dataframe(self):\n",
    "        \"\"\"Convert processed data to pandas DataFrame\"\"\"\n",
    "        # Normalize the data to handle missing fields\n",
    "        all_fields = set()\n",
    "        for record in self.data:\n",
    "            all_fields.update(record.keys())\n",
    "        \n",
    "        normalized_data = []\n",
    "        for record in self.data:\n",
    "            normalized_record = {field: record.get(field, None) for field in all_fields}\n",
    "            normalized_data.append(normalized_record)\n",
    "        \n",
    "        return pd.DataFrame(normalized_data)\n",
    "    \n",
    "    def store_in_database(self):\n",
    "        \"\"\"Store data in SQL database with error handling\"\"\"\n",
    "        self.logger.info(f\"Storing data in {self.db_config['type']} database\")\n",
    "        \n",
    "        try:\n",
    "            # Create database connection\n",
    "            if self.db_config[\"type\"] == \"postgresql\":\n",
    "                connection_string = f\"postgresql://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}\"\n",
    "            else:  # MySQL\n",
    "                connection_string = f\"mysql+pymysql://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}\"\n",
    "            \n",
    "            engine = create_engine(connection_string)\n",
    "            \n",
    "            # Drop existing objects to avoid conflicts\n",
    "            from sqlalchemy import text\n",
    "            with engine.connect() as connection:\n",
    "                # Drop the view first, then the table\n",
    "                connection.execute(text(\"DROP VIEW IF EXISTS financial_data_stats CASCADE;\"))\n",
    "                connection.execute(text(\"DROP TABLE IF EXISTS financial_data CASCADE;\"))\n",
    "                connection.commit()\n",
    "            \n",
    "            # Convert data to DataFrame\n",
    "            df = self.create_dataframe()\n",
    "            \n",
    "            # Store in database\n",
    "            df.to_sql('financial_data', engine, if_exists='replace', index=False)\n",
    "            \n",
    "            # Create view for statistics - dynamically based on actual columns\n",
    "            self._create_stats_view(engine, df.columns)\n",
    "            \n",
    "            self.logger.info(f\"Successfully stored {len(df)} records in database\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Database storage error: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def _create_stats_view(self, engine, columns):\n",
    "        \"\"\"Create a database view with extraction statistics based on actual columns\"\"\"\n",
    "        try:\n",
    "            # Get the actual column names from the dataframe\n",
    "            column_cases = []\n",
    "            \n",
    "            # Add count for each mandatory field if present in columns\n",
    "            for field in CONFIG[\"extraction\"][\"mandatory_fields\"]:\n",
    "                if field in columns:\n",
    "                    column_cases.append(f\"SUM(CASE WHEN {field} IS NOT NULL THEN 1 ELSE 0 END) AS {field}_count\")\n",
    "            \n",
    "            # Add other useful stats\n",
    "            if \"currency\" in columns:\n",
    "                column_cases.append(\"COUNT(DISTINCT currency) AS currency_count_distinct\")\n",
    "            \n",
    "            # Build the SQL\n",
    "            view_sql = f\"\"\"\n",
    "            CREATE OR REPLACE VIEW financial_data_stats AS\n",
    "            SELECT\n",
    "                COUNT(*) AS total_records,\n",
    "                {', '.join(column_cases)}\n",
    "            FROM financial_data;\n",
    "            \"\"\"\n",
    "            \n",
    "            from sqlalchemy import text\n",
    "            with engine.connect() as connection:\n",
    "                connection.execute(text(view_sql))\n",
    "                connection.commit()\n",
    "            \n",
    "            self.logger.info(\"Successfully created financial_data_stats view\")\n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"Error creating statistics view: {str(e)}\")\n",
    "    \n",
    "    def store_in_excel(self):\n",
    "        \"\"\"Store data in Excel file with two sheets and formatting\"\"\"\n",
    "        self.logger.info(f\"Storing data in Excel file: {self.excel_file}\")\n",
    "        \n",
    "        try:\n",
    "            # Convert data to DataFrame - handle empty data gracefully\n",
    "            df = self.create_dataframe()\n",
    "            \n",
    "            # Verify we have data to store\n",
    "            if len(df) == 0:\n",
    "                self.logger.warning(\"No data to store in Excel file\")\n",
    "                # Create a dummy dataframe with mandatory columns to avoid Excel creation errors\n",
    "                dummy_columns = CONFIG[\"extraction\"][\"mandatory_fields\"] + CONFIG[\"extraction\"][\"additional_fields\"]\n",
    "                df = pd.DataFrame(columns=dummy_columns)\n",
    "            \n",
    "            # Create a Pandas Excel writer\n",
    "            writer = pd.ExcelWriter(self.excel_file, engine='openpyxl')\n",
    "            \n",
    "            # Write data to \"Extracted Data\" sheet\n",
    "            df.to_excel(writer, sheet_name='Extracted Data', index=False)\n",
    "            \n",
    "            # Create statistics DataFrame\n",
    "            stats_data = {\n",
    "                \"Metric\": [\n",
    "                    \"Total Records Processed\",\n",
    "                    \"Mandatory Fields Extracted\",\n",
    "                    \"Mandatory Fields Percentage\",\n",
    "                    \"Extraction Accuracy\",\n",
    "                    \"Missing Fields\",\n",
    "                    \"Inconsistent Data\"\n",
    "                ],\n",
    "                \"Value\": [\n",
    "                    self.stats[\"total_records\"],\n",
    "                    self.stats[\"mandatory_fields_extracted\"],\n",
    "                    f\"{self.stats['mandatory_fields_percentage']:.2f}%\",\n",
    "                    f\"{self.stats['extraction_accuracy']:.2f}%\",\n",
    "                    \", \".join(self.stats[\"missing_fields\"]) if self.stats[\"missing_fields\"] else \"None\",\n",
    "                    \", \".join(self.stats[\"inconsistent_data\"]) if self.stats[\"inconsistent_data\"] else \"None\"\n",
    "                ]\n",
    "            }\n",
    "            \n",
    "            # Add field presence statistics\n",
    "            if \"field_presence\" in self.stats and self.stats[\"field_presence\"]:\n",
    "                for field, presence in self.stats[\"field_presence\"].items():\n",
    "                    stats_data[\"Metric\"].append(f\"Field presence: {field}\")\n",
    "                    stats_data[\"Value\"].append(f\"{presence['count']} records ({presence['percentage']:.2f}%)\")\n",
    "            \n",
    "            stats_df = pd.DataFrame(stats_data)\n",
    "            \n",
    "            # Write statistics to \"Statistics\" sheet\n",
    "            stats_df.to_excel(writer, sheet_name='Statistics', index=False)\n",
    "            \n",
    "            # Apply formatting to the Excel file\n",
    "            self._format_excel_file(writer)\n",
    "            \n",
    "            # Save the Excel file\n",
    "            writer.close()\n",
    "            \n",
    "            self.logger.info(f\"Successfully stored data in Excel file\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Excel storage error: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def _format_excel_file(self, writer):\n",
    "        \"\"\"Apply formatting to the Excel file for better readability\"\"\"\n",
    "        try:\n",
    "            workbook = writer.book\n",
    "            \n",
    "            # Format Data sheet\n",
    "            worksheet = workbook['Extracted Data']\n",
    "            \n",
    "            # Format headers\n",
    "            for col in range(1, worksheet.max_column + 1):\n",
    "                cell = worksheet.cell(row=1, column=col)\n",
    "                cell.font = Font(bold=True)\n",
    "                cell.fill = PatternFill(start_color=\"DDDDDD\", end_color=\"DDDDDD\", fill_type=\"solid\")\n",
    "                cell.alignment = Alignment(horizontal='center')\n",
    "            \n",
    "            # Adjust column widths\n",
    "            for col in range(1, worksheet.max_column + 1):\n",
    "                max_length = 0\n",
    "                column = worksheet.column_dimensions[chr(64 + col)]  # A, B, C, etc.\n",
    "                \n",
    "                # Find the maximum length in the column\n",
    "                for row in range(1, worksheet.max_row + 1):\n",
    "                    cell_value = str(worksheet.cell(row=row, column=col).value or \"\")\n",
    "                    if len(cell_value) > max_length:\n",
    "                        max_length = len(cell_value)\n",
    "                \n",
    "                # Set width with some padding\n",
    "                column.width = max(10, min(50, max_length + 2))\n",
    "            \n",
    "            # Format Statistics sheet\n",
    "            worksheet = workbook['Statistics']\n",
    "            \n",
    "            # Format headers\n",
    "            for col in range(1, worksheet.max_column + 1):\n",
    "                cell = worksheet.cell(row=1, column=col)\n",
    "                cell.font = Font(bold=True)\n",
    "                cell.fill = PatternFill(start_color=\"DDDDDD\", end_color=\"DDDDDD\", fill_type=\"solid\")\n",
    "                cell.alignment = Alignment(horizontal='center')\n",
    "            \n",
    "            # Highlight metrics based on values\n",
    "            for row in range(2, worksheet.max_row + 1):\n",
    "                metric_cell = worksheet.cell(row=row, column=1)\n",
    "                value_cell = worksheet.cell(row=row, column=2)\n",
    "                \n",
    "                # Highlight percentage metrics\n",
    "                if metric_cell.value and \"Percentage\" in str(metric_cell.value) or \"Accuracy\" in str(metric_cell.value):\n",
    "                    value_text = str(value_cell.value or \"\")\n",
    "                    if value_text and \"%\" in value_text:\n",
    "                        try:\n",
    "                            percentage = float(value_text.replace(\"%\", \"\"))\n",
    "                            if percentage < 50:\n",
    "                                value_cell.fill = PatternFill(start_color=\"FFCCCC\", end_color=\"FFCCCC\", fill_type=\"solid\")\n",
    "                            elif percentage < 80:\n",
    "                                value_cell.fill = PatternFill(start_color=\"FFFFCC\", end_color=\"FFFFCC\", fill_type=\"solid\")\n",
    "                            else:\n",
    "                                value_cell.fill = PatternFill(start_color=\"CCFFCC\", end_color=\"CCFFCC\", fill_type=\"solid\")\n",
    "                        except ValueError:\n",
    "                            pass\n",
    "                \n",
    "                # Highlight missing fields or inconsistent data\n",
    "                if metric_cell.value and (\"Missing Fields\" in str(metric_cell.value) or \"Inconsistent Data\" in str(metric_cell.value)):\n",
    "                    if value_cell.value and str(value_cell.value) != \"None\":\n",
    "                        value_cell.fill = PatternFill(start_color=\"FFCCCC\", end_color=\"FFCCCC\", fill_type=\"solid\")\n",
    "            \n",
    "            # Adjust column widths\n",
    "            for col in range(1, worksheet.max_column + 1):\n",
    "                max_length = 0\n",
    "                column = worksheet.column_dimensions[chr(64 + col)]  # A, B, C, etc.\n",
    "                \n",
    "                # Find the maximum length in the column\n",
    "                for row in range(1, worksheet.max_row + 1):\n",
    "                    cell_value = str(worksheet.cell(row=row, column=col).value or \"\")\n",
    "                    if len(cell_value) > max_length:\n",
    "                        max_length = len(cell_value)\n",
    "                \n",
    "                # Set width with some padding\n",
    "                column.width = max(15, min(75, max_length + 2))\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"Error applying Excel formatting: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aac1087e-b2f0-42a2-adc3-211d60b0144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 (revised): Create Sample Document with More Variations\n",
    "def create_sample_document(document_type=\".txt\"):\n",
    "    \"\"\"\n",
    "    Create a sample financial document for testing with various formats and field variations.\n",
    "    Returns the path to the created document.\n",
    "    \"\"\"\n",
    "    if document_type == \".txt\":\n",
    "        sample_text = \"\"\"# QUARTERLY INVESTMENT REPORT\n",
    "## Confidential Financial Document\n",
    "\n",
    "Report date: 03/31/2024\n",
    "\n",
    "### DETAILED INVESTMENTS\n",
    "\n",
    "#### INVESTMENT 1\n",
    "Security name: Global Technology Fund Class A\n",
    "Original investment value: 400,000.00\n",
    "Current value: 475,250.00\n",
    "Previous value: 425,800.00\n",
    "Currency code: USD\n",
    "Sector: Technology\n",
    "Risk level: Moderate\n",
    "Maturity date: N/A\n",
    "Yield rate: 2.45%\n",
    "\n",
    "#### INVESTMENT 2\n",
    "Instrument name: Emerging Markets ETF\n",
    "Acquisition cost: 200,000.00\n",
    "Market value: 180,500.75\n",
    "Value previous period: 194,325.00\n",
    "Currency: USD\n",
    "Sector: International\n",
    "Risk rating: High\n",
    "Maturity date: N/A\n",
    "Annual yield: 3.85%\n",
    "\n",
    "#### INVESTMENT 3\n",
    "Original security name: US Treasury Bond 2026\n",
    "Initial investment: 250,000.00\n",
    "Present value: 250,000.00\n",
    "Prior investment value: 250,000.00\n",
    "Currency: USD\n",
    "Sector: Government\n",
    "Risk profile: Low\n",
    "Expiration date: 06/15/2026\n",
    "Yield %: 4.25\n",
    "\"\"\"\n",
    "        \n",
    "        # Create a sample text file\n",
    "        sample_file_path = \"sample_financial_document.txt\"\n",
    "        with open(sample_file_path, 'w') as f:\n",
    "            f.write(sample_text)\n",
    "        \n",
    "    elif document_type == \".csv\":\n",
    "        sample_text = \"\"\"Security Name,Initial Investment,Market Value,Prior Value,Currency,Sector,Risk Rating,Maturity Date,Yield %\n",
    "Global Technology Fund Class A,400000.00,475250.00,425800.00,USD,Technology,Moderate,N/A,2.45\n",
    "Emerging Markets ETF,200000.00,180500.75,194325.00,USD,International,High,N/A,3.85\n",
    "US Treasury Bond 2026,250000.00,250000.00,250000.00,USD,Government,Low,06/15/2026,4.25\n",
    "\"\"\"\n",
    "        \n",
    "        # Create a sample CSV file\n",
    "        sample_file_path = \"sample_financial_document.csv\"\n",
    "        with open(sample_file_path, 'w') as f:\n",
    "            f.write(sample_text)\n",
    "            \n",
    "    elif document_type == \".json\":\n",
    "        sample_data = {\n",
    "            \"report_date\": \"03/31/2024\",\n",
    "            \"investments\": [\n",
    "                {\n",
    "                    \"security_name\": \"Global Technology Fund Class A\",\n",
    "                    \"investment_original\": \"400000.00\",\n",
    "                    \"investment_current\": \"475250.00\",\n",
    "                    \"investment_prior\": \"425800.00\",\n",
    "                    \"currency\": \"USD\",\n",
    "                    \"sector\": \"Technology\",\n",
    "                    \"risk_rating\": \"Moderate\",\n",
    "                    \"maturity_date\": \"N/A\",\n",
    "                    \"yield_percentage\": \"2.45\"\n",
    "                },\n",
    "                {\n",
    "                    \"security_name\": \"Emerging Markets ETF\",\n",
    "                    \"investment_original\": \"200000.00\",\n",
    "                    \"investment_current\": \"180500.75\",\n",
    "                    \"investment_prior\": \"194325.00\",\n",
    "                    \"currency\": \"USD\",\n",
    "                    \"sector\": \"International\",\n",
    "                    \"risk_rating\": \"High\",\n",
    "                    \"maturity_date\": \"N/A\",\n",
    "                    \"yield_percentage\": \"3.85\"\n",
    "                },\n",
    "                {\n",
    "                    \"security_name\": \"US Treasury Bond 2026\",\n",
    "                    \"investment_original\": \"250000.00\",\n",
    "                    \"investment_current\": \"250000.00\",\n",
    "                    \"investment_prior\": \"250000.00\",\n",
    "                    \"currency\": \"USD\",\n",
    "                    \"sector\": \"Government\",\n",
    "                    \"risk_rating\": \"Low\",\n",
    "                    \"maturity_date\": \"06/15/2026\",\n",
    "                    \"yield_percentage\": \"4.25\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Create a sample JSON file\n",
    "        sample_file_path = \"sample_financial_document.json\"\n",
    "        with open(sample_file_path, 'w') as f:\n",
    "            json.dump(sample_data, f, indent=2)\n",
    "    \n",
    "    elif document_type == \".txt-alt\":\n",
    "        # Alternative text format with different field names and formatting\n",
    "        sample_text = \"\"\"INVESTMENT PORTFOLIO SUMMARY\n",
    "=========================\n",
    "Statement Date: March 31, 2024\n",
    "\n",
    "INVESTMENT HOLDINGS\n",
    "------------------\n",
    "\n",
    "1. ASSET: Global Technology Fund Class A\n",
    "   Cost: $400,000.00\n",
    "   Market Value (Current): $475,250.00\n",
    "   Market Value (Previous Period): $425,800.00\n",
    "   Traded in: USD\n",
    "   Industry Sector: Technology\n",
    "   Risk Assessment: Moderate\n",
    "   Term End Date: Not Applicable\n",
    "   Annual Return: 2.45%\n",
    "\n",
    "2. ASSET: Emerging Markets ETF\n",
    "   Cost: $200,000.00\n",
    "   Market Value (Current): $180,500.75\n",
    "   Market Value (Previous Period): $194,325.00\n",
    "   Traded in: USD\n",
    "   Industry Sector: International\n",
    "   Risk Assessment: High\n",
    "   Term End Date: Not Applicable\n",
    "   Annual Return: 3.85%\n",
    "\n",
    "3. ASSET: US Treasury Bond 2026\n",
    "   Cost: $250,000.00\n",
    "   Market Value (Current): $250,000.00\n",
    "   Market Value (Previous Period): $250,000.00\n",
    "   Traded in: USD\n",
    "   Industry Sector: Government\n",
    "   Risk Assessment: Low\n",
    "   Term End Date: 15/06/2026\n",
    "   Annual Return: 4.25%\n",
    "\"\"\"\n",
    "        \n",
    "        # Create an alternative sample text file\n",
    "        sample_file_path = \"sample_financial_document_alt.txt\"\n",
    "        with open(sample_file_path, 'w') as f:\n",
    "            f.write(sample_text)\n",
    "    \n",
    "    else:\n",
    "        # Create a simple txt file as fallback\n",
    "        sample_file_path = \"sample_financial_document.txt\"\n",
    "        with open(sample_file_path, 'w') as f:\n",
    "            f.write(\"As of date: 03/31/2024\\nAsset: Sample Asset\\nInvestment (original): 100000\\nInvestment: 120000\\nInvestment (prior): 110000\\nCurrency: USD\")\n",
    "    \n",
    "    return sample_file_path\n",
    "\n",
    "# Cell 6 (revised): Main Function with Better Error Handling\n",
    "def main(file_path):\n",
    "    \"\"\"Main function to orchestrate the extraction, processing and storage\"\"\"\n",
    "    logger = logging.getLogger('financial_data_extractor.main')\n",
    "    logger.info(f\"Starting extraction process for {file_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Extract data from document\n",
    "        logger.info(f\"Extracting data from {file_path}...\")\n",
    "        extractor = DocumentExtractor(file_path)\n",
    "        raw_data = extractor.extract_data()\n",
    "        \n",
    "        if not raw_data:\n",
    "            logger.warning(\"No data was extracted from the document.\")\n",
    "            # Create empty data and continue to generate statistics\n",
    "            raw_data = [{}]\n",
    "        \n",
    "        logger.info(f\"Extracted {len(raw_data)} records.\")\n",
    "        \n",
    "        # Step 2: Process and format data\n",
    "        logger.info(\"Processing and formatting data...\")\n",
    "        processor = DataProcessor(raw_data)\n",
    "        processed_data = processor.format_data()\n",
    "        stats = processor.calculate_statistics()\n",
    "        \n",
    "        # Step 3: Store data\n",
    "        logger.info(\"Storing data...\")\n",
    "        storage = DataStorage(processed_data, stats)\n",
    "        \n",
    "        # Attempt to store in database\n",
    "        db_result = storage.store_in_database()\n",
    "        if db_result:\n",
    "            logger.info(f\"Data successfully stored in {CONFIG['database']['type']} database.\")\n",
    "        else:\n",
    "            logger.warning(f\"Failed to store data in database. Check your database connection settings.\")\n",
    "        \n",
    "        # Store in Excel\n",
    "        excel_result = storage.store_in_excel()\n",
    "        if excel_result:\n",
    "            logger.info(f\"Data successfully stored in Excel file: {CONFIG['output']['excel_file']}\")\n",
    "        else:\n",
    "            logger.warning(\"Failed to store data in Excel file.\")\n",
    "        \n",
    "        # Step 4: Print statistics\n",
    "        logger.info(\"\\nExtraction Statistics:\")\n",
    "        logger.info(f\"Total Records: {stats['total_records']}\")\n",
    "        logger.info(f\"Mandatory Fields Extracted: {stats['mandatory_fields_extracted']}\")\n",
    "        logger.info(f\"Mandatory Fields Percentage: {stats['mandatory_fields_percentage']:.2f}%\")\n",
    "        logger.info(f\"Extraction Accuracy: {stats['extraction_accuracy']:.2f}%\")\n",
    "        \n",
    "        if stats['missing_fields']:\n",
    "            logger.info(f\"Missing Fields: {', '.join(stats['missing_fields'])}\")\n",
    "        else:\n",
    "            logger.info(\"Missing Fields: None\")\n",
    "        \n",
    "        if stats['inconsistent_data']:\n",
    "            logger.info(f\"Inconsistent Data: {', '.join(stats['inconsistent_data'])}\")\n",
    "        else:\n",
    "            logger.info(\"Inconsistent Data: None\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in extraction process: {str(e)}\", exc_info=True)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1993b80a-f496-4672-9c26-540bef98c34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 11:56:39,934 - financial_data_extractor.DocumentExtractor - INFO - Extracting text from sample_financial_document.txt (type: .txt)\n",
      "2025-05-09 11:56:39,936 - financial_data_extractor.DocumentExtractor - INFO - Successfully extracted 856 characters of text\n",
      "2025-05-09 11:56:39,937 - financial_data_extractor.DocumentExtractor - INFO - Starting data extraction\n",
      "2025-05-09 11:56:39,938 - financial_data_extractor.DocumentExtractor - INFO - Global as_of_date extracted: 03/31/2024\n",
      "2025-05-09 11:56:39,938 - financial_data_extractor.DocumentExtractor - INFO - No tabular data found, trying section-based extraction\n",
      "2025-05-09 11:56:39,939 - financial_data_extractor.DocumentExtractor - INFO - Identified 3 investment sections\n",
      "2025-05-09 11:56:39,945 - financial_data_extractor.DocumentExtractor - INFO - Extracted 3 valid records with data\n",
      "2025-05-09 11:56:39,946 - financial_data_extractor.DataProcessor - INFO - Formatting extracted data\n",
      "2025-05-09 11:56:39,946 - financial_data_extractor.DataProcessor - INFO - Formatted 3 records\n",
      "2025-05-09 11:56:39,947 - financial_data_extractor.DataProcessor - INFO - Calculating extraction statistics\n",
      "2025-05-09 11:56:39,948 - financial_data_extractor.DataProcessor - INFO - Statistics calculated: 100.00% mandatory fields extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created sample document: sample_financial_document.txt\n",
      "\n",
      "--- Extracted Raw Data (Text) ---\n",
      "\n",
      "Record 1:\n",
      "  as_of_date: 03/31/2024\n",
      "  original_security_name: Global Technology Fund Class A\n",
      "  investment_in_original: 400000.00\n",
      "  investment_in: 475250.00\n",
      "  investment_in_prior: 425800.00\n",
      "  currency: USD\n",
      "  sector: Technology\n",
      "  risk_rating: Moderate\n",
      "  maturity_date: N/A\n",
      "  yield_percentage: 2.45\n",
      "\n",
      "Record 2:\n",
      "  as_of_date: 03/31/2024\n",
      "  original_security_name: Emerging Markets ETF\n",
      "  investment_in_original: 200000.00\n",
      "  investment_in: 180500.75\n",
      "  investment_in_prior: 194325.00\n",
      "  currency: USD\n",
      "  sector: International\n",
      "  risk_rating: High\n",
      "  maturity_date: N/A\n",
      "  yield_percentage: 3.85\n",
      "\n",
      "Record 3:\n",
      "  as_of_date: 03/31/2024\n",
      "  original_security_name: US Treasury Bond 2026\n",
      "  investment_in_original: 250000.00\n",
      "  investment_in: 250000.00\n",
      "  investment_in_prior: 250000.00\n",
      "  currency: USD\n",
      "  sector: Government\n",
      "  risk_rating: Low\n",
      "  maturity_date: 06/15/2026\n",
      "  yield_percentage: 4.25\n",
      "\n",
      "--- Processed Data (Text) ---\n",
      "\n",
      "Record 1:\n",
      "  as_of_date: 03/31/2024\n",
      "  maturity_date: N/A\n",
      "  investment_in_original: 400000.00\n",
      "  investment_in: 475250.00\n",
      "  investment_in_prior: 425800.00\n",
      "  yield_percentage: 2.45\n",
      "  original_security_name: Global Technology Fund Class A\n",
      "  currency: USD\n",
      "  sector: Technology\n",
      "  risk_rating: Moderate\n",
      "\n",
      "Record 2:\n",
      "  as_of_date: 03/31/2024\n",
      "  maturity_date: N/A\n",
      "  investment_in_original: 200000.00\n",
      "  investment_in: 180500.75\n",
      "  investment_in_prior: 194325.00\n",
      "  yield_percentage: 3.85\n",
      "  original_security_name: Emerging Markets ETF\n",
      "  currency: USD\n",
      "  sector: International\n",
      "  risk_rating: High\n",
      "\n",
      "Record 3:\n",
      "  as_of_date: 03/31/2024\n",
      "  maturity_date: 06/15/2026\n",
      "  investment_in_original: 250000.00\n",
      "  investment_in: 250000.00\n",
      "  investment_in_prior: 250000.00\n",
      "  yield_percentage: 4.25\n",
      "  original_security_name: US Treasury Bond 2026\n",
      "  currency: USD\n",
      "  sector: Government\n",
      "  risk_rating: Low\n",
      "\n",
      "--- Extraction Statistics (Text) ---\n",
      "Total Records: 3\n",
      "Mandatory Fields Extracted: 18\n",
      "Mandatory Fields Percentage: 100.00%\n",
      "Extraction Accuracy: 100.00%\n",
      "Missing Fields: None\n",
      "Inconsistent Data: None\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Test Text Document Extraction\n",
    "# Create and test with a sample text document\n",
    "sample_path_txt = create_sample_document(\".txt\")\n",
    "print(f\"Created sample document: {sample_path_txt}\")\n",
    "\n",
    "# Test extraction with the sample document\n",
    "extractor = DocumentExtractor(sample_path_txt)\n",
    "extracted_data = extractor.extract_data()\n",
    "\n",
    "print(\"\\n--- Extracted Raw Data (Text) ---\")\n",
    "for i, item in enumerate(extracted_data):\n",
    "    print(f\"\\nRecord {i+1}:\")\n",
    "    for key, value in item.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Process the extracted data\n",
    "processor = DataProcessor(extracted_data)\n",
    "processed_data = processor.format_data()\n",
    "stats = processor.calculate_statistics()\n",
    "\n",
    "print(\"\\n--- Processed Data (Text) ---\")\n",
    "for i, item in enumerate(processed_data):\n",
    "    print(f\"\\nRecord {i+1}:\")\n",
    "    for key, value in item.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n--- Extraction Statistics (Text) ---\")\n",
    "print(f\"Total Records: {stats['total_records']}\")\n",
    "print(f\"Mandatory Fields Extracted: {stats['mandatory_fields_extracted']}\")\n",
    "print(f\"Mandatory Fields Percentage: {stats['mandatory_fields_percentage']:.2f}%\")\n",
    "print(f\"Extraction Accuracy: {stats['extraction_accuracy']:.2f}%\")\n",
    "\n",
    "if stats['missing_fields']:\n",
    "    print(f\"Missing Fields: {', '.join(stats['missing_fields'])}\")\n",
    "else:\n",
    "    print(\"Missing Fields: None\")\n",
    "\n",
    "if stats['inconsistent_data']:\n",
    "    print(f\"Inconsistent Data: {', '.join(stats['inconsistent_data'])}\")\n",
    "else:\n",
    "    print(\"Inconsistent Data: None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b4f3c34-73a9-41b4-b0b9-ca02f6c2b117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 11:56:41,177 - financial_data_extractor.DocumentExtractor - INFO - Extracting text from sample_financial_document.csv (type: .csv)\n",
      "2025-05-09 11:56:41,179 - financial_data_extractor.DocumentExtractor - INFO - Successfully extracted 372 characters of text\n",
      "2025-05-09 11:56:41,179 - financial_data_extractor.DocumentExtractor - INFO - Starting data extraction\n",
      "2025-05-09 11:56:41,181 - financial_data_extractor.DocumentExtractor - INFO - Global as_of_date extracted: None\n",
      "2025-05-09 11:56:41,181 - financial_data_extractor.DocumentExtractor - INFO - No tabular data found, trying section-based extraction\n",
      "2025-05-09 11:56:41,182 - financial_data_extractor.DocumentExtractor - INFO - Identified 1 investment sections\n",
      "2025-05-09 11:56:41,183 - financial_data_extractor.DocumentExtractor - INFO - No investment sections found, trying general extraction\n",
      "2025-05-09 11:56:41,184 - financial_data_extractor.DocumentExtractor - INFO - Extracted 3 records from CSV file\n",
      "2025-05-09 11:56:41,184 - financial_data_extractor.DocumentExtractor - INFO - Extracted 3 valid records with data\n",
      "2025-05-09 11:56:41,185 - financial_data_extractor.DataProcessor - INFO - Formatting extracted data\n",
      "2025-05-09 11:56:41,186 - financial_data_extractor.DataProcessor - INFO - Formatted 3 records\n",
      "2025-05-09 11:56:41,186 - financial_data_extractor.DataProcessor - INFO - Calculating extraction statistics\n",
      "2025-05-09 11:56:41,188 - financial_data_extractor.DataProcessor - INFO - Statistics calculated: 83.33% mandatory fields extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created sample document: sample_financial_document.csv\n",
      "\n",
      "--- Extracted Raw Data (CSV) ---\n",
      "\n",
      "Record 1:\n",
      "  original_security_name: Global Technology Fund Class A\n",
      "  investment_in_original: 400000.00\n",
      "  investment_in: 475250.00\n",
      "  investment_in_prior: 425800.00\n",
      "  currency: USD\n",
      "  sector: Technology\n",
      "  risk_rating: Moderate\n",
      "  maturity_date: N/A\n",
      "  yield_percentage: 2.45\n",
      "\n",
      "Record 2:\n",
      "  original_security_name: Emerging Markets ETF\n",
      "  investment_in_original: 200000.00\n",
      "  investment_in: 180500.75\n",
      "  investment_in_prior: 194325.00\n",
      "  currency: USD\n",
      "  sector: International\n",
      "  risk_rating: High\n",
      "  maturity_date: N/A\n",
      "  yield_percentage: 3.85\n",
      "\n",
      "Record 3:\n",
      "  original_security_name: US Treasury Bond 2026\n",
      "  investment_in_original: 250000.00\n",
      "  investment_in: 250000.00\n",
      "  investment_in_prior: 250000.00\n",
      "  currency: USD\n",
      "  sector: Government\n",
      "  risk_rating: Low\n",
      "  maturity_date: 06/15/2026\n",
      "  yield_percentage: 4.25\n",
      "\n",
      "--- Processed Data (CSV) ---\n",
      "\n",
      "Record 1:\n",
      "  maturity_date: N/A\n",
      "  investment_in_original: 400000.00\n",
      "  investment_in: 475250.00\n",
      "  investment_in_prior: 425800.00\n",
      "  yield_percentage: 2.45\n",
      "  original_security_name: Global Technology Fund Class A\n",
      "  currency: USD\n",
      "  sector: Technology\n",
      "  risk_rating: Moderate\n",
      "\n",
      "Record 2:\n",
      "  maturity_date: N/A\n",
      "  investment_in_original: 200000.00\n",
      "  investment_in: 180500.75\n",
      "  investment_in_prior: 194325.00\n",
      "  yield_percentage: 3.85\n",
      "  original_security_name: Emerging Markets ETF\n",
      "  currency: USD\n",
      "  sector: International\n",
      "  risk_rating: High\n",
      "\n",
      "Record 3:\n",
      "  maturity_date: 06/15/2026\n",
      "  investment_in_original: 250000.00\n",
      "  investment_in: 250000.00\n",
      "  investment_in_prior: 250000.00\n",
      "  yield_percentage: 4.25\n",
      "  original_security_name: US Treasury Bond 2026\n",
      "  currency: USD\n",
      "  sector: Government\n",
      "  risk_rating: Low\n",
      "\n",
      "--- Extraction Statistics (CSV) ---\n",
      "Total Records: 3\n",
      "Mandatory Fields Extracted: 15\n",
      "Mandatory Fields Percentage: 83.33%\n",
      "Extraction Accuracy: 88.33%\n",
      "Missing Fields: as_of_date (3 missing)\n",
      "Inconsistent Data: None\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Test CSV Document Extraction\n",
    "# Create and test with a sample CSV document\n",
    "sample_path_csv = create_sample_document(\".csv\")\n",
    "print(f\"Created sample document: {sample_path_csv}\")\n",
    "\n",
    "# Test extraction with the sample document\n",
    "extractor = DocumentExtractor(sample_path_csv)\n",
    "extracted_data = extractor.extract_data()\n",
    "\n",
    "print(\"\\n--- Extracted Raw Data (CSV) ---\")\n",
    "for i, item in enumerate(extracted_data):\n",
    "    print(f\"\\nRecord {i+1}:\")\n",
    "    for key, value in item.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Process the extracted data\n",
    "processor = DataProcessor(extracted_data)\n",
    "processed_data = processor.format_data()\n",
    "stats = processor.calculate_statistics()\n",
    "\n",
    "print(\"\\n--- Processed Data (CSV) ---\")\n",
    "for i, item in enumerate(processed_data):\n",
    "    print(f\"\\nRecord {i+1}:\")\n",
    "    for key, value in item.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n--- Extraction Statistics (CSV) ---\")\n",
    "print(f\"Total Records: {stats['total_records']}\")\n",
    "print(f\"Mandatory Fields Extracted: {stats['mandatory_fields_extracted']}\")\n",
    "print(f\"Mandatory Fields Percentage: {stats['mandatory_fields_percentage']:.2f}%\")\n",
    "print(f\"Extraction Accuracy: {stats['extraction_accuracy']:.2f}%\")\n",
    "\n",
    "if stats['missing_fields']:\n",
    "    print(f\"Missing Fields: {', '.join(stats['missing_fields'])}\")\n",
    "else:\n",
    "    print(\"Missing Fields: None\")\n",
    "\n",
    "if stats['inconsistent_data']:\n",
    "    print(f\"Inconsistent Data: {', '.join(stats['inconsistent_data'])}\")\n",
    "else:\n",
    "    print(\"Inconsistent Data: None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20be5e40-d0ee-4b55-a534-0cf8ef57e0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 11:56:43,874 - financial_data_extractor.DocumentExtractor - INFO - Extracting text from sample_financial_document.json (type: .json)\n",
      "2025-05-09 11:56:43,876 - financial_data_extractor.DocumentExtractor - INFO - Successfully extracted 1067 characters of text\n",
      "2025-05-09 11:56:43,876 - financial_data_extractor.DocumentExtractor - INFO - Starting data extraction\n",
      "2025-05-09 11:56:43,876 - financial_data_extractor.DocumentExtractor - INFO - Global as_of_date extracted: None\n",
      "2025-05-09 11:56:43,877 - financial_data_extractor.DocumentExtractor - INFO - No tabular data found, trying section-based extraction\n",
      "2025-05-09 11:56:43,878 - financial_data_extractor.DocumentExtractor - INFO - Identified 1 investment sections\n",
      "2025-05-09 11:56:43,880 - financial_data_extractor.DocumentExtractor - INFO - No investment sections found, trying general extraction\n",
      "2025-05-09 11:56:43,880 - financial_data_extractor.DocumentExtractor - INFO - Extracted 3 records from JSON file\n",
      "2025-05-09 11:56:43,881 - financial_data_extractor.DocumentExtractor - INFO - Extracted 3 valid records with data\n",
      "2025-05-09 11:56:43,883 - financial_data_extractor.DataProcessor - INFO - Formatting extracted data\n",
      "2025-05-09 11:56:43,884 - financial_data_extractor.DataProcessor - INFO - Formatted 3 records\n",
      "2025-05-09 11:56:43,885 - financial_data_extractor.DataProcessor - INFO - Calculating extraction statistics\n",
      "2025-05-09 11:56:43,885 - financial_data_extractor.DataProcessor - INFO - Statistics calculated: 100.00% mandatory fields extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created sample document: sample_financial_document.json\n",
      "\n",
      "--- Extracted Raw Data (JSON) ---\n",
      "\n",
      "Record 1:\n",
      "  as_of_date: 03/31/2024\n",
      "  original_security_name: Global Technology Fund Class A\n",
      "  investment_in_original: 400000.00\n",
      "  investment_in: 475250.00\n",
      "  investment_in_prior: 425800.00\n",
      "  currency: USD\n",
      "  sector: Technology\n",
      "  risk_rating: Moderate\n",
      "  maturity_date: N/A\n",
      "  yield_percentage: 2.45\n",
      "\n",
      "Record 2:\n",
      "  as_of_date: 03/31/2024\n",
      "  original_security_name: Emerging Markets ETF\n",
      "  investment_in_original: 200000.00\n",
      "  investment_in: 180500.75\n",
      "  investment_in_prior: 194325.00\n",
      "  currency: USD\n",
      "  sector: International\n",
      "  risk_rating: High\n",
      "  maturity_date: N/A\n",
      "  yield_percentage: 3.85\n",
      "\n",
      "Record 3:\n",
      "  as_of_date: 03/31/2024\n",
      "  original_security_name: US Treasury Bond 2026\n",
      "  investment_in_original: 250000.00\n",
      "  investment_in: 250000.00\n",
      "  investment_in_prior: 250000.00\n",
      "  currency: USD\n",
      "  sector: Government\n",
      "  risk_rating: Low\n",
      "  maturity_date: 06/15/2026\n",
      "  yield_percentage: 4.25\n",
      "\n",
      "--- Processed Data (JSON) ---\n",
      "\n",
      "Record 1:\n",
      "  as_of_date: 03/31/2024\n",
      "  maturity_date: N/A\n",
      "  investment_in_original: 400000.00\n",
      "  investment_in: 475250.00\n",
      "  investment_in_prior: 425800.00\n",
      "  yield_percentage: 2.45\n",
      "  original_security_name: Global Technology Fund Class A\n",
      "  currency: USD\n",
      "  sector: Technology\n",
      "  risk_rating: Moderate\n",
      "\n",
      "Record 2:\n",
      "  as_of_date: 03/31/2024\n",
      "  maturity_date: N/A\n",
      "  investment_in_original: 200000.00\n",
      "  investment_in: 180500.75\n",
      "  investment_in_prior: 194325.00\n",
      "  yield_percentage: 3.85\n",
      "  original_security_name: Emerging Markets ETF\n",
      "  currency: USD\n",
      "  sector: International\n",
      "  risk_rating: High\n",
      "\n",
      "Record 3:\n",
      "  as_of_date: 03/31/2024\n",
      "  maturity_date: 06/15/2026\n",
      "  investment_in_original: 250000.00\n",
      "  investment_in: 250000.00\n",
      "  investment_in_prior: 250000.00\n",
      "  yield_percentage: 4.25\n",
      "  original_security_name: US Treasury Bond 2026\n",
      "  currency: USD\n",
      "  sector: Government\n",
      "  risk_rating: Low\n",
      "\n",
      "--- Extraction Statistics (JSON) ---\n",
      "Total Records: 3\n",
      "Mandatory Fields Extracted: 18\n",
      "Mandatory Fields Percentage: 100.00%\n",
      "Extraction Accuracy: 100.00%\n",
      "Missing Fields: None\n",
      "Inconsistent Data: None\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Test JSON Document Extraction\n",
    "# Create and test with a sample JSON document\n",
    "sample_path_json = create_sample_document(\".json\")\n",
    "print(f\"Created sample document: {sample_path_json}\")\n",
    "\n",
    "# Test extraction with the sample document\n",
    "extractor = DocumentExtractor(sample_path_json)\n",
    "extracted_data = extractor.extract_data()\n",
    "\n",
    "print(\"\\n--- Extracted Raw Data (JSON) ---\")\n",
    "for i, item in enumerate(extracted_data):\n",
    "    print(f\"\\nRecord {i+1}:\")\n",
    "    for key, value in item.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Process the extracted data\n",
    "processor = DataProcessor(extracted_data)\n",
    "processed_data = processor.format_data()\n",
    "stats = processor.calculate_statistics()\n",
    "\n",
    "print(\"\\n--- Processed Data (JSON) ---\")\n",
    "for i, item in enumerate(processed_data):\n",
    "    print(f\"\\nRecord {i+1}:\")\n",
    "    for key, value in item.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n--- Extraction Statistics (JSON) ---\")\n",
    "print(f\"Total Records: {stats['total_records']}\")\n",
    "print(f\"Mandatory Fields Extracted: {stats['mandatory_fields_extracted']}\")\n",
    "print(f\"Mandatory Fields Percentage: {stats['mandatory_fields_percentage']:.2f}%\")\n",
    "print(f\"Extraction Accuracy: {stats['extraction_accuracy']:.2f}%\")\n",
    "\n",
    "if stats['missing_fields']:\n",
    "    print(f\"Missing Fields: {', '.join(stats['missing_fields'])}\")\n",
    "else:\n",
    "    print(\"Missing Fields: None\")\n",
    "\n",
    "if stats['inconsistent_data']:\n",
    "    print(f\"Inconsistent Data: {', '.join(stats['inconsistent_data'])}\")\n",
    "else:\n",
    "    print(\"Inconsistent Data: None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5af0cf8-442b-4d1f-9c5f-f4517efbaba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 11:56:47,805 - financial_data_extractor.main - INFO - Starting extraction process for sample_financial_document.txt\n",
      "2025-05-09 11:56:47,805 - financial_data_extractor.main - INFO - Extracting data from sample_financial_document.txt...\n",
      "2025-05-09 11:56:47,806 - financial_data_extractor.DocumentExtractor - INFO - Extracting text from sample_financial_document.txt (type: .txt)\n",
      "2025-05-09 11:56:47,808 - financial_data_extractor.DocumentExtractor - INFO - Successfully extracted 856 characters of text\n",
      "2025-05-09 11:56:47,808 - financial_data_extractor.DocumentExtractor - INFO - Starting data extraction\n",
      "2025-05-09 11:56:47,808 - financial_data_extractor.DocumentExtractor - INFO - Global as_of_date extracted: 03/31/2024\n",
      "2025-05-09 11:56:47,809 - financial_data_extractor.DocumentExtractor - INFO - No tabular data found, trying section-based extraction\n",
      "2025-05-09 11:56:47,810 - financial_data_extractor.DocumentExtractor - INFO - Identified 3 investment sections\n",
      "2025-05-09 11:56:47,810 - financial_data_extractor.DocumentExtractor - INFO - Extracted 3 valid records with data\n",
      "2025-05-09 11:56:47,810 - financial_data_extractor.main - INFO - Extracted 3 records.\n",
      "2025-05-09 11:56:47,811 - financial_data_extractor.main - INFO - Processing and formatting data...\n",
      "2025-05-09 11:56:47,812 - financial_data_extractor.DataProcessor - INFO - Formatting extracted data\n",
      "2025-05-09 11:56:47,812 - financial_data_extractor.DataProcessor - INFO - Formatted 3 records\n",
      "2025-05-09 11:56:47,813 - financial_data_extractor.DataProcessor - INFO - Calculating extraction statistics\n",
      "2025-05-09 11:56:47,814 - financial_data_extractor.DataProcessor - INFO - Statistics calculated: 100.00% mandatory fields extracted\n",
      "2025-05-09 11:56:47,814 - financial_data_extractor.main - INFO - Storing data...\n",
      "2025-05-09 11:56:47,814 - financial_data_extractor.DataStorage - INFO - Storing data in postgresql database\n",
      "2025-05-09 11:56:47,899 - financial_data_extractor.DataStorage - INFO - Successfully created financial_data_stats view\n",
      "2025-05-09 11:56:47,900 - financial_data_extractor.DataStorage - INFO - Successfully stored 3 records in database\n",
      "2025-05-09 11:56:47,900 - financial_data_extractor.main - INFO - Data successfully stored in postgresql database.\n",
      "2025-05-09 11:56:47,901 - financial_data_extractor.DataStorage - INFO - Storing data in Excel file: extracted_financial_data.xlsx\n",
      "2025-05-09 11:56:47,928 - financial_data_extractor.DataStorage - INFO - Successfully stored data in Excel file\n",
      "2025-05-09 11:56:47,929 - financial_data_extractor.main - INFO - Data successfully stored in Excel file: extracted_financial_data.xlsx\n",
      "2025-05-09 11:56:47,929 - financial_data_extractor.main - INFO - \n",
      "Extraction Statistics:\n",
      "2025-05-09 11:56:47,929 - financial_data_extractor.main - INFO - Total Records: 3\n",
      "2025-05-09 11:56:47,931 - financial_data_extractor.main - INFO - Mandatory Fields Extracted: 18\n",
      "2025-05-09 11:56:47,931 - financial_data_extractor.main - INFO - Mandatory Fields Percentage: 100.00%\n",
      "2025-05-09 11:56:47,932 - financial_data_extractor.main - INFO - Extraction Accuracy: 100.00%\n",
      "2025-05-09 11:56:47,932 - financial_data_extractor.main - INFO - Missing Fields: None\n",
      "2025-05-09 11:56:47,933 - financial_data_extractor.main - INFO - Inconsistent Data: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created sample document: sample_financial_document.txt\n",
      "\n",
      "Successfully completed the extraction, processing, and storage pipeline!\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Full Pipeline Test\n",
    "# Test the full pipeline with a sample document\n",
    "sample_path = create_sample_document()  # Default is .txt\n",
    "print(f\"Created sample document: {sample_path}\")\n",
    "\n",
    "# Run the main function\n",
    "result = main(sample_path)\n",
    "\n",
    "if result:\n",
    "    print(\"\\nSuccessfully completed the extraction, processing, and storage pipeline!\")\n",
    "else:\n",
    "    print(\"\\nPipeline execution encountered issues. Check logs for details.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fefe9c4c-2fd3-49e3-b23b-36ef8d333d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 11:56:52,064 - financial_data_extractor.DataStorage - INFO - Storing data in Excel file: extracted_financial_data.xlsx\n",
      "2025-05-09 11:56:52,076 - financial_data_extractor.DataStorage - INFO - Successfully stored data in Excel file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data successfully stored in Excel file: extracted_financial_data.xlsx\n",
      "\n",
      "--- Excel Data Preview ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>currency</th>\n",
       "      <th>risk_rating</th>\n",
       "      <th>as_of_date</th>\n",
       "      <th>investment_in_prior</th>\n",
       "      <th>yield_percentage</th>\n",
       "      <th>maturity_date</th>\n",
       "      <th>investment_in_original</th>\n",
       "      <th>original_security_name</th>\n",
       "      <th>sector</th>\n",
       "      <th>investment_in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USD</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>03/31/2024</td>\n",
       "      <td>425800.0</td>\n",
       "      <td>2.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>Global Technology Fund Class A</td>\n",
       "      <td>Technology</td>\n",
       "      <td>475250.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USD</td>\n",
       "      <td>High</td>\n",
       "      <td>03/31/2024</td>\n",
       "      <td>194325.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>Emerging Markets ETF</td>\n",
       "      <td>International</td>\n",
       "      <td>180500.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USD</td>\n",
       "      <td>Low</td>\n",
       "      <td>03/31/2024</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>4.25</td>\n",
       "      <td>06/15/2026</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>US Treasury Bond 2026</td>\n",
       "      <td>Government</td>\n",
       "      <td>250000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  currency risk_rating  as_of_date  investment_in_prior  yield_percentage  \\\n",
       "0      USD    Moderate  03/31/2024             425800.0              2.45   \n",
       "1      USD        High  03/31/2024             194325.0              3.85   \n",
       "2      USD         Low  03/31/2024             250000.0              4.25   \n",
       "\n",
       "  maturity_date  investment_in_original          original_security_name  \\\n",
       "0           NaN                400000.0  Global Technology Fund Class A   \n",
       "1           NaN                200000.0            Emerging Markets ETF   \n",
       "2    06/15/2026                250000.0           US Treasury Bond 2026   \n",
       "\n",
       "          sector  investment_in  \n",
       "0     Technology      475250.00  \n",
       "1  International      180500.75  \n",
       "2     Government      250000.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Excel Statistics Preview ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total Records Processed</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mandatory Fields Extracted</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mandatory Fields Percentage</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extraction Accuracy</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Missing Fields</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Inconsistent Data</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Field presence: as_of_date</td>\n",
       "      <td>3 records (100.00%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Field presence: investment_in_prior</td>\n",
       "      <td>3 records (100.00%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Field presence: yield_percentage</td>\n",
       "      <td>3 records (100.00%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Field presence: maturity_date</td>\n",
       "      <td>3 records (100.00%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Field presence: original_security_name</td>\n",
       "      <td>3 records (100.00%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Field presence: currency</td>\n",
       "      <td>3 records (100.00%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Field presence: risk_rating</td>\n",
       "      <td>3 records (100.00%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Field presence: investment_in_original</td>\n",
       "      <td>3 records (100.00%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Field presence: sector</td>\n",
       "      <td>3 records (100.00%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Field presence: investment_in</td>\n",
       "      <td>3 records (100.00%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Metric                Value\n",
       "0                  Total Records Processed                    3\n",
       "1               Mandatory Fields Extracted                   18\n",
       "2              Mandatory Fields Percentage              100.00%\n",
       "3                      Extraction Accuracy              100.00%\n",
       "4                           Missing Fields                  NaN\n",
       "5                        Inconsistent Data                  NaN\n",
       "6               Field presence: as_of_date  3 records (100.00%)\n",
       "7      Field presence: investment_in_prior  3 records (100.00%)\n",
       "8         Field presence: yield_percentage  3 records (100.00%)\n",
       "9            Field presence: maturity_date  3 records (100.00%)\n",
       "10  Field presence: original_security_name  3 records (100.00%)\n",
       "11                Field presence: currency  3 records (100.00%)\n",
       "12             Field presence: risk_rating  3 records (100.00%)\n",
       "13  Field presence: investment_in_original  3 records (100.00%)\n",
       "14                  Field presence: sector  3 records (100.00%)\n",
       "15           Field presence: investment_in  3 records (100.00%)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 11:56:52,137 - financial_data_extractor.DataStorage - INFO - Storing data in postgresql database\n",
      "2025-05-09 11:56:52,185 - financial_data_extractor.DataStorage - INFO - Successfully created financial_data_stats view\n",
      "2025-05-09 11:56:52,186 - financial_data_extractor.DataStorage - INFO - Successfully stored 3 records in database\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully dropped the view (if it existed).\n",
      "Data successfully stored in postgresql database.\n",
      "\n",
      "--- Database Data Preview ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>currency</th>\n",
       "      <th>risk_rating</th>\n",
       "      <th>as_of_date</th>\n",
       "      <th>investment_in_prior</th>\n",
       "      <th>yield_percentage</th>\n",
       "      <th>maturity_date</th>\n",
       "      <th>investment_in_original</th>\n",
       "      <th>original_security_name</th>\n",
       "      <th>sector</th>\n",
       "      <th>investment_in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USD</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>03/31/2024</td>\n",
       "      <td>425800.00</td>\n",
       "      <td>2.45</td>\n",
       "      <td>N/A</td>\n",
       "      <td>400000.00</td>\n",
       "      <td>Global Technology Fund Class A</td>\n",
       "      <td>Technology</td>\n",
       "      <td>475250.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USD</td>\n",
       "      <td>High</td>\n",
       "      <td>03/31/2024</td>\n",
       "      <td>194325.00</td>\n",
       "      <td>3.85</td>\n",
       "      <td>N/A</td>\n",
       "      <td>200000.00</td>\n",
       "      <td>Emerging Markets ETF</td>\n",
       "      <td>International</td>\n",
       "      <td>180500.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USD</td>\n",
       "      <td>Low</td>\n",
       "      <td>03/31/2024</td>\n",
       "      <td>250000.00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>06/15/2026</td>\n",
       "      <td>250000.00</td>\n",
       "      <td>US Treasury Bond 2026</td>\n",
       "      <td>Government</td>\n",
       "      <td>250000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  currency risk_rating  as_of_date investment_in_prior yield_percentage  \\\n",
       "0      USD    Moderate  03/31/2024           425800.00             2.45   \n",
       "1      USD        High  03/31/2024           194325.00             3.85   \n",
       "2      USD         Low  03/31/2024           250000.00             4.25   \n",
       "\n",
       "  maturity_date investment_in_original          original_security_name  \\\n",
       "0           N/A              400000.00  Global Technology Fund Class A   \n",
       "1           N/A              200000.00            Emerging Markets ETF   \n",
       "2    06/15/2026              250000.00           US Treasury Bond 2026   \n",
       "\n",
       "          sector investment_in  \n",
       "0     Technology     475250.00  \n",
       "1  International     180500.75  \n",
       "2     Government     250000.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Database Stats View Preview ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_records</th>\n",
       "      <th>as_of_date_count</th>\n",
       "      <th>original_security_name_count</th>\n",
       "      <th>investment_in_original_count</th>\n",
       "      <th>investment_in_count</th>\n",
       "      <th>investment_in_prior_count</th>\n",
       "      <th>currency_count</th>\n",
       "      <th>currency_count_distinct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_records  as_of_date_count  original_security_name_count  \\\n",
       "0              3                 3                             3   \n",
       "\n",
       "   investment_in_original_count  investment_in_count  \\\n",
       "0                             3                    3   \n",
       "\n",
       "   investment_in_prior_count  currency_count  currency_count_distinct  \n",
       "0                          3               3                        1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 11: Store in Excel and Database\n",
    "# Test the storage functionality with the sample data\n",
    "storage = DataStorage(processed_data, stats)\n",
    "\n",
    "# Store in Excel\n",
    "excel_result = storage.store_in_excel()\n",
    "if excel_result:\n",
    "    print(f\"\\nData successfully stored in Excel file: {CONFIG['output']['excel_file']}\")\n",
    "    # Read and display Excel file contents to verify\n",
    "    try:\n",
    "        df = pd.read_excel(CONFIG['output']['excel_file'], sheet_name='Extracted Data')\n",
    "        print(\"\\n--- Excel Data Preview ---\")\n",
    "        display(df)  # Jupyter will nicely format this\n",
    "        \n",
    "        stats_df = pd.read_excel(CONFIG['output']['excel_file'], sheet_name='Statistics')\n",
    "        print(\"\\n--- Excel Statistics Preview ---\")\n",
    "        display(stats_df)  # Jupyter will nicely format this\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading Excel file: {e}\")\n",
    "else:\n",
    "    print(\"Failed to store data in Excel file.\")\n",
    "\n",
    "# Store in database\n",
    "try:\n",
    "    # Ensure view is dropped to avoid conflicts\n",
    "    connection_string = f\"postgresql://{CONFIG['database']['user']}:{CONFIG['database']['password']}@{CONFIG['database']['host']}:{CONFIG['database']['port']}/{CONFIG['database']['database']}\"\n",
    "    engine = create_engine(connection_string)\n",
    "    \n",
    "    from sqlalchemy import text\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(\"DROP VIEW IF EXISTS financial_data_stats CASCADE;\"))\n",
    "        connection.commit()\n",
    "    \n",
    "    print(\"Successfully dropped the view (if it existed).\")\n",
    "except Exception as e:\n",
    "    print(f\"Error dropping view: {e}\")\n",
    "\n",
    "# Store data in database and verify\n",
    "try:\n",
    "    # Step 1: Store the data\n",
    "    db_result = storage.store_in_database()\n",
    "    if db_result:\n",
    "        print(f\"Data successfully stored in {CONFIG['database']['type']} database.\")\n",
    "        \n",
    "        connection_string = f\"postgresql://{CONFIG['database']['user']}:{CONFIG['database']['password']}@{CONFIG['database']['host']}:{CONFIG['database']['port']}/{CONFIG['database']['database']}\"\n",
    "        engine = create_engine(connection_string)\n",
    "        \n",
    "        # Step 2: Verify the data\n",
    "        query = \"SELECT * FROM financial_data\"\n",
    "        db_data = pd.read_sql(query, engine)\n",
    "        \n",
    "        print(\"\\n--- Database Data Preview ---\")\n",
    "        display(db_data)\n",
    "        \n",
    "        # Step 3: Query the stats view\n",
    "        query = \"SELECT * FROM financial_data_stats\"\n",
    "        stats_data = pd.read_sql(query, engine)\n",
    "        \n",
    "        print(\"\\n--- Database Stats View Preview ---\")\n",
    "        display(stats_data)\n",
    "    else:\n",
    "        print(f\"Failed to store data in database.\")\n",
    "except Exception as e:\n",
    "    print(f\"Database operation error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa29e70-7df9-4062-8a89-897b6c4b3977",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
