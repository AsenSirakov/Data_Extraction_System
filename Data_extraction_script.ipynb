{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad83720f-8fce-4779-8b93-9e6a031901ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import psycopg2  # For PostgreSQL\n",
    "import pymysql   # For MySQL\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, PatternFill, Alignment\n",
    "import docx2txt  # For .docx files\n",
    "import PyPDF2    # For PDF files\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f0a8d6a-7d01-46dd-b2cb-c7139d44b1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from example_financial_document.docx...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'example_financial_document.docx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 388\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m    387\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_financial_document.docx\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with your document path\u001b[39;00m\n\u001b[1;32m--> 388\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 333\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting data from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    332\u001b[0m extractor \u001b[38;5;241m=\u001b[39m DocumentExtractor(file_path)\n\u001b[1;32m--> 333\u001b[0m raw_data \u001b[38;5;241m=\u001b[39m \u001b[43mextractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_data:\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data was extracted from the document.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 69\u001b[0m, in \u001b[0;36mDocumentExtractor.extract_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Make sure we have text to process\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_text:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Initialize data dictionaries list\u001b[39;00m\n\u001b[0;32m     72\u001b[0m data_dicts \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[8], line 45\u001b[0m, in \u001b[0;36mDocumentExtractor.extract_text\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Extract raw text from document based on file extension\"\"\"\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_extension \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.docx\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_text \u001b[38;5;241m=\u001b[39m \u001b[43mdocx2txt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_extension \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\docx2txt\\docx2txt.py:76\u001b[0m, in \u001b[0;36mprocess\u001b[1;34m(docx, img_dir)\u001b[0m\n\u001b[0;32m     73\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# unzip the docx in memory\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m zipf \u001b[38;5;241m=\u001b[39m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m filelist \u001b[38;5;241m=\u001b[39m zipf\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# get header text\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# there can be 3 header files in the zip\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\zipfile\\__init__.py:1331\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1331\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m   1333\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'example_financial_document.docx'"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"database\": {\n",
    "        \"type\": \"postgresql\",  # Change to \"mysql\" if using MySQL\n",
    "        \"host\": \"localhost\",\n",
    "        \"port\": 5432,  # Change to 3306 for MySQL\n",
    "        \"database\": \"financial_data\",\n",
    "        \"user\": \"postgres\",\n",
    "        \"password\": \"SenkoSQL\"\n",
    "    },\n",
    "    \"extraction\": {\n",
    "        \"mandatory_fields\": [\n",
    "            \"as_of_date\",\n",
    "            \"original_security_name\",\n",
    "            \"investment_in_original\",\n",
    "            \"investment_in\",\n",
    "            \"investment_in_prior\",\n",
    "            \"currency\"\n",
    "        ],\n",
    "        \"additional_fields\": [\n",
    "            \"sector\",\n",
    "            \"risk_rating\",\n",
    "            \"maturity_date\",\n",
    "            \"yield_percentage\"\n",
    "        ]\n",
    "    },\n",
    "    \"output\": {\n",
    "        \"excel_file\": \"extracted_financial_data.xlsx\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "class DocumentExtractor:\n",
    "    \"\"\"Handle extraction of data from various document types\"\"\"\n",
    "    \n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.file_extension = os.path.splitext(file_path)[1].lower()\n",
    "        self.raw_text = \"\"\n",
    "        self.extracted_data = []\n",
    "        \n",
    "    def extract_text(self):\n",
    "        \"\"\"Extract raw text from document based on file extension\"\"\"\n",
    "        if self.file_extension == \".docx\":\n",
    "            self.raw_text = docx2txt.process(self.file_path)\n",
    "        elif self.file_extension == \".pdf\":\n",
    "            with open(self.file_path, \"rb\") as file:\n",
    "                pdf_reader = PyPDF2.PdfReader(file)\n",
    "                for page_num in range(len(pdf_reader.pages)):\n",
    "                    page = pdf_reader.pages[page_num]\n",
    "                    self.raw_text += page.extract_text()\n",
    "        elif self.file_extension == \".txt\":\n",
    "            with open(self.file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                self.raw_text = file.read()\n",
    "        elif self.file_extension == \".csv\":\n",
    "            with open(self.file_path, 'r', encoding='utf-8') as file:\n",
    "                reader = csv.reader(file)\n",
    "                for row in reader:\n",
    "                    self.raw_text += ' '.join(row) + '\\n'\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file format: {self.file_extension}\")\n",
    "            \n",
    "        return self.raw_text\n",
    "    \n",
    "    def extract_data(self):\n",
    "        \"\"\"Extract structured data from the text\"\"\"\n",
    "        # Make sure we have text to process\n",
    "        if not self.raw_text:\n",
    "            self.extract_text()\n",
    "            \n",
    "        # Initialize data dictionaries list\n",
    "        data_dicts = []\n",
    "        \n",
    "        # Patterns for extraction - these will need to be adjusted based on the actual document format\n",
    "        patterns = {\n",
    "            \"as_of_date\": r\"(?:As of date|Date)[:\\s]+([0-9]{1,2}[\\/\\-\\.][0-9]{1,2}[\\/\\-\\.][0-9]{2,4})\",\n",
    "            \"original_security_name\": r\"(?:Original security name|Security)[:\\s]+([A-Za-z0-9\\s\\.\\,\\&\\-]+)\",\n",
    "            \"investment_in_original\": r\"(?:Investment in \\(original\\)|Original investment)[:\\s]+([0-9,\\.]+)\",\n",
    "            \"investment_in\": r\"(?:Investment in(?!\\s+\\()|Current investment)[:\\s]+([0-9,\\.]+)\",\n",
    "            \"investment_in_prior\": r\"(?:Investment in \\(prior\\)|Prior investment)[:\\s]+([0-9,\\.]+)\",\n",
    "            \"currency\": r\"(?:Currency)[:\\s]+([A-Z]{3})\",\n",
    "            # Additional fields (optional)\n",
    "            \"sector\": r\"(?:Sector|Industry)[:\\s]+([A-Za-z\\s\\&]+)\",\n",
    "            \"risk_rating\": r\"(?:Risk rating|Risk)[:\\s]+([A-Za-z0-9\\-]+)\",\n",
    "            \"maturity_date\": r\"(?:Maturity date|Maturity)[:\\s]+([0-9]{1,2}[\\/\\-\\.][0-9]{1,2}[\\/\\-\\.][0-9]{2,4})\",\n",
    "            \"yield_percentage\": r\"(?:Yield|Yield %)[:\\s]+([0-9\\.]+)[%]?\"\n",
    "        }\n",
    "        \n",
    "        # This is a simplified approach - for real documents, you might need \n",
    "        # more sophisticated parsing based on document structure\n",
    "        \n",
    "        # Approach 1: Try to find individual entries (assuming one entry per line or section)\n",
    "        sections = re.split(r'\\n\\s*\\n', self.raw_text)\n",
    "        \n",
    "        for section in sections:\n",
    "            if len(section.strip()) < 10:  # Skip very short sections\n",
    "                continue\n",
    "                \n",
    "            data_dict = {}\n",
    "            \n",
    "            # Extract each field from the section\n",
    "            for field, pattern in patterns.items():\n",
    "                match = re.search(pattern, section)\n",
    "                if match:\n",
    "                    data_dict[field] = match.group(1).strip()\n",
    "                    \n",
    "            # Only add if we found at least one field\n",
    "            if data_dict:\n",
    "                # Check if this could be a valid entry\n",
    "                if any(key in data_dict for key in CONFIG[\"extraction\"][\"mandatory_fields\"]):\n",
    "                    data_dicts.append(data_dict)\n",
    "        \n",
    "        # If no data found with the section approach, try whole document approach\n",
    "        if not data_dicts:\n",
    "            data_dict = {}\n",
    "            for field, pattern in patterns.items():\n",
    "                matches = re.findall(pattern, self.raw_text)\n",
    "                if matches:\n",
    "                    data_dict[field] = matches[0].strip()\n",
    "            \n",
    "            if data_dict:\n",
    "                data_dicts.append(data_dict)\n",
    "                \n",
    "        self.extracted_data = data_dicts\n",
    "        return data_dicts\n",
    "\n",
    "\n",
    "class DataProcessor:\n",
    "    \"\"\"Process and format the extracted data\"\"\"\n",
    "    \n",
    "    def __init__(self, data_list):\n",
    "        self.raw_data = data_list\n",
    "        self.processed_data = []\n",
    "        self.extraction_stats = {}\n",
    "        \n",
    "    def format_data(self):\n",
    "        \"\"\"Format all data according to US standards\"\"\"\n",
    "        for item in self.raw_data:\n",
    "            processed_item = {}\n",
    "            \n",
    "            # Process date fields (MM/DD/YYYY)\n",
    "            for field in ['as_of_date', 'maturity_date']:\n",
    "                if field in item:\n",
    "                    try:\n",
    "                        # Try different date formats\n",
    "                        for fmt in ['%d/%m/%Y', '%d-%m-%Y', '%d.%m.%Y', '%m/%d/%Y', '%Y-%m-%d']:\n",
    "                            try:\n",
    "                                date_obj = datetime.strptime(item[field], fmt)\n",
    "                                processed_item[field] = date_obj.strftime('%m/%d/%Y')\n",
    "                                break\n",
    "                            except ValueError:\n",
    "                                continue\n",
    "                    except:\n",
    "                        # If we can't parse it, keep the original\n",
    "                        processed_item[field] = item[field]\n",
    "            \n",
    "            # Process currency fields (USD format with 2 decimal places)\n",
    "            for field in ['investment_in_original', 'investment_in', 'investment_in_prior']:\n",
    "                if field in item:\n",
    "                    try:\n",
    "                        # Remove any non-numeric characters except decimal point\n",
    "                        value = re.sub(r'[^\\d.]', '', item[field])\n",
    "                        # Format as currency with 2 decimal places\n",
    "                        processed_item[field] = \"{:.2f}\".format(float(value))\n",
    "                    except:\n",
    "                        processed_item[field] = item[field]\n",
    "            \n",
    "            # Process yield percentage\n",
    "            if 'yield_percentage' in item:\n",
    "                try:\n",
    "                    value = re.sub(r'[^\\d.]', '', item['yield_percentage'])\n",
    "                    processed_item['yield_percentage'] = \"{:.2f}\".format(float(value))\n",
    "                except:\n",
    "                    processed_item['yield_percentage'] = item['yield_percentage']\n",
    "            \n",
    "            # Copy other fields as is\n",
    "            for field in ['original_security_name', 'currency', 'sector', 'risk_rating']:\n",
    "                if field in item:\n",
    "                    processed_item[field] = item[field]\n",
    "            \n",
    "            self.processed_data.append(processed_item)\n",
    "        \n",
    "        return self.processed_data\n",
    "    \n",
    "    def calculate_statistics(self):\n",
    "        \"\"\"Calculate extraction statistics\"\"\"\n",
    "        total_records = len(self.processed_data)\n",
    "        if total_records == 0:\n",
    "            self.extraction_stats = {\n",
    "                \"total_records\": 0,\n",
    "                \"mandatory_fields_extracted\": 0,\n",
    "                \"mandatory_fields_percentage\": 0,\n",
    "                \"extraction_accuracy\": 0,\n",
    "                \"missing_fields\": CONFIG[\"extraction\"][\"mandatory_fields\"],\n",
    "                \"inconsistent_data\": []\n",
    "            }\n",
    "            return self.extraction_stats\n",
    "        \n",
    "        # Count mandatory fields\n",
    "        mandatory_fields = CONFIG[\"extraction\"][\"mandatory_fields\"]\n",
    "        mandatory_field_counts = {field: 0 for field in mandatory_fields}\n",
    "        \n",
    "        for record in self.processed_data:\n",
    "            for field in mandatory_fields:\n",
    "                if field in record and record[field]:\n",
    "                    mandatory_field_counts[field] += 1\n",
    "        \n",
    "        # Calculate percentages\n",
    "        total_mandatory_fields = len(mandatory_fields) * total_records\n",
    "        extracted_mandatory_fields = sum(mandatory_field_counts.values())\n",
    "        \n",
    "        mandatory_fields_percentage = (extracted_mandatory_fields / total_mandatory_fields) * 100 if total_mandatory_fields > 0 else 0\n",
    "        \n",
    "        # Identify missing and inconsistent data\n",
    "        missing_fields = []\n",
    "        for field, count in mandatory_field_counts.items():\n",
    "            if count < total_records:\n",
    "                missing_fields.append(f\"{field} ({total_records - count} missing)\")\n",
    "        \n",
    "        # Check for inconsistent data\n",
    "        inconsistent_data = []\n",
    "        \n",
    "        # Example check: Verify if currencies are consistent\n",
    "        currencies = set()\n",
    "        for record in self.processed_data:\n",
    "            if 'currency' in record and record['currency']:\n",
    "                currencies.add(record['currency'])\n",
    "        \n",
    "        if len(currencies) > 1:\n",
    "            inconsistent_data.append(f\"Multiple currencies detected: {', '.join(currencies)}\")\n",
    "        \n",
    "        # Calculate overall extraction accuracy (simplified)\n",
    "        extraction_accuracy = mandatory_fields_percentage  # This can be refined with additional logic\n",
    "        \n",
    "        self.extraction_stats = {\n",
    "            \"total_records\": total_records,\n",
    "            \"mandatory_fields_extracted\": extracted_mandatory_fields,\n",
    "            \"mandatory_fields_percentage\": mandatory_fields_percentage,\n",
    "            \"extraction_accuracy\": extraction_accuracy,\n",
    "            \"missing_fields\": missing_fields,\n",
    "            \"inconsistent_data\": inconsistent_data\n",
    "        }\n",
    "        \n",
    "        return self.extraction_stats\n",
    "\n",
    "\n",
    "class DataStorage:\n",
    "    \"\"\"Store processed data in database and Excel file\"\"\"\n",
    "    \n",
    "    def __init__(self, processed_data, stats):\n",
    "        self.data = processed_data\n",
    "        self.stats = stats\n",
    "        self.db_config = CONFIG[\"database\"]\n",
    "        self.excel_file = CONFIG[\"output\"][\"excel_file\"]\n",
    "        \n",
    "    def create_dataframe(self):\n",
    "        \"\"\"Convert processed data to pandas DataFrame\"\"\"\n",
    "        return pd.DataFrame(self.data)\n",
    "    \n",
    "    def store_in_database(self):\n",
    "        \"\"\"Store data in SQL database\"\"\"\n",
    "        try:\n",
    "            # Create database connection\n",
    "            if self.db_config[\"type\"] == \"postgresql\":\n",
    "                connection_string = f\"postgresql://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}\"\n",
    "            else:  # MySQL\n",
    "                connection_string = f\"mysql+pymysql://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}\"\n",
    "            \n",
    "            engine = create_engine(connection_string)\n",
    "            \n",
    "            # Convert data to DataFrame\n",
    "            df = self.create_dataframe()\n",
    "            \n",
    "            # Store in database\n",
    "            df.to_sql('financial_data', engine, if_exists='replace', index=False)\n",
    "            \n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Database storage error: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def store_in_excel(self):\n",
    "        \"\"\"Store data in Excel file with two sheets\"\"\"\n",
    "        try:\n",
    "            # Create a Pandas Excel writer\n",
    "            writer = pd.ExcelWriter(self.excel_file, engine='openpyxl')\n",
    "            \n",
    "            # Convert data to DataFrame\n",
    "            df = self.create_dataframe()\n",
    "            \n",
    "            # Write data to \"Extracted Data\" sheet\n",
    "            df.to_excel(writer, sheet_name='Extracted Data', index=False)\n",
    "            \n",
    "            # Create statistics DataFrame\n",
    "            stats_data = {\n",
    "                \"Metric\": [\n",
    "                    \"Total Records Processed\",\n",
    "                    \"Mandatory Fields Extracted\",\n",
    "                    \"Mandatory Fields Percentage\",\n",
    "                    \"Extraction Accuracy\",\n",
    "                    \"Missing Fields\",\n",
    "                    \"Inconsistent Data\"\n",
    "                ],\n",
    "                \"Value\": [\n",
    "                    self.stats[\"total_records\"],\n",
    "                    self.stats[\"mandatory_fields_extracted\"],\n",
    "                    f\"{self.stats['mandatory_fields_percentage']:.2f}%\",\n",
    "                    f\"{self.stats['extraction_accuracy']:.2f}%\",\n",
    "                    \", \".join(self.stats[\"missing_fields\"]) if self.stats[\"missing_fields\"] else \"None\",\n",
    "                    \", \".join(self.stats[\"inconsistent_data\"]) if self.stats[\"inconsistent_data\"] else \"None\"\n",
    "                ]\n",
    "            }\n",
    "            \n",
    "            stats_df = pd.DataFrame(stats_data)\n",
    "            \n",
    "            # Write statistics to \"Statistics\" sheet\n",
    "            stats_df.to_excel(writer, sheet_name='Statistics', index=False)\n",
    "            \n",
    "            # Save the Excel file\n",
    "            writer.close()\n",
    "            \n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Excel storage error: {e}\")\n",
    "            return False\n",
    "\n",
    "\n",
    "def main(file_path):\n",
    "    \"\"\"Main function to orchestrate the extraction, processing and storage\"\"\"\n",
    "    # Step 1: Extract data from document\n",
    "    print(f\"Extracting data from {file_path}...\")\n",
    "    extractor = DocumentExtractor(file_path)\n",
    "    raw_data = extractor.extract_data()\n",
    "    \n",
    "    if not raw_data:\n",
    "        print(\"No data was extracted from the document.\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"Extracted {len(raw_data)} records.\")\n",
    "    \n",
    "    # Step 2: Process and format data\n",
    "    print(\"Processing and formatting data...\")\n",
    "    processor = DataProcessor(raw_data)\n",
    "    processed_data = processor.format_data()\n",
    "    stats = processor.calculate_statistics()\n",
    "    \n",
    "    # Step 3: Store data\n",
    "    print(\"Storing data...\")\n",
    "    storage = DataStorage(processed_data, stats)\n",
    "    \n",
    "    # Attempt to store in database\n",
    "    db_result = storage.store_in_database()\n",
    "    if db_result:\n",
    "        print(f\"Data successfully stored in {CONFIG['database']['type']} database.\")\n",
    "    else:\n",
    "        print(f\"Failed to store data in database. Check your database connection settings.\")\n",
    "    \n",
    "    # Store in Excel\n",
    "    excel_result = storage.store_in_excel()\n",
    "    if excel_result:\n",
    "        print(f\"Data successfully stored in Excel file: {CONFIG['output']['excel_file']}\")\n",
    "    else:\n",
    "        print(\"Failed to store data in Excel file.\")\n",
    "    \n",
    "    # Step 4: Print statistics\n",
    "    print(\"\\nExtraction Statistics:\")\n",
    "    print(f\"Total Records: {stats['total_records']}\")\n",
    "    print(f\"Mandatory Fields Extracted: {stats['mandatory_fields_extracted']}\")\n",
    "    print(f\"Mandatory Fields Percentage: {stats['mandatory_fields_percentage']:.2f}%\")\n",
    "    print(f\"Extraction Accuracy: {stats['extraction_accuracy']:.2f}%\")\n",
    "    \n",
    "    if stats['missing_fields']:\n",
    "        print(f\"Missing Fields: {', '.join(stats['missing_fields'])}\")\n",
    "    else:\n",
    "        print(\"Missing Fields: None\")\n",
    "    \n",
    "    if stats['inconsistent_data']:\n",
    "        print(f\"Inconsistent Data: {', '.join(stats['inconsistent_data'])}\")\n",
    "    else:\n",
    "        print(\"Inconsistent Data: None\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    file_path = \"example_financial_document.docx\"  # Replace with your document path\n",
    "    main(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34784f79-d47e-4c65-9e72-0475ce4f739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_document():\n",
    "    \"\"\"\n",
    "    Create a sample financial document for testing.\n",
    "    Returns the path to the created document.\n",
    "    \"\"\"\n",
    "    sample_text = \"\"\"# QUARTERLY INVESTMENT REPORT\n",
    "## Confidential Financial Document\n",
    "\n",
    "**As of date:** 03/31/2024\n",
    "\n",
    "### PORTFOLIO SUMMARY\n",
    "\n",
    "| Security Name | Investment Amount | Prior Investment | Change (%) |\n",
    "|---------------|------------------|-----------------|-----------|\n",
    "| Global Tech Fund | $475,250.00 | $425,800.00 | +11.61% |\n",
    "| Emerging Markets ETF | $180,500.75 | $194,325.00 | -7.11% |\n",
    "| US Treasury Bond 2026 | $250,000.00 | $250,000.00 | 0.00% |\n",
    "\n",
    "### DETAILED INVESTMENTS\n",
    "\n",
    "#### INVESTMENT 1\n",
    "**Original security name:** Global Technology Fund Class A  \n",
    "**Investment in (original):** 400,000.00  \n",
    "**Investment in:** 475,250.00  \n",
    "**Investment in (prior):** 425,800.00  \n",
    "**Currency:** USD  \n",
    "**Sector:** Technology  \n",
    "**Risk rating:** Moderate  \n",
    "**Maturity date:** N/A  \n",
    "**Yield percentage:** 2.45%  \n",
    "\n",
    "#### INVESTMENT 2\n",
    "**Original security name:** Emerging Markets ETF  \n",
    "**Investment in (original):** 200,000.00  \n",
    "**Investment in:** 180,500.75  \n",
    "**Investment in (prior):** 194,325.00  \n",
    "**Currency:** USD  \n",
    "**Sector:** International  \n",
    "**Risk rating:** High  \n",
    "**Maturity date:** N/A  \n",
    "**Yield percentage:** 3.85%  \n",
    "\n",
    "#### INVESTMENT 3\n",
    "**Original security name:** US Treasury Bond 2026  \n",
    "**Investment in (original):** 250,000.00  \n",
    "**Investment in:** 250,000.00  \n",
    "**Investment in (prior):** 250,000.00  \n",
    "**Currency:** USD  \n",
    "**Sector:** Government  \n",
    "**Risk rating:** Low  \n",
    "**Maturity date:** 06/15/2026  \n",
    "**Yield percentage:** 4.25%  \n",
    "\"\"\"\n",
    "    \n",
    "    # Create a sample text file\n",
    "    sample_file_path = \"sample_financial_document.txt\"\n",
    "    with open(sample_file_path, 'w') as f:\n",
    "        f.write(sample_text)\n",
    "    \n",
    "    return sample_file_path\n",
    "\n",
    "# Create the sample document\n",
    "sample_path = create_sample_document()\n",
    "print(f\"Created sample document: {sample_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9a5709-d92c-436c-af06-3ff6b5e4a60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test extraction with the sample document\n",
    "extractor = DocumentExtractor(sample_path)\n",
    "extracted_data = extractor.extract_data()\n",
    "\n",
    "print(\"\\n--- Extracted Raw Data ---\")\n",
    "for i, item in enumerate(extracted_data):\n",
    "    print(f\"\\nRecord {i+1}:\")\n",
    "    for key, value in item.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d9b71f-73ad-441f-a52f-954f8fa404e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the extracted data\n",
    "processor = DataProcessor(extracted_data)\n",
    "processed_data = processor.format_data()\n",
    "stats = processor.calculate_statistics()\n",
    "\n",
    "print(\"\\n--- Processed Data ---\")\n",
    "for i, item in enumerate(processed_data):\n",
    "    print(f\"\\nRecord {i+1}:\")\n",
    "    for key, value in item.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n--- Extraction Statistics ---\")\n",
    "print(f\"Total Records: {stats['total_records']}\")\n",
    "print(f\"Mandatory Fields Extracted: {stats['mandatory_fields_extracted']}\")\n",
    "print(f\"Mandatory Fields Percentage: {stats['mandatory_fields_percentage']:.2f}%\")\n",
    "print(f\"Extraction Accuracy: {stats['extraction_accuracy']:.2f}%\")\n",
    "\n",
    "if stats['missing_fields']:\n",
    "    print(f\"Missing Fields: {', '.join(stats['missing_fields'])}\")\n",
    "else:\n",
    "    print(\"Missing Fields: None\")\n",
    "\n",
    "if stats['inconsistent_data']:\n",
    "    print(f\"Inconsistent Data: {', '.join(stats['inconsistent_data'])}\")\n",
    "else:\n",
    "    print(\"Inconsistent Data: None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968b3daf-0a4e-4c2b-be9c-c4558aafc5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data in Excel\n",
    "storage = DataStorage(processed_data, stats)\n",
    "excel_result = storage.store_in_excel()\n",
    "\n",
    "if excel_result:\n",
    "    print(f\"\\nData successfully stored in Excel file: {CONFIG['output']['excel_file']}\")\n",
    "    # Read and display Excel file contents to verify\n",
    "    try:\n",
    "        df = pd.read_excel(CONFIG['output']['excel_file'], sheet_name='Extracted Data')\n",
    "        print(\"\\n--- Excel Data Preview ---\")\n",
    "        display(df)  # Jupyter will nicely format this\n",
    "        \n",
    "        stats_df = pd.read_excel(CONFIG['output']['excel_file'], sheet_name='Statistics')\n",
    "        print(\"\\n--- Excel Statistics Preview ---\")\n",
    "        display(stats_df)  # Jupyter will nicely format this\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading Excel file: {e}\")\n",
    "else:\n",
    "    print(\"Failed to store data in Excel file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dda838b-1dac-417a-9afe-49230ee98206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data in database\n",
    "try:\n",
    "    db_result = storage.store_in_database()\n",
    "    if db_result:\n",
    "        print(f\"Data successfully stored in {CONFIG['database']['type']} database.\")\n",
    "        \n",
    "        # Verify data in database\n",
    "        connection_string = f\"postgresql://{CONFIG['database']['user']}:{CONFIG['database']['password']}@{CONFIG['database']['host']}:{CONFIG['database']['port']}/{CONFIG['database']['database']}\"\n",
    "        engine = create_engine(connection_string)\n",
    "        \n",
    "        # Query the database to verify data was stored\n",
    "        query = \"SELECT * FROM financial_data\"\n",
    "        db_data = pd.read_sql(query, engine)\n",
    "        \n",
    "        print(\"\\n--- Database Data Preview ---\")\n",
    "        display(db_data)\n",
    "    else:\n",
    "        print(f\"Failed to store data in database.\")\n",
    "except Exception as e:\n",
    "    print(f\"Database error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
