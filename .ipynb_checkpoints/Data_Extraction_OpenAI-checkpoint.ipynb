{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e598a33-0a34-4e7a-ab69-d9f075dbbf38",
   "metadata": {},
   "source": [
    "# **Data Extraction Using OpenAI API (GPT-4)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e83717e-a657-460c-8eea-de6d552d7b89",
   "metadata": {},
   "source": [
    "## Note: I will again write the description for the setup of the PostgreSQL Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865e8a56-a071-4503-949a-5f05dea5675e",
   "metadata": {},
   "source": [
    "### **Setting Up the PostgreSQL Database**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd8a291-3ed8-424f-adf6-9e84010640df",
   "metadata": {},
   "source": [
    "To store the extracted and processed financial data, we create a dedicated PostgreSQL database and define a schema that supports both data storage and statistical analysis.\n",
    "\n",
    "#### 1. Create the Database\n",
    "\n",
    "First, create the database named `financial_data`:\n",
    "\n",
    "```sql\n",
    "CREATE DATABASE financial_data;\n",
    "```\n",
    "#### 2. Connect to it \n",
    "``` sql\n",
    "\\c financial_data\n",
    "```\n",
    "#### 3. Create the Main Table: financial_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5020029d-be2f-4ac4-b4bc-e5cd230c6fbb",
   "metadata": {},
   "source": [
    "The financial_data table is designed to store each investment record with both required and optional fields. It includes financial metrics, metadata, and indexing for performance:\n",
    "```sql\n",
    "CREATE TABLE IF NOT EXISTS financial_data (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    as_of_date DATE,\n",
    "    original_security_name VARCHAR(255),\n",
    "    investment_in_original DECIMAL(18, 2),\n",
    "    investment_in DECIMAL(18, 2),\n",
    "    investment_in_prior DECIMAL(18, 2),\n",
    "    currency VARCHAR(3),\n",
    "    sector VARCHAR(100),\n",
    "    risk_rating VARCHAR(50),\n",
    "    maturity_date DATE,\n",
    "    yield_percentage DECIMAL(6, 2),\n",
    "    isin VARCHAR(20),\n",
    "    cusip VARCHAR(20),\n",
    "    asset_class VARCHAR(50),\n",
    "    country VARCHAR(100),\n",
    "    region VARCHAR(100),\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "```\n",
    "\n",
    "This table is designed to store structured financial investment data. Below is a column-by-column explanation of what each field does, along with what the data types like `VARCHAR` and `DECIMAL` actually mean.\n",
    "\n",
    "---\n",
    "\n",
    "#### Column-by-Column Breakdown\n",
    "\n",
    "- **`id`** – A unique, auto-incrementing number for each row. `SERIAL` automatically generates values like 1, 2, 3, etc., and acts as the primary key to uniquely identify each record.\n",
    "\n",
    "- **`as_of_date`** – Stores the date when the investment data was recorded. The `DATE` type is used to handle standard calendar dates (e.g., `2024-03-31`).\n",
    "\n",
    "- **`original_security_name`** – Stores the full name of the investment or asset (e.g., \"US Treasury Bond 2026\"). `VARCHAR(255)` means it can hold up to 255 characters of text.\n",
    "\n",
    "- **`investment_in_original`** – The original amount of money that was invested. `DECIMAL(18, 2)` allows up to 18 digits total, with 2 digits after the decimal point (e.g., `1000000.00`), ensuring accurate storage of monetary values.\n",
    "\n",
    "- **`investment_in`** – The current value of the investment. Uses `DECIMAL(18, 2)` for high-precision financial data.\n",
    "\n",
    "- **`investment_in_prior`** – The value of the investment from a previous reporting period. Also uses `DECIMAL(18, 2)`.\n",
    "\n",
    "- **`currency`** – Stores the 3-letter currency code (e.g., USD, EUR). `VARCHAR(3)` allows up to 3 characters.\n",
    "\n",
    "- **`sector`** – Describes the investment's industry sector (e.g., \"Technology\", \"Government\"). `VARCHAR(100)` means it can store up to 100 characters.\n",
    "\n",
    "- **`risk_rating`** – Describes the risk level of the investment (e.g., \"Low\", \"Moderate\", \"High\"). `VARCHAR(50)` allows up to 50 characters.\n",
    "\n",
    "- **`maturity_date`** – Indicates when the investment is expected to mature. Uses the `DATE` type to store standard dates.\n",
    "\n",
    "- **`yield_percentage`** – Represents the investment's annual return rate (e.g., `4.25%`). `DECIMAL(6, 2)` allows up to 6 digits total, including 2 after the decimal point (max value `9999.99`).\n",
    "\n",
    "- **`isin`** - The ISIN (International Securities Identification Number) code for the asset. `VARCHAR(20)` supports standard ISIN formatting.\n",
    "\n",
    "- **`cusip`** - The CUSIP (Committee on Uniform Securities Identification Procedures) code, used for US securities. Stored as `VARCHAR(20)`.\n",
    "\n",
    "- **`asset_class`** - Describes the type of asset (e.g., equity, bond, real estate). `VARCHAR(50)` accommodates common classifications.\n",
    "\n",
    "- **`country`** - Country of risk, origin, or domicile for the asset. Stored as `VARCHAR(100)`.\n",
    "\n",
    "- **`region`** - Geographic or market region (e.g., \"North America\", \"EMEA\"). Also stored as `VARCHAR(100)`.\n",
    "\n",
    "- **`created_at`** – A timestamp showing when the record was first created. `TIMESTAMP DEFAULT CURRENT_TIMESTAMP` automatically stores the current time when a row is inserted.\n",
    "\n",
    "- **`updated_at`** – A timestamp for when the record was last updated. Also uses `TIMESTAMP DEFAULT CURRENT_TIMESTAMP`, but typically updated manually or via a trigger.\n",
    " \n",
    "---\n",
    "\n",
    "This schema ensures precise handling of financial data, proper storage of descriptive fields, and automatic tracking of when records are created and modified.\n",
    "\n",
    "#### Add Indexes for Performance \n",
    "\n",
    "To speed up queries, especially those filtering by date or investment name, create indexes:\n",
    "\n",
    "```sql\n",
    "CREATE INDEX idx_fnancial_data_as_of_date ON financial_data(as_of_date);\n",
    "CREATE INDEX idx_financial_data_security_name ON financial_data(original_security_name);\n",
    "```\n",
    "---\n",
    "\n",
    "#### Create a View for Statistics\n",
    "\n",
    "```sql\n",
    "CREATE OR REPLACE VIEW financial_data_stats AS\n",
    "SELECT\n",
    "    COUNT(*) AS total_records,\n",
    "\n",
    "    \n",
    "    SUM(CASE WHEN as_of_date IS NOT NULL THEN 1 ELSE 0 END) AS as_of_date_count,\n",
    "    SUM(CASE WHEN original_security_name IS NOT NULL THEN 1 ELSE 0 END) AS original_security_name_count,\n",
    "    SUM(CASE WHEN investment_in_original IS NOT NULL THEN 1 ELSE 0 END) AS investment_in_original_count,\n",
    "    SUM(CASE WHEN investment_in IS NOT NULL THEN 1 ELSE 0 END) AS investment_in_count,\n",
    "    SUM(CASE WHEN investment_in_prior IS NOT NULL THEN 1 ELSE 0 END) AS investment_in_prior_count,\n",
    "    SUM(CASE WHEN currency IS NOT NULL THEN 1 ELSE 0 END) AS currency_count,\n",
    "    COUNT(DISTINCT currency) AS currency_count_distinct,\n",
    "\n",
    "    -- Additional fields(not mandatory can be neglected for this assigment)\n",
    "    SUM(CASE WHEN sector IS NOT NULL THEN 1 ELSE 0 END) AS sector_count,\n",
    "    SUM(CASE WHEN risk_rating IS NOT NULL THEN 1 ELSE 0 END) AS risk_rating_count,\n",
    "    SUM(CASE WHEN maturity_date IS NOT NULL THEN 1 ELSE 0 END) AS maturity_date_count,\n",
    "    SUM(CASE WHEN yield_percentage IS NOT NULL THEN 1 ELSE 0 END) AS yield_percentage_count,\n",
    "    SUM(CASE WHEN isin IS NOT NULL THEN 1 ELSE 0 END) AS isin_count,\n",
    "    SUM(CASE WHEN cusip IS NOT NULL THEN 1 ELSE 0 END) AS cusip_count,\n",
    "    SUM(CASE WHEN asset_class IS NOT NULL THEN 1 ELSE 0 END) AS asset_class_count,\n",
    "    SUM(CASE WHEN country IS NOT NULL THEN 1 ELSE 0 END) AS country_count,\n",
    "    SUM(CASE WHEN region IS NOT NULL THEN 1 ELSE 0 END) AS region_count\n",
    "\n",
    "FROM financial_data;\n",
    "\n",
    "```\n",
    "This view helps verify data completeness and consistency, especially during extraction and validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1c2115-d49f-4408-a5d1-6be04e9e10eb",
   "metadata": {},
   "source": [
    "## **Project Imports Explanation**\r\n",
    "\r\n",
    "### Core Data Processing Libraries\r\n",
    "\r\n",
    "- `re`: Regular expressions library used to detect and extract patterns from unstructured text (e.g., field name variations).\r\n",
    "- `os`: Provides utilities for interacting with the file system, such as identifying file extensions or handling file paths.\r\n",
    "- `json`: Parses JSON input files and handles structured JSON configurations or data output.\r\n",
    "- `logging`: Standard Python logging module used for tracking events, errors, and execution flow in a structured format.\r\n",
    "- `typing` (`Dict`, `List`, `Any`, `Optional`): Enables type hints for improved readability and error checking in function definitions.\r\n",
    "- `datetime`: Handles and formats date and time data within documents and during data normalization.\r\n",
    "- `dataclasses` (`@dataclass`, `asdict`): Provides a clean syntax for creating structured objects to hold document metadata or parsed data records.\r\n",
    "\r\n",
    "### Data Handling and Transformation\r\n",
    "\r\n",
    "- `pandas` (as `pd`): A core library for data manipulation and analysis. Used extensively to transform extracted data, handle tabular formats, and prepare output for Excel or database storage.\r\n",
    "\r\n",
    "### Excel File Processing\r\n",
    "\r\n",
    "- `openpyxl`: Library for reading and writing `.xlsx` files.\r\n",
    "  - `Workbook`: Used to create and save Excel workbooks.\r\n",
    "  - `Font`, `PatternFill`, `Alignment`: Styling utilities to enhance the formatting and readability of Excel output.\r\n",
    "\r\n",
    "### Database Connectivity\r\n",
    "\r\n",
    "- `sqlalchemy`:\r\n",
    "  - `create_engine`, `text`: Creates connections to various databases (e.g., PostgreSQL, MySQL) and executes raw SQL for inserting or querying extracted data.\r\n",
    "\r\n",
    "### AI and Natural Language Processing\r\n",
    "\r\n",
    "- `openai`, `OpenAI`: Interfaces with OpenAI’s language models, enabling intelligent parsing, summarization, or contextual understanding of unstructured data in documents.\r\n",
    "\r\n",
    "### Document Parsing\r\n",
    "\r\n",
    "- `docx2txt`: Extracts raw text from `.docx` (Microsoft Word) documents for downstream processing.\r\n",
    "- `PyPDF2`: Parses and extracts textual content from PDF files, supporting analysis of semi-structured document formats.\r\n",
    "\r\n",
    "### Date Parsing\r\n",
    "\r\n",
    "- `dateutil.parser` (as `date_parser`): Provides robust date parsing capabilities to normalize inconsistent date formats tructured results to Excel or a database.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "693562c2-11c6-4608-a867-86a191c52204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import logging\n",
    "from typing import Dict, List, Any, Optional\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, asdict\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, PatternFill, Alignment\n",
    "from sqlalchemy import create_engine, text\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import docx2txt\n",
    "import PyPDF2\n",
    "from dateutil import parser as date_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed76ba5d-7783-4fa1-bdd1-2e32d45fed23",
   "metadata": {},
   "source": [
    "## **Configuration and Logging Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8350479c-e53e-4d87-a2ea-5d4643f4e423",
   "metadata": {},
   "source": [
    "### Logging Setup\n",
    "\n",
    "This section configures the logging system to capture INFO level messages and above (INFO, WARNING, ERROR, CRITICAL)\n",
    "Sets a consistent format for log messages that includes:\n",
    "- Timestamp (%(asctime)s)\n",
    "- Logger name (%(name)s)\n",
    "- Log level (%(levelname)s)\n",
    "- The actual message (%(message)s)\n",
    "\n",
    "Creates a root logger named 'ai_financial_extractor' that will be used throughout the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "806b1da7-3898-4dcc-a83f-136d025d78cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger('ai_financial_extractor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5d267f-42dd-4e30-bf95-a90df92ed7ce",
   "metadata": {},
   "source": [
    "## **CONFIG Dictionary Explanation**\r",
    "### NOTE: The OpenAI security key will not be included for security reasons and OpenAI policy breaking, for seperate testing please use your own keys\n",
    "\r\n",
    "The `CONFIG` dictionary centralizes all configurable settings for the AI-enhanced financial data extraction pipeline. It simplifies code maintenance by separating logic from parameters and includes sections for database connectivity, OpenAI model usage, and output preferences.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 1. `database`\r\n",
    "Defines the parameters required to connect to a PostgreSQL database:\r\n",
    "\r\n",
    "| Key        | Description                                        |\r\n",
    "|------------|----------------------------------------------------|\r\n",
    "| `type`     | Type of database system (`\"postgresql\"`)           |\r\n",
    "| `host`     | Database host address (`\"localhost\"`)              |\r\n",
    "| `port`     | Network port used by PostgreSQL (`5432`)           |\r\n",
    "| `database` | Name of the PostgreSQL database (`\"financial_data\"`)|\r\n",
    "| `user`     | Username for authenticating database access        |\r\n",
    "| `password` | Password for authenticating database access        |\r\n",
    "\r\n",
    "This section enables reading from or writing to the PostgreSQL database using tools like SQLAlchemy.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 2. `openai`\r\n",
    "Specifies how the application connects to and interacts with OpenAI's language models:\r\n",
    "\r\n",
    "| Key           | Description                                                                 |\r\n",
    "|----------------|-----------------------------------------------------------------------------|\r\n",
    "| `api_key`      | The secret API key used to authenticate requests to OpenAI’s API           |\r\n",
    "| `model`        | Specifies the model to use, e.g., `\"gpt-4o\"` for optimized GPT-4 Omni       |\r\n",
    "| `temperature`  | Controls randomness in responses. Low values (e.g., `0.1`) produce more consistent, predictable results, which is ideal for structured extraction tasks |\r\n",
    "\r\n",
    "This section empowers the script to use OpenAI models to interpret and extract structured information from unstructured documents (e.g., PDFs or Word files).\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 3. `output`\r\n",
    "Controls how and where the final extracted data will be saved:\r\n",
    "\r\n",
    "| Key          | Description                                                   |\r\n",
    "|---------------|---------------------------------------------------------------|\r\n",
    "| `excel_file`  | Name of the Excel file to save the AI-extracted data into     |\r\n",
    "\r\n",
    "The output is formatted and exported as an `.xlsx` file using `openpyxl` or `pandas`, depending on the implementation.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### Summary\r\n",
    "\r\n",
    "This configuration:\r\n",
    "- Enables **PostgreSQL database connectivity** without embedding credentials in the main logic.\r\n",
    "- Integrates with **OpenAI's LLM** for intelligent document parsing and data extraction.\r\n",
    "- Exports extracted data to a user-defined **Excel file**, ensuring results are accessible and well-formatted.\r\n",
    "\r\n",
    "By modifying this dictionary, users can easily switch databases, AI models, or output files without touching the core extraction code.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb6efe93-3be9-44c2-b789-597eb9ba1d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"database\": {\n",
    "        \"type\": \"postgresql\",\n",
    "        \"host\": \"localhost\",\n",
    "        \"port\": 5432,\n",
    "        \"database\": \"financial_data\",\n",
    "        \"user\": \"postgres\",\n",
    "        \"password\": \"SenkoSQL\"\n",
    "    },\n",
    "    \"openai\": {\n",
    "        \"api_key\": \"CANNOT_INPUT_MY_SECURITY_KEY_HERE_FOR_SECURITY_REASONS\", # Input your key if needed for testing\n",
    "        \"model\": \"gpt-4o\", \n",
    "        \"temperature\": 0.1  \n",
    "    },\n",
    "    \"output\": {\n",
    "        \"excel_file\": \"ai_extracted_financial_data.xlsx\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cc4962-5e36-4698-9826-8010c48913a7",
   "metadata": {},
   "source": [
    "## **`FinancialRecord` Data Class Explanation**\r\n",
    "\r\n",
    "The `FinancialRecord` class defines a structured container for holding extracted financial investment data. It uses Python’s `@dataclass` decorator to automatically generate an initializer, representation methods, and support for type hinting and serialization.\r\n",
    "\r\n",
    "This class ensures consistency and clarity when storing records parsed from various document sources (e.g., PDFs, Word files, Excel sheets).\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### Core Fields (Mandatory)\r\n",
    "\r\n",
    "These fields are typically required for financial reporting and analysis:\r\n",
    "\r\n",
    "| Field Name              | Type         | Description                                                   |\r\n",
    "|--------------------------|--------------|---------------------------------------------------------------|\r\n",
    "| `as_of_date`             | `Optional[str]`  | The valuation or reporting date of the investment             |\r\n",
    "| `original_security_name`| `Optional[str]`  | Name or identifier of the financial instrument                |\r\n",
    "| `investment_in_original`| `Optional[float]`| Initial investment value (acquisition or purchase cost)       |\r\n",
    "| `investment_in`         | `Optional[float]`| Current or most recent investment value                       |\r\n",
    "| `investment_in_prior`   | `Optional[float]`| Investment value in the previous period                       |\r\n",
    "| `currency`              | `Optional[str]`  | Currency in which the investment is denominated (e.g., USD)  |\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### Additional Fields (Enrichment & Classification)\r\n",
    "\r\n",
    "These fields provide further classification and context to enhance reporting or analytics:\r\n",
    "\r\n",
    "| Field Name         | Type              | Description                                                |\r\n",
    "|---------------------|-------------------|------------------------------------------------------------|\r\n",
    "| `sector`            | `Optional[str]`   | Economic or industry sector of the security                |\r\n",
    "| `risk_rating`       | `Optional[str]`   | Risk classification or rating for the investment           |\r\n",
    "| `maturity_date`     | `Optional[str]`   | Date on which the security matures (for bonds, etc.)       |\r\n",
    "| `yield_percentage`  | `Optional[float]` | Annualized return or yield expressed as a percentage       |\r\n",
    "| `isin`              | `Optional[str]`   | International Securities Identification Number             |\r\n",
    "| `cusip`             | `Optional[str]`   | U.S. security identifier (Committee on Uniform Securities Identification Procedures) |\r\n",
    "| `asset_class`       | `Optional[str]`   | Classification of the asset (e.g., equity, bond, real estate) |\r\n",
    "| `country`           | `Optional[str]`   | Country of risk or domicile of the issuer                  |\r\n",
    "| `region`            | `Optional[str]`   | Broader market or geographic region                        |\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### Summary\r\n",
    "\r\n",
    "The `FinancialRecord` class enables:\r\n",
    "- Clean and validated data storage for each extracted investment entry.\r\n",
    "- Consistent use across data parsing, transformation, and export stages.\r\n",
    "- Easy serialization to dictionaries or DataFrames using `asdict()` or similar.\r\n",
    "\r\n",
    "It provides a robust foundation for AI-assisted or rule-based data extraction pipelines.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8163af80-aedb-4113-8597-14a3ab9beb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FinancialRecord:\n",
    "    \"\"\"Data class representing a financial investment record\"\"\"\n",
    "    as_of_date: Optional[str] = None\n",
    "    original_security_name: Optional[str] = None\n",
    "    investment_in_original: Optional[float] = None\n",
    "    investment_in: Optional[float] = None\n",
    "    investment_in_prior: Optional[float] = None\n",
    "    currency: Optional[str] = None\n",
    "    # Additional fields\n",
    "    sector: Optional[str] = None\n",
    "    risk_rating: Optional[str] = None\n",
    "    maturity_date: Optional[str] = None\n",
    "    yield_percentage: Optional[float] = None\n",
    "    isin: Optional[str] = None\n",
    "    cusip: Optional[str] = None\n",
    "    asset_class: Optional[str] = None\n",
    "    country: Optional[str] = None\n",
    "    region: Optional[str] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb5f482-79ec-49e0-8f16-81d2e2d0ac10",
   "metadata": {},
   "source": [
    "# **AIDocumentExtractor Class - Explanation**\n",
    "\n",
    "The `AIDocumentExtractor` class provides an interface for extracting structured financial data from unstructured documents using OpenAI's language models (e.g., GPT-4o). It supports multiple document formats and converts text into structured JSON records by prompting the AI with a detailed schema.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Components:\n",
    "\n",
    "### 1. Initialization (`__init__`)\n",
    "- Initializes the class with an OpenAI API key and model name.\n",
    "- Sets up an OpenAI client via the `OpenAI` SDK.\n",
    "- Configures a logger for error reporting and tracking.\n",
    "- Default model is `\"gpt-4o\"` unless otherwise specified.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. `extract_text_from_file()`\n",
    "- Extracts raw text from the input file based on its extension:\n",
    "  - `.docx` → via `docx2txt`\n",
    "  - `.pdf` → reads all pages using `PyPDF2`\n",
    "  - `.txt` → standard UTF-8 file read\n",
    "  - `.csv` → converted into plain text table using `pandas.to_string()`\n",
    "  - `.json` → pretty-printed string via `json.dumps()`\n",
    "- Returns a unified, readable string ready for LLM input.\n",
    "- Logs and raises errors for unsupported file types or I/O issues.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. `extract_financial_data()`\n",
    "- Core method for extracting structured data using the LLM:\n",
    "  1. Extracts text using `extract_text_from_file()`.\n",
    "  2. Builds an extraction prompt with `_create_extraction_prompt()`.\n",
    "  3. Sends the prompt to the OpenAI API via `chat.completions.create()`.\n",
    "  4. Parses the JSON response using `_parse_ai_response()`.\n",
    "  5. Logs the number of successfully extracted records.\n",
    "- Returns a list of dictionaries representing cleaned investment records.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. `_create_extraction_prompt()`\n",
    "- Constructs a detailed prompt instructing the LLM to:\n",
    "  - Extract key financial fields.\n",
    "  - Format dates as `MM/DD/YYYY`.\n",
    "  - Remove currency symbols and commas from numbers.\n",
    "  - Output **valid JSON only** with no additional text or formatting.\n",
    "  - Omit missing fields and infer semantic equivalents (e.g., `\"Market Value\"` → `investment_in`).\n",
    "- Embeds the entire document’s text in the prompt as the final input.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. `_parse_ai_response()`\n",
    "- Extracts the AI's JSON response from the raw text:\n",
    "  - Finds the first `[` and last `]` to isolate the JSON array.\n",
    "  - Uses `json.loads()` to convert it to Python objects.\n",
    "  - Cleans each record using `_clean_record()`.\n",
    "- If JSON decoding fails, falls back to `_extract_json_fallback()` to salvage valid objects.\n",
    "- Logs raw responses and error messages if parsing fails.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. `_extract_json_fallback()`\n",
    "- A regex-based recovery method to parse `\"{...}\"` blocks from messy LLM outputs.\n",
    "- Iterates over matches and attempts `json.loads()` on each block.\n",
    "- Returns a list of valid JSON objects if any are found.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. `_clean_record()` \n",
    "- Standardizes and validates each record returned by the LLM: \n",
    "  - Maps common alternate field names to standardized ones (e.g., `\"yield_rate\"` → `yield_percentage`).\n",
    "  - Converts numeric fields to `float` (removing commas, symbols).\n",
    "  - Parses and formats date fields using `dateutil.parser`.\n",
    "  - Strips whitespace from all strings.\n",
    "- Returns a cleaned dictionary if at least one valid field is present.\n",
    "\n",
    "---\n",
    "\n",
    "## Extracted Financial Fields\n",
    "\n",
    "The LLM is prompted to extract the following key fields from any document WITH THEIR VARIATIONS:\n",
    "\n",
    "| Field Name               | Description                                      |\n",
    "|--------------------------|--------------------------------------------------|\n",
    "| `as_of_date`             | Valuation/reporting date (`MM/DD/YYYY`)         |\n",
    "| `original_security_name` | Name of the investment/security                 |\n",
    "| `investment_in_original` | Initial investment amount                        |\n",
    "| `investment_in`          | Current value of the investment                 |\n",
    "| `investment_in_prior`    | Previous period’s value                         |\n",
    "| `currency`               | 3-letter currency code (e.g., USD, EUR)         |\n",
    "| `sector`                 | Industry sector (e.g., Technology, Finance)     |\n",
    "| `risk_rating`            | Risk classification (Low, Medium, High)         |\n",
    "| `maturity_date`          | Expiry or maturity date (`MM/DD/YYYY`)          |\n",
    "| `yield_percentage`       | Annualized return percentage                    |\n",
    "| `isin`                   | International Securities Identification Number  |\n",
    "| `cusip`                  | U.S. securities identifier                      |\n",
    "| `asset_class`            | Type of asset (Bond, Equity, etc.)              |\n",
    "| `country`                | Country of issuance or origin                   |\n",
    "| `region`                 | Geographical or market region                   |\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "The `AIDocumentExtractor` class offers a modern and scalable solution for extracting complex structured data from financial documents. Its key benefits include:\n",
    "\n",
    "- Seamless integration with OpenAI's GPT models.\n",
    "- Support for diverse document formats and flexible layouts.\n",
    "- Automatic recognition of field variations and formatting inconsistencies.\n",
    "- Clean JSON output ideal for export to Excel, databases, or analytics tools.\n",
    "\n",
    "It is ideal for use cases involving varied document sources where traditional pattern-based extraction would be brittle or require constant maintenance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60213c66-c7f2-49f9-8a4f-36031704b25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIDocumentExtractor:\n",
    "    \"\"\"Extract financial data from documents using OpenAI's API\"\"\"\n",
    "    \n",
    "    def __init__(self, openai_api_key: str, model: str = \"gpt-4o\"):\n",
    "        self.client = OpenAI(api_key=openai_api_key)\n",
    "        self.model = model\n",
    "        self.logger = logging.getLogger(f'{__name__}.AIDocumentExtractor')\n",
    "        \n",
    "    def extract_text_from_file(self, file_path: str) -> str:\n",
    "        \"\"\"Extract text from various file formats\"\"\"\n",
    "        file_extension = os.path.splitext(file_path)[1].lower()\n",
    "        \n",
    "        try:\n",
    "            if file_extension == \".docx\":\n",
    "                return docx2txt.process(file_path)\n",
    "            elif file_extension == \".pdf\":\n",
    "                text = \"\"\n",
    "                with open(file_path, \"rb\") as file:\n",
    "                    pdf_reader = PyPDF2.PdfReader(file)\n",
    "                    for page in pdf_reader.pages:\n",
    "                        text += page.extract_text()\n",
    "                return text\n",
    "            elif file_extension == \".txt\":\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as file:\n",
    "                    return file.read()\n",
    "            elif file_extension == \".csv\":\n",
    "                # For CSV, we'll convert to a readable format for the LLM\n",
    "                df = pd.read_csv(file_path)\n",
    "                return df.to_string()\n",
    "            elif file_extension == \".json\":\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                    data = json.load(file)\n",
    "                    return json.dumps(data, indent=2)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported file format: {file_extension}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error extracting text from {file_path}: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def extract_financial_data(self, file_path: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Extract financial data using AI\"\"\"\n",
    "        self.logger.info(f\"Starting AI extraction for {file_path}\")\n",
    "        \n",
    "        document_text = self.extract_text_from_file(file_path)\n",
    "        \n",
    "        # Create the extraction prompt\n",
    "        prompt = self._create_extraction_prompt(document_text)\n",
    "        \n",
    "        try:\n",
    "            # Call OpenAI API\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an expert financial data analyst specializing in extracting structured data from financial documents.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=CONFIG[\"openai\"][\"temperature\"]\n",
    "            )\n",
    "            \n",
    "            # Parse the response\n",
    "            extracted_data = self._parse_ai_response(response.choices[0].message.content)\n",
    "            \n",
    "            self.logger.info(f\"Successfully extracted {len(extracted_data)} records using AI\")\n",
    "            return extracted_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in AI extraction: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _create_extraction_prompt(self, document_text: str) -> str:\n",
    "        \"\"\"Create a detailed prompt for the AI to extract financial data\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "Please analyze the following financial document and extract all investment records. \n",
    "Return the data as a JSON array where each object represents one investment record.\n",
    "\n",
    "For each record, extract the following fields (if available):\n",
    "- as_of_date: The date when the data was recorded (format as MM/DD/YYYY)\n",
    "- original_security_name: The name of the investment/security\n",
    "- investment_in_original: Original investment amount (as a number, no currency symbols)\n",
    "- investment_in: Current investment value (as a number, no currency symbols)\n",
    "- investment_in_prior: Previous period investment value (as a number, no currency symbols)\n",
    "- currency: Three-letter currency code (e.g., USD, EUR)\n",
    "- sector: Investment sector (e.g., Technology, Government)\n",
    "- risk_rating: Risk level (e.g., Low, Moderate, High)\n",
    "- maturity_date: When the investment matures (format as MM/DD/YYYY)\n",
    "- yield_percentage: Yield or return percentage (as a number without % sign)\n",
    "- isin: ISIN code if available\n",
    "- cusip: CUSIP code if available\n",
    "- asset_class: Type of asset (e.g., Bond, Equity)\n",
    "- country: Country of origin\n",
    "- region: Geographic region\n",
    "\n",
    "IMPORTANT RULES:\n",
    "1. Only include fields that are actually present in the document\n",
    "2. Convert all dates to MM/DD/YYYY format\n",
    "3. Extract numeric values without currency symbols or commas\n",
    "4. If a field is not found, omit it from the record\n",
    "5. Look for variations in field names (e.g., \"Market Value\" might mean \"investment_in\")\n",
    "6. Return valid JSON only, no additional text\n",
    "\n",
    "Document to analyze:\n",
    "\n",
    "{document_text}\n",
    "\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def _parse_ai_response(self, response_text: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Parse the AI response into structured data\"\"\"\n",
    "        try:\n",
    "            # Clean the response text to extract JSON\n",
    "            json_start = response_text.find('[')\n",
    "            json_end = response_text.rfind(']') + 1\n",
    "            json_text = response_text[json_start:json_end]\n",
    "            \n",
    "            # Parse JSON\n",
    "            extracted_data = json.loads(json_text)\n",
    "            \n",
    "            # Validate and clean the data\n",
    "            cleaned_data = []\n",
    "            for record in extracted_data:\n",
    "                cleaned_record = self._clean_record(record)\n",
    "                if cleaned_record:\n",
    "                    cleaned_data.append(cleaned_record)\n",
    "            \n",
    "            return cleaned_data\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            self.logger.error(f\"Error parsing AI response as JSON: {str(e)}\")\n",
    "            self.logger.debug(f\"Raw response: {response_text}\")\n",
    "            # Attempt to extract JSON using regex as fallback\n",
    "            return self._extract_json_fallback(response_text)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing AI response: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _extract_json_fallback(self, text: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Fallback method to extract JSON from response\"\"\"\n",
    "        try:\n",
    "            # Try to find JSON objects in the text\n",
    "            json_objects = re.findall(r'\\{[^{}]*\\}', text)\n",
    "            results = []\n",
    "            for obj_str in json_objects:\n",
    "                try:\n",
    "                    obj = json.loads(obj_str)\n",
    "                    results.append(obj)\n",
    "                except:\n",
    "                    continue\n",
    "            return results if results else []\n",
    "        except:\n",
    "            return []\n",
    "    \n",
    "    def _clean_record(self, record: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Clean and validate a single record\"\"\"\n",
    "        cleaned = {}\n",
    "        \n",
    "        # Map of field conversions\n",
    "        field_mapping = {\n",
    "            # Original security name\n",
    "            'security_name': 'original_security_name',\n",
    "            'instrument_name': 'original_security_name',\n",
    "            'asset_name': 'original_security_name',\n",
    "            'investment_name': 'original_security_name',\n",
    "        \n",
    "            # Original investment amount\n",
    "            'original_investment': 'investment_in_original',\n",
    "            'initial_investment': 'investment_in_original',\n",
    "            'amount_invested': 'investment_in_original',\n",
    "            'purchase_amount': 'investment_in_original',\n",
    "        \n",
    "            # Current investment value\n",
    "            'market_value': 'investment_in',\n",
    "            'current_value': 'investment_in',\n",
    "            'value_as_of': 'investment_in',\n",
    "            'valuation': 'investment_in',\n",
    "        \n",
    "            # Previous investment value\n",
    "            'previous_value': 'investment_in_prior',\n",
    "            'prior_value': 'investment_in_prior',\n",
    "            'last_period_value': 'investment_in_prior',\n",
    "            'previous_market_value': 'investment_in_prior',\n",
    "        \n",
    "            # Yield / return %\n",
    "            'yield': 'yield_percentage',\n",
    "            'yield_rate': 'yield_percentage',\n",
    "            'annual_yield': 'yield_percentage',\n",
    "            'interest_rate': 'yield_percentage',\n",
    "            'rate_of_return': 'yield_percentage',\n",
    "        \n",
    "            # Currency\n",
    "            'currency_code': 'currency',\n",
    "            'base_currency': 'currency',\n",
    "        \n",
    "            # Risk\n",
    "            'risk_level': 'risk_rating',\n",
    "            'risk': 'risk_rating',\n",
    "        \n",
    "            # Dates\n",
    "            'report_date': 'as_of_date',\n",
    "            'valuation_date': 'as_of_date',\n",
    "            'trade_date': 'as_of_date',\n",
    "            'asof': 'as_of_date',\n",
    "        \n",
    "            'maturity': 'maturity_date',\n",
    "            'maturity_dt': 'maturity_date',\n",
    "        \n",
    "            # Asset class\n",
    "            'investment_type': 'asset_class',\n",
    "            'asset_type': 'asset_class',\n",
    "        \n",
    "            # Identifiers\n",
    "            'isin_code': 'isin',\n",
    "            'cusip_code': 'cusip',\n",
    "        \n",
    "            # Geography\n",
    "            'domicile': 'country',\n",
    "            'region_name': 'region',\n",
    "            'country_of_issue': 'country'\n",
    "        }\n",
    "        \n",
    "        # Clean and map fields\n",
    "        for key, value in record.items():\n",
    "            # Normalize key name\n",
    "            clean_key = field_mapping.get(key.lower(), key.lower())\n",
    "            \n",
    "            # Clean and convert values\n",
    "            if value is not None and value != \"\":\n",
    "                if clean_key in ['investment_in_original', 'investment_in', 'investment_in_prior', 'yield_percentage']:\n",
    "                    # Convert to float, removing any non-numeric characters except decimal point\n",
    "                    try:\n",
    "                        cleaned_value = re.sub(r'[^\\d.-]', '', str(value))\n",
    "                        cleaned[clean_key] = float(cleaned_value) if cleaned_value else None\n",
    "                    except:\n",
    "                        cleaned[clean_key] = None\n",
    "                elif clean_key in ['as_of_date', 'maturity_date']:\n",
    "                    # Format dates\n",
    "                    try:\n",
    "                        if isinstance(value, str) and value.lower() not in ['n/a', 'na', 'none']:\n",
    "                            date_obj = date_parser.parse(value, fuzzy=True)\n",
    "                            cleaned[clean_key] = date_obj.strftime('%m/%d/%Y')\n",
    "                        else:\n",
    "                            cleaned[clean_key] = value\n",
    "                    except:\n",
    "                        cleaned[clean_key] = value\n",
    "                else:\n",
    "                    cleaned[clean_key] = str(value).strip()\n",
    "        \n",
    "        # Only return records with at least one meaningful field\n",
    "        return cleaned if len(cleaned) > 0 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b99c14-15be-4514-a2fe-eb5a7336d188",
   "metadata": {},
   "source": [
    "# **AIDataProcessor Class - Explanation**\r\n",
    "\r\n",
    "The `AIDataProcessor` class processes raw AI-extracted financial records and:\r\n",
    "- Converts dictionary records into typed `FinancialRecord` objects\r\n",
    "- Calculates completeness of mandatory fields\r\n",
    "- Identifies missing data and inconsistencies\r\n",
    "- Computes extraction accuracy metrics\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## Key Methods\r\n",
    "\r\n",
    "### 1. `__init__(self)`\r\n",
    "Initializes the processor:\r\n",
    "- Sets up a logger for internal logging and debugging\r\n",
    "- Defines a list of `mandatory_fields` required for completeness:\r\n",
    "  - `as_of_date`\r\n",
    "  - `original_security_name`\r\n",
    "  - `investment_in_original`\r\n",
    "  - `investment_in`\r\n",
    "  - `investment_in_prior`\r\n",
    "  - `currency`\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 2. `process_data(raw_data)`\r\n",
    "Converts raw dictionaries into `FinancialRecord` objects.\r\n",
    "\r\n",
    "- Iterates through `raw_data`, attempting to unpack each dictionary into a `FinancialRecord`.\r\n",
    "- Skips and logs any item that fails to convert due to missing or invalid fields.\r\n",
    "- Returns a list of valid, structured `FinancialRecord` objects.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 3. `calculate_statistics(records)`\r\n",
    "Analyzes the given list of `FinancialRecord` objects and returns a detailed report with:\r\n",
    "\r\n",
    "- `total_records`: Number of processed records\r\n",
    "- `extraction_accuracy`: Percentage of mandatory fields filled across all records\r\n",
    "- `mandatory_field_completeness`: Count and completeness % for each required field\r\n",
    "- `field_presence`: How often each field (mandatory or optional) appears\r\n",
    "- `missing_fields`: Which mandatory fields are missing, and how often\r\n",
    "- `inconsistent_data`: Any inconsistencies found across the dataset:\r\n",
    "  - Multiple currencies\r\n",
    "  - Mixed date formats\r\n",
    "\r\n",
    "The accuracy is computed as:\r\n",
    "- `(total filled mandatory fields) / (total expected mandatory fields) * 100`\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 4. `_identify_date_format(date_str)`\r\n",
    "A helper method that uses regular expressions to infer the format of a date string.\r\n",
    "\r\n",
    "Possible outputs include:\r\n",
    "- `\"MM/DD/YYYY\"`\r\n",
    "- `\"YYYY-MM-DD\"`\r\n",
    "- `\"Month DD, YYYY\"`\r\n",
    "- `\"Unknown format\"`\r\n",
    "\r\n",
    "Used internally during inconsistency checks to validate date format consistency across records.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## Summary\r\n",
    "The `AIDataProcessor` class plays a key role in the post-AI validation pipeline. It transforms AI output into structured objects, computes quality metrics, and flags missing or inconsistent information.\r\n",
    "\r\n",
    "It ensures that:\r\n",
    "- Mandatory fields are reliably filled\r\n",
    "- The dataset maintains consistency in key attributes (like currency or dates)\r\n",
    "- Users receive actionable insights on the overall quality of the AI-based extraction process\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "933fab31-c107-4760-a93c-4c2222e2417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIDataProcessor:\n",
    "    \"\"\"Process and validate AI-extracted data\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(f'{__name__}.AIDataProcessor')\n",
    "        self.mandatory_fields = [\n",
    "            'as_of_date', 'original_security_name', 'investment_in_original',\n",
    "            'investment_in', 'investment_in_prior', 'currency'\n",
    "        ]\n",
    "    \n",
    "    def process_data(self, raw_data: List[Dict[str, Any]]) -> List[FinancialRecord]:\n",
    "        \"\"\"Convert raw data to FinancialRecord objects\"\"\"\n",
    "        records = []\n",
    "        \n",
    "        for item in raw_data:\n",
    "            try:\n",
    "                # Convert to FinancialRecord\n",
    "                record = FinancialRecord(**item)\n",
    "                records.append(record)\n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"Error creating record from {item}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        self.logger.info(f\"Processed {len(records)} records\")\n",
    "        return records\n",
    "    \n",
    "    def calculate_statistics(self, records: List[FinancialRecord]) -> Dict[str, Any]:\n",
    "        \"\"\"Calculate extraction statistics\"\"\"\n",
    "        total_records = len(records)\n",
    "        if total_records == 0:\n",
    "            return {\n",
    "                'total_records': 0,\n",
    "                'extraction_accuracy': 0,\n",
    "                'mandatory_field_completeness': {},\n",
    "                'field_presence': {},\n",
    "                'missing_fields': [],\n",
    "                'inconsistent_data': []\n",
    "            }\n",
    "        \n",
    "        # Count field presence\n",
    "        field_counts = {}\n",
    "        for record in records:\n",
    "            record_dict = asdict(record)\n",
    "            for field, value in record_dict.items():\n",
    "                if value is not None:\n",
    "                    field_counts[field] = field_counts.get(field, 0) + 1\n",
    "        \n",
    "        # Calculate mandatory field completeness\n",
    "        mandatory_completeness = {}\n",
    "        missing_fields = []\n",
    "        for field in self.mandatory_fields:\n",
    "            count = field_counts.get(field, 0)\n",
    "            percentage = (count / total_records) * 100\n",
    "            mandatory_completeness[field] = {\n",
    "                'count': count,\n",
    "                'percentage': percentage\n",
    "            }\n",
    "            if count < total_records:\n",
    "                missing_fields.append(f\"{field} ({total_records - count} missing)\")\n",
    "        \n",
    "        # Check for inconsistencies\n",
    "        inconsistencies = []\n",
    "        currencies = set()\n",
    "        date_formats = set()\n",
    "        \n",
    "        for record in records:\n",
    "            if record.currency:\n",
    "                currencies.add(record.currency)\n",
    "            if record.as_of_date:\n",
    "                date_formats.add(self._identify_date_format(record.as_of_date))\n",
    "        \n",
    "        if len(currencies) > 1:\n",
    "            inconsistencies.append(f\"Multiple currencies: {', '.join(currencies)}\")\n",
    "        if len(date_formats) > 1:\n",
    "            inconsistencies.append(f\"Multiple date formats: {', '.join(date_formats)}\")\n",
    "        \n",
    "        # Calculate overall accuracy\n",
    "        total_mandatory_fields = len(self.mandatory_fields) * total_records\n",
    "        filled_mandatory_fields = sum(counts['count'] for counts in mandatory_completeness.values())\n",
    "        accuracy = (filled_mandatory_fields / total_mandatory_fields) * 100 if total_mandatory_fields > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'total_records': total_records,\n",
    "            'extraction_accuracy': accuracy,\n",
    "            'mandatory_field_completeness': mandatory_completeness,\n",
    "            'field_presence': field_counts,\n",
    "            'missing_fields': missing_fields,\n",
    "            'inconsistent_data': inconsistencies\n",
    "        }\n",
    "    \n",
    "    def _identify_date_format(self, date_str: str) -> str:\n",
    "        \"\"\"Identify the format of a date string\"\"\"\n",
    "        if re.match(r'\\d{1,2}/\\d{1,2}/\\d{4}', date_str):\n",
    "            return \"MM/DD/YYYY\"\n",
    "        elif re.match(r'\\d{4}-\\d{1,2}-\\d{1,2}', date_str):\n",
    "            return \"YYYY-MM-DD\"\n",
    "        elif re.match(r'[A-Za-z]+ \\d{1,2},?\\s+\\d{4}', date_str):\n",
    "            return \"Month DD, YYYY\"\n",
    "        return \"Unknown format\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8449a88a-6988-42b9-8619-7a52cd95eaf9",
   "metadata": {},
   "source": [
    "# **AIDataStorage Class - Explanation**\r\n",
    "\r\n",
    "The `AIDataStorage` class handles storing AI-processed financial data into two destinations:\r\n",
    "1. A PostgreSQL database using SQLAlchemy\r\n",
    "2. An Excel workbook with formatted data and extraction statistics\r\n",
    "\r\n",
    "It manages data persistence, error handling, logging, and presentation formatting for both outputs.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## Key Components\r\n",
    "\r\n",
    "### 1. `__init__(self, db_config, excel_file)`\r\n",
    "Initializes with:\r\n",
    "- `db_config`: A dictionary containing PostgreSQL connection details (host, port, user, password, database).\r\n",
    "- `excel_file`: Path to the Excel output file.\r\n",
    "- Sets up a logger for tracking export operations.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 2. `store_in_database(records)`\r\n",
    "Stores the list of `FinancialRecord` objects into a PostgreSQL table:\r\n",
    "- Converts records to a `pandas` DataFrame.\r\n",
    "- Creates a database connection using SQLAlchemy.\r\n",
    "- Drops any existing table or view (`ai_financial_data` and `ai_financial_data_stats`) to ensure schema consistency.\r\n",
    "- Uploads the data using `df.to_sql()` into the `ai_financial_data` table.\r\n",
    "- Creates a statistics view (`ai_financial_data_stats`) using `_create_stats_view()`.\r\n",
    "\r\n",
    "Returns `True` on success or `False` if any error occurs.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 3. `_create_stats_view(engine)`\r\n",
    "Creates a PostgreSQL view named `ai_financial_data_stats` that:\r\n",
    "- Counts total records.\r\n",
    "- Counts how many records have non-null values for each mandatory field.\r\n",
    "- Counts the number of distinct currencies in the dataset.\r\n",
    "\r\n",
    "This view allows quick insights directly from the database.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 4. `store_in_excel(records, stats)`\r\n",
    "Writes extracted data and calculated statistics to an Excel file:\r\n",
    "- Sheet 1: `Extracted Data` → All `FinancialRecord` entries.\r\n",
    "- Sheet 2: `Statistics` → Summary metrics such as:\r\n",
    "  - Total records\r\n",
    "  - Extraction accuracy\r\n",
    "  - List of missing fields\r\n",
    "  - Inconsistencies (e.g., currency/date issues)\r\n",
    "  - Completeness of each mandatory field\r\n",
    "\r\n",
    "It applies formatting via `_format_excel()` and returns `True` on success.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### 5. `_format_excel(writer)`\r\n",
    "Applies visual enhancements using `openpyxl`:\r\n",
    "- Bold headers with light gray fill.\r\n",
    "- Center-aligned header cells.\r\n",
    "- Automatically adjusts column widths for all sheets.\r\n",
    "- Applies formatting to both `Extracted Data` and `Statistics` sheets to improve readability.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## Summary\r\n",
    "The `AIDataStorage` class finalizes the AI extraction pipeline by:\r\n",
    "- Persisting structured data to a relational database.\r\n",
    "- Creating a view for database-level statistics.\r\n",
    "- Exporting a clean, readable Excel file with both raw data and key metrics.\r\n",
    "\r\n",
    "It ensures the extracted data is not only preserved, but also organized and ready for analysis or reporting in downstream systems.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9f2451d-ef50-47b0-ad96-39ab21319b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIDataStorage:\n",
    "    \"\"\"Store processed data in database and Excel\"\"\"\n",
    "    \n",
    "    def __init__(self, db_config: Dict[str, Any], excel_file: str):\n",
    "        self.db_config = db_config\n",
    "        self.excel_file = excel_file\n",
    "        self.logger = logging.getLogger(f'{__name__}.AIDataStorage')\n",
    "    \n",
    "    def store_in_database(self, records: List[FinancialRecord]) -> bool:\n",
    "        \"\"\"Store records in PostgreSQL database\"\"\"\n",
    "        try:\n",
    "            # Convert records to DataFrame\n",
    "            df = pd.DataFrame([asdict(record) for record in records])\n",
    "            \n",
    "            # Create database connection\n",
    "            connection_string = (f\"postgresql://{self.db_config['user']}:{self.db_config['password']}\"\n",
    "                               f\"@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}\")\n",
    "            engine = create_engine(connection_string)\n",
    "            \n",
    "            # Drop existing table/view\n",
    "            with engine.connect() as connection:\n",
    "                connection.execute(text(\"DROP VIEW IF EXISTS ai_financial_data_stats CASCADE;\"))\n",
    "                connection.execute(text(\"DROP TABLE IF EXISTS ai_financial_data CASCADE;\"))\n",
    "                connection.commit()\n",
    "            \n",
    "            # Store data\n",
    "            df.to_sql('ai_financial_data', engine, if_exists='replace', index=False)\n",
    "            \n",
    "            # Create statistics view\n",
    "            self._create_stats_view(engine)\n",
    "            \n",
    "            self.logger.info(f\"Successfully stored {len(records)} records in database\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Database storage error: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def _create_stats_view(self, engine):\n",
    "        \"\"\"Create database view with statistics\"\"\"\n",
    "        view_sql = \"\"\"\n",
    "        CREATE OR REPLACE VIEW ai_financial_data_stats AS\n",
    "        SELECT\n",
    "            COUNT(*) AS total_records,\n",
    "            SUM(CASE WHEN as_of_date IS NOT NULL THEN 1 ELSE 0 END) AS as_of_date_count,\n",
    "            SUM(CASE WHEN original_security_name IS NOT NULL THEN 1 ELSE 0 END) AS original_security_name_count,\n",
    "            SUM(CASE WHEN investment_in_original IS NOT NULL THEN 1 ELSE 0 END) AS investment_in_original_count,\n",
    "            SUM(CASE WHEN investment_in IS NOT NULL THEN 1 ELSE 0 END) AS investment_in_count,\n",
    "            SUM(CASE WHEN investment_in_prior IS NOT NULL THEN 1 ELSE 0 END) AS investment_in_prior_count,\n",
    "            SUM(CASE WHEN currency IS NOT NULL THEN 1 ELSE 0 END) AS currency_count,\n",
    "            COUNT(DISTINCT currency) AS distinct_currencies\n",
    "        FROM ai_financial_data;\n",
    "        \"\"\"\n",
    "        \n",
    "        with engine.connect() as connection:\n",
    "            connection.execute(text(view_sql))\n",
    "            connection.commit()\n",
    "    \n",
    "    def store_in_excel(self, records: List[FinancialRecord], stats: Dict[str, Any]) -> bool:\n",
    "        \"\"\"Store records and statistics in Excel file\"\"\"\n",
    "        try:\n",
    "            # Convert records to DataFrame\n",
    "            df = pd.DataFrame([asdict(record) for record in records])\n",
    "            \n",
    "            # Create Excel writer\n",
    "            with pd.ExcelWriter(self.excel_file, engine='openpyxl') as writer:\n",
    "                # Write data sheet\n",
    "                df.to_excel(writer, sheet_name='Extracted Data', index=False)\n",
    "                \n",
    "                # Create statistics DataFrame\n",
    "                stats_data = {\n",
    "                    'Metric': [\n",
    "                        'Total Records',\n",
    "                        'Overall Extraction Accuracy (%)',\n",
    "                        'Missing Fields',\n",
    "                        'Inconsistent Data'\n",
    "                    ],\n",
    "                    'Value': [\n",
    "                        stats['total_records'],\n",
    "                        f\"{stats['extraction_accuracy']:.2f}%\",\n",
    "                        ', '.join(stats['missing_fields']) if stats['missing_fields'] else 'None',\n",
    "                        ', '.join(stats['inconsistent_data']) if stats['inconsistent_data'] else 'None'\n",
    "                    ]\n",
    "                }\n",
    "                \n",
    "                # Add mandatory field completeness\n",
    "                for field, completeness in stats['mandatory_field_completeness'].items():\n",
    "                    stats_data['Metric'].append(f'{field} completeness')\n",
    "                    stats_data['Value'].append(f\"{completeness['count']}/{stats['total_records']} ({completeness['percentage']:.1f}%)\")\n",
    "                \n",
    "                stats_df = pd.DataFrame(stats_data)\n",
    "                stats_df.to_excel(writer, sheet_name='Statistics', index=False)\n",
    "                \n",
    "                # Apply formatting\n",
    "                self._format_excel(writer)\n",
    "            \n",
    "            self.logger.info(f\"Successfully stored data in Excel file: {self.excel_file}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Excel storage error: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def _format_excel(self, writer):\n",
    "        \"\"\"Apply formatting to Excel file\"\"\"\n",
    "        workbook = writer.book\n",
    "        \n",
    "        # Format data sheet\n",
    "        worksheet = workbook['Extracted Data']\n",
    "        for cell in worksheet[1]:\n",
    "            cell.font = Font(bold=True)\n",
    "            cell.fill = PatternFill(start_color=\"DDDDDD\", end_color=\"DDDDDD\", fill_type=\"solid\")\n",
    "            cell.alignment = Alignment(horizontal='center')\n",
    "        \n",
    "        # Format statistics sheet\n",
    "        worksheet = workbook['Statistics']\n",
    "        for cell in worksheet[1]:\n",
    "            cell.font = Font(bold=True)\n",
    "            cell.fill = PatternFill(start_color=\"DDDDDD\", end_color=\"DDDDDD\", fill_type=\"solid\")\n",
    "            cell.alignment = Alignment(horizontal='center')\n",
    "        \n",
    "        # Adjust column widths\n",
    "        for sheet_name in ['Extracted Data', 'Statistics']:\n",
    "            worksheet = workbook[sheet_name]\n",
    "            for column in worksheet.columns:\n",
    "                max_length = 0\n",
    "                column_letter = column[0].column_letter\n",
    "                for cell in column:\n",
    "                    try:\n",
    "                        if len(str(cell.value)) > max_length:\n",
    "                            max_length = len(str(cell.value))\n",
    "                    except:\n",
    "                        pass\n",
    "                worksheet.column_dimensions[column_letter].width = max(max_length + 2, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1550e1a-de7a-4d69-b0c9-6b31b61326ef",
   "metadata": {},
   "source": [
    "# **Explanation for create_sample_financial_document() and main_ai_extraction()**\r\n",
    "\r\n",
    "This code defines two utility functions that together serve to:\r\n",
    "- **Generate synthetic financial documents** for testing the AI extraction pipeline\r\n",
    "- **Run the complete AI-powered ETL process**, including extraction, validation, storage, and reporting\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## Function: `create_sample_financial_document(doc_type=\"txt\")`\r\n",
    "\r\n",
    "Creates a synthetic financial document for use in testing the AI extraction workflow.\r\n",
    "\r\n",
    "### Supported formats:\r\n",
    "- **`\"txt\"`**: Simulates a manually written financial report with multiple investment entries and human-style formatting.\r\n",
    "- **`\"csv\"`**: Tabular format with standardized column headers, useful for structured data extraction.\r\n",
    "- **`\"json\"`**: Structured format representing investments as objects in a list, including nested fields such as `maturity_date` or `yield_percentage`.\r\n",
    "\r\n",
    "### Output:\r\n",
    "- Saves the document locally under a format-specific filename:\r\n",
    "  - `\"sample_financial_report.txt\"`\r\n",
    "  - `\"sample_financial_data.csv\"`\r\n",
    "  - `\"sample_financial_data.json\"`\r\n",
    "- Returns the file path string of the created sample document.\r\n",
    "\r\n",
    "This function is essential for:\r\n",
    "- Simulating real-world file inputs\r\n",
    "- Testing the robustness of the extraction logic\r\n",
    "- Validating AI performance against consistent, known data\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## Function: `main_ai_extraction(file_path, openai_api_key)`\r\n",
    "\r\n",
    "This is the main controller function that coordinates the **AI-based financial data extraction pipeline** from start to finish.\r\n",
    "\r\n",
    "### Step-by-step flow:\r\n",
    "\r\n",
    "#### 1. **Extraction**\r\n",
    "- Initializes an instance of `AIDocumentExtractor` with the OpenAI API key and configured model.\r\n",
    "- Reads and processes the document using OpenAI to extract raw structured data.\r\n",
    "\r\n",
    "#### 2. **Processing**\r\n",
    "- Initializes `AIDataProcessor` to:\r\n",
    "  - Convert raw dictionaries into `FinancialRecord` objects\r\n",
    "  - Compute statistics such as field completeness and consistency\r\n",
    "  - Identify missing values and discrepancies\r\n",
    "\r\n",
    "#### 3. **Storage**\r\n",
    "- Initializes `AIDataStorage` with database and Excel configuration.\r\n",
    "- Stores the processed records:\r\n",
    "  - In a PostgreSQL database table (`ai_financial_data`)\r\n",
    "  - In an Excel file with a summary statistics sheet\r\n",
    "\r\n",
    "#### 4. **Reporting**\r\n",
    "- Logs the following results:\r\n",
    "  - Total records extracted\r\n",
    "  - Extraction accuracy (based on filled mandatory fields)\r\n",
    "  - Missing fields (if any)\r\n",
    "  - Inconsistencies (e.g., multiple currencies or date formats)\r\n",
    "  - Status of database and Excel exports\r\n",
    "\r\n",
    "### Error Handling:\r\n",
    "- All major steps are wrapped in a try-except block.\r\n",
    "- Any failure (e.g., API issues, file errors, DB connection problems) is caught and logged.\r\n",
    "- Returns `True` on full pipeline success or `False` on any error.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## Summary\r\n",
    "\r\n",
    "These two functions are key components for both:\r\n",
    "- **Testing**: `create_sample_financial_document()` provides test documents in multiple formats and structures.\r\n",
    "- **Production-like Execution**: `main_ai_extraction()` runs the full AI-driven ETL pipeline including:\r\n",
    "  - OpenAI-based data extraction\r\n",
    "  - Record validation and statistics\r\n",
    "  - Exporting to both SQL and Excel with logging\r\n",
    "\r\n",
    "They are designed to ensure the pipeline can be validated, maintained, and operated end-to-end with minimal manual intervention.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ac7e1b6-2167-4829-a59b-62788aac66b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_financial_document(doc_type: str = \"txt\") -> str:\n",
    "    \"\"\"Create sample financial documents for testing\"\"\"\n",
    "    if doc_type == \"txt\":\n",
    "        content = \"\"\"Financial Investment Report\n",
    "Date: March 31, 2024\n",
    "\n",
    "PORTFOLIO SUMMARY\n",
    "\n",
    "Investment 1:\n",
    "Security Name: Apple Inc. Common Stock\n",
    "Original Investment: $50,000.00\n",
    "Current Market Value: $57,500.00\n",
    "Prior Quarter Value: $52,000.00\n",
    "Currency: USD\n",
    "Sector: Technology\n",
    "Risk Rating: Moderate\n",
    "Yield: 0.50%\n",
    "\n",
    "Investment 2:\n",
    "Security Name: US Treasury Bond 2030\n",
    "Original Investment: $100,000.00\n",
    "Current Market Value: $98,500.00\n",
    "Prior Quarter Value: $99,200.00\n",
    "Currency: USD\n",
    "Sector: Government\n",
    "Risk Rating: Low\n",
    "Maturity Date: 12/31/2030\n",
    "Yield: 4.25%\n",
    "\n",
    "Investment 3:\n",
    "Security Name: Emerging Markets ETF\n",
    "Original Investment: $25,000.00\n",
    "Current Market Value: $27,800.00\n",
    "Prior Quarter Value: $26,100.00\n",
    "Currency: USD\n",
    "Sector: International\n",
    "Risk Rating: High\n",
    "Yield: 2.85%\n",
    "\"\"\"\n",
    "        filename = \"sample_financial_report.txt\"\n",
    "        \n",
    "    elif doc_type == \"csv\":\n",
    "        content = \"\"\"Security Name,Original Investment,Current Value,Prior Value,Currency,Sector,Risk Rating,Yield %\n",
    "Apple Inc. Common Stock,50000,57500,52000,USD,Technology,Moderate,0.50\n",
    "US Treasury Bond 2030,100000,98500,99200,USD,Government,Low,4.25\n",
    "Emerging Markets ETF,25000,27800,26100,USD,International,High,2.85\n",
    "\"\"\"\n",
    "        filename = \"sample_financial_data.csv\"\n",
    "        \n",
    "    elif doc_type == \"json\":\n",
    "        data = {\n",
    "            \"report_date\": \"2024-03-31\",\n",
    "            \"investments\": [\n",
    "                {\n",
    "                    \"security_name\": \"Apple Inc. Common Stock\",\n",
    "                    \"original_investment\": 50000,\n",
    "                    \"current_value\": 57500,\n",
    "                    \"prior_value\": 52000,\n",
    "                    \"currency\": \"USD\",\n",
    "                    \"sector\": \"Technology\",\n",
    "                    \"risk_rating\": \"Moderate\",\n",
    "                    \"yield_percentage\": 0.50\n",
    "                },\n",
    "                {\n",
    "                    \"security_name\": \"US Treasury Bond 2030\",\n",
    "                    \"original_investment\": 100000,\n",
    "                    \"current_value\": 98500,\n",
    "                    \"prior_value\": 99200,\n",
    "                    \"currency\": \"USD\",\n",
    "                    \"sector\": \"Government\",\n",
    "                    \"risk_rating\": \"Low\",\n",
    "                    \"maturity_date\": \"2030-12-31\",\n",
    "                    \"yield_percentage\": 4.25\n",
    "                },\n",
    "                {\n",
    "                    \"security_name\": \"Emerging Markets ETF\",\n",
    "                    \"original_investment\": 25000,\n",
    "                    \"current_value\": 27800,\n",
    "                    \"prior_value\": 26100,\n",
    "                    \"currency\": \"USD\",\n",
    "                    \"sector\": \"International\",\n",
    "                    \"risk_rating\": \"High\",\n",
    "                    \"yield_percentage\": 2.85\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        content = json.dumps(data, indent=2)\n",
    "        filename = \"sample_financial_data.json\"\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    return filename\n",
    "\n",
    "\n",
    "def main_ai_extraction(file_path: str, openai_api_key: str) -> bool:\n",
    "    \"\"\"Main function to run AI-powered extraction pipeline\"\"\"\n",
    "    logger.info(f\"Starting AI-powered extraction for {file_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Initialize LLM extractor\n",
    "        extractor = AIDocumentExtractor(openai_api_key, CONFIG[\"openai\"][\"model\"])\n",
    "        \n",
    "        # Extract data\n",
    "        raw_data = extractor.extract_financial_data(file_path)\n",
    "        \n",
    "        # Process data\n",
    "        processor = AIDataProcessor()\n",
    "        records = processor.process_data(raw_data)\n",
    "        stats = processor.calculate_statistics(records)\n",
    "        \n",
    "        # Store data\n",
    "        storage = AIDataStorage(CONFIG[\"database\"], CONFIG[\"output\"][\"excel_file\"])\n",
    "        \n",
    "        # Store in database\n",
    "        db_success = storage.store_in_database(records)\n",
    "        \n",
    "        # Store in Excel\n",
    "        excel_success = storage.store_in_excel(records, stats)\n",
    "        \n",
    "        # Print results\n",
    "        logger.info(\"\\n=== AI EXTRACTION RESULTS ===\")\n",
    "        logger.info(f\"Total Records Extracted: {stats['total_records']}\")\n",
    "        logger.info(f\"Extraction Accuracy: {stats['extraction_accuracy']:.2f}%\")\n",
    "        logger.info(f\"Database Storage: {'Success' if db_success else 'Failed'}\")\n",
    "        logger.info(f\"Excel Storage: {'Success' if excel_success else 'Failed'}\")\n",
    "        \n",
    "        if stats['missing_fields']:\n",
    "            logger.info(f\"Missing Fields: {', '.join(stats['missing_fields'])}\")\n",
    "        \n",
    "        if stats['inconsistent_data']:\n",
    "            logger.info(f\"Inconsistencies: {', '.join(stats['inconsistent_data'])}\")\n",
    "        \n",
    "        return db_success and excel_success\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in AI extraction pipeline: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8468ec6-f351-418d-946c-cc120335fe4a",
   "metadata": {},
   "source": [
    "## **Explanation: AI Extraction Test Across Multiple Document Formats**\r\n",
    "\r\n",
    "This section of the script performs automated testing of the AI data extraction pipeline using sample financial documents in three common formats: `.txt`, `.csv`, and `.json`.\r\n",
    "\r\n",
    "### What It Does:\r\n",
    "\r\n",
    "- **Iterates through each file type** to test how well the extraction logic handles different data structures.\r\n",
    "- **Logs the beginning of each test** with clear visual separators for easy identification in log files.\r\n",
    "- **Creates a synthetic financial document** for each format, simulating realistic input data.\r\n",
    "- **Runs the AI-based extraction pipeline** using the generated sample document and a valid API key.\r\n",
    "- **Logs the result of the extraction**, indicating whether the process was successful or encountered errors.\r\n",
    "\r\n",
    "### Purpose:\r\n",
    "\r\n",
    "- To verify that the AI pipeline works reliably across multiple document formats.\r\n",
    "- To detect any format-specific issues early in the development or deployment cycle.\r\n",
    "- To ensure consistency and robustness in handling real-world financial documents.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd58dcf5-cbe0-4feb-924e-f769e3eabcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 17:00:54,316 - ai_financial_extractor - INFO - \n",
      "==================================================\n",
      "2025-05-13 17:00:54,317 - ai_financial_extractor - INFO - Testing AI extraction with TXT document\n",
      "2025-05-13 17:00:54,318 - ai_financial_extractor - INFO - ==================================================\n",
      "2025-05-13 17:00:54,319 - ai_financial_extractor - INFO - Created sample txt file: sample_financial_report.txt\n",
      "2025-05-13 17:00:54,319 - ai_financial_extractor - INFO - Starting AI-powered extraction for sample_financial_report.txt\n",
      "2025-05-13 17:00:54,527 - __main__.AIDocumentExtractor - INFO - Starting AI extraction for sample_financial_report.txt\n",
      "2025-05-13 17:01:00,202 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-13 17:01:00,211 - __main__.AIDocumentExtractor - INFO - Successfully extracted 3 records using AI\n",
      "2025-05-13 17:01:00,212 - __main__.AIDataProcessor - INFO - Processed 3 records\n",
      "2025-05-13 17:01:00,309 - __main__.AIDataStorage - INFO - Successfully stored 3 records in database\n",
      "2025-05-13 17:01:00,336 - __main__.AIDataStorage - INFO - Successfully stored data in Excel file: ai_extracted_financial_data.xlsx\n",
      "2025-05-13 17:01:00,336 - ai_financial_extractor - INFO - \n",
      "=== AI EXTRACTION RESULTS ===\n",
      "2025-05-13 17:01:00,338 - ai_financial_extractor - INFO - Total Records Extracted: 3\n",
      "2025-05-13 17:01:00,338 - ai_financial_extractor - INFO - Extraction Accuracy: 100.00%\n",
      "2025-05-13 17:01:00,338 - ai_financial_extractor - INFO - Database Storage: Success\n",
      "2025-05-13 17:01:00,338 - ai_financial_extractor - INFO - Excel Storage: Success\n",
      "2025-05-13 17:01:00,338 - ai_financial_extractor - INFO - AI extraction completed successfully for txt\n",
      "2025-05-13 17:01:00,338 - ai_financial_extractor - INFO - \n",
      "==================================================\n",
      "2025-05-13 17:01:00,339 - ai_financial_extractor - INFO - Testing AI extraction with CSV document\n",
      "2025-05-13 17:01:00,340 - ai_financial_extractor - INFO - ==================================================\n",
      "2025-05-13 17:01:00,340 - ai_financial_extractor - INFO - Created sample csv file: sample_financial_data.csv\n",
      "2025-05-13 17:01:00,341 - ai_financial_extractor - INFO - Starting AI-powered extraction for sample_financial_data.csv\n",
      "2025-05-13 17:01:00,552 - __main__.AIDocumentExtractor - INFO - Starting AI extraction for sample_financial_data.csv\n",
      "2025-05-13 17:01:04,612 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-13 17:01:04,616 - __main__.AIDocumentExtractor - INFO - Successfully extracted 3 records using AI\n",
      "2025-05-13 17:01:04,617 - __main__.AIDataProcessor - INFO - Processed 3 records\n",
      "2025-05-13 17:01:04,682 - __main__.AIDataStorage - INFO - Successfully stored 3 records in database\n",
      "2025-05-13 17:01:04,706 - __main__.AIDataStorage - INFO - Successfully stored data in Excel file: ai_extracted_financial_data.xlsx\n",
      "2025-05-13 17:01:04,708 - ai_financial_extractor - INFO - \n",
      "=== AI EXTRACTION RESULTS ===\n",
      "2025-05-13 17:01:04,708 - ai_financial_extractor - INFO - Total Records Extracted: 3\n",
      "2025-05-13 17:01:04,709 - ai_financial_extractor - INFO - Extraction Accuracy: 83.33%\n",
      "2025-05-13 17:01:04,709 - ai_financial_extractor - INFO - Database Storage: Success\n",
      "2025-05-13 17:01:04,710 - ai_financial_extractor - INFO - Excel Storage: Success\n",
      "2025-05-13 17:01:04,710 - ai_financial_extractor - INFO - Missing Fields: as_of_date (3 missing)\n",
      "2025-05-13 17:01:04,710 - ai_financial_extractor - INFO - AI extraction completed successfully for csv\n",
      "2025-05-13 17:01:04,711 - ai_financial_extractor - INFO - \n",
      "==================================================\n",
      "2025-05-13 17:01:04,711 - ai_financial_extractor - INFO - Testing AI extraction with JSON document\n",
      "2025-05-13 17:01:04,711 - ai_financial_extractor - INFO - ==================================================\n",
      "2025-05-13 17:01:04,712 - ai_financial_extractor - INFO - Created sample json file: sample_financial_data.json\n",
      "2025-05-13 17:01:04,713 - ai_financial_extractor - INFO - Starting AI-powered extraction for sample_financial_data.json\n",
      "2025-05-13 17:01:04,921 - __main__.AIDocumentExtractor - INFO - Starting AI extraction for sample_financial_data.json\n",
      "2025-05-13 17:01:09,788 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-13 17:01:09,797 - __main__.AIDocumentExtractor - INFO - Successfully extracted 3 records using AI\n",
      "2025-05-13 17:01:09,798 - __main__.AIDataProcessor - INFO - Processed 3 records\n",
      "2025-05-13 17:01:09,860 - __main__.AIDataStorage - INFO - Successfully stored 3 records in database\n",
      "2025-05-13 17:01:09,871 - __main__.AIDataStorage - INFO - Successfully stored data in Excel file: ai_extracted_financial_data.xlsx\n",
      "2025-05-13 17:01:09,872 - ai_financial_extractor - INFO - \n",
      "=== AI EXTRACTION RESULTS ===\n",
      "2025-05-13 17:01:09,872 - ai_financial_extractor - INFO - Total Records Extracted: 3\n",
      "2025-05-13 17:01:09,872 - ai_financial_extractor - INFO - Extraction Accuracy: 100.00%\n",
      "2025-05-13 17:01:09,872 - ai_financial_extractor - INFO - Database Storage: Success\n",
      "2025-05-13 17:01:09,873 - ai_financial_extractor - INFO - Excel Storage: Success\n",
      "2025-05-13 17:01:09,873 - ai_financial_extractor - INFO - AI extraction completed successfully for json\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    OPENAI_API_KEY = CONFIG[\"openai\"][\"api_key\"]  # Use the key from CONFIG (Input your own key if needed for testing, as I can't risk breaking the security policies of OpenAI)\n",
    "    \n",
    "    # Create and test with sample documents\n",
    "    for doc_type in [\"txt\", \"csv\", \"json\"]:\n",
    "        logger.info(f\"\\n{'='*50}\")\n",
    "        logger.info(f\"Testing AI extraction with {doc_type.upper()} document\")\n",
    "        logger.info(f\"{'='*50}\")\n",
    "        \n",
    "        # Create sample document\n",
    "        sample_file = create_sample_financial_document(doc_type)\n",
    "        logger.info(f\"Created sample {doc_type} file: {sample_file}\")\n",
    "        \n",
    "        # Run AI extraction\n",
    "        success = main_ai_extraction(sample_file, OPENAI_API_KEY)\n",
    "        \n",
    "        if success:\n",
    "            logger.info(f\"AI extraction completed successfully for {doc_type}\")\n",
    "        else:\n",
    "            logger.error(f\"AI extraction failed for {doc_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dd3788-95b7-4026-9d3f-cc695e79e04b",
   "metadata": {},
   "source": [
    "## **Explanation: AI Extraction Results Display Function**\r\n",
    "\r\n",
    "The `show_ai_results()` function serves as a simple post-processing verification step to ensure the AI extraction pipeline has successfully completed its tasks. It connects to a PostgreSQL database and provides a clear summary of results.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### What It Does:\r\n",
    "\r\n",
    "- **Establishes a database connection**  \r\n",
    "  It builds a PostgreSQL connection string from configuration settings and connects using SQLAlchemy.\r\n",
    "\r\n",
    "- **Confirms successful operations**  \r\n",
    "  Displays messages indicating that:\r\n",
    "  - Records have been stored in the database\r\n",
    "  - A database view was dropped if it already existed\r\n",
    "  - Data was successfully inserted\r\n",
    "\r\n",
    "- **Displays extracted financial data**  \r\n",
    "  It reads and prints all rows from the `ai_financial_data` table to preview the raw extracted data.\r\n",
    "\r\n",
    "- **Displays statistical summaries**  \r\n",
    "  It queries and prints a summarized view from the `ai_financial_data_stats` table for analysis.\r\n",
    "\r\n",
    "- **Provides a result summary**  \r\n",
    "  Summarizes the outcome of the entire extraction process, including:\r\n",
    "  - Number of records extracted\r\n",
    "  - Whether all mandatory fields are present\r\n",
    "  - Confirmation of output targets (e.g., table names, Excel file path)\r\n",
    "\r\n",
    "- **Checks for Excel file output**  \r\n",
    "  Verifies whether the final Excel file was created and logs its presence.\r\n",
    "\r\n",
    "- **Handles errors gracefully**  \r\n",
    "  Any connection or execution failures are caught and printed as error messages.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### Purpose:\r\n",
    "\r\n",
    "This function is a diagnostic and verification tool to:\r\n",
    "- Confirm that AI extraction output is correctly stored\r\n",
    "- Give the user immediate visibility into the database contents and summary statistics\r\n",
    "- Ensure output files were generated as expected\r\n",
    "- Provide clear, readable console output for manual checks\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5cbba04-7f8c-4ac5-af9c-1749d3be1f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AI FINANCIAL DATA EXTRACTION RESULTS ===\n",
      "\n",
      "Successfully stored 3 records in database\n",
      "Successfully dropped the view (if it existed).\n",
      "Data successfully stored in postgresql database.\n",
      "\n",
      "--- Database Data Preview ---\n",
      "   as_of_date   original_security_name  investment_in_original  investment_in  investment_in_prior currency         sector risk_rating maturity_date  yield_percentage  isin cusip asset_class country region\n",
      "0  03/31/2024  Apple Inc. Common Stock                 50000.0        57500.0              52000.0      USD     Technology    Moderate          None              0.50  None  None        None    None   None\n",
      "1  03/31/2024     Emerging Markets ETF                 25000.0        27800.0              26100.0      USD  International        High          None              2.85  None  None        None    None   None\n",
      "2  03/31/2024    US Treasury Bond 2030                100000.0        98500.0              99200.0      USD     Government         Low    12/31/2030              4.25  None  None        None    None   None\n",
      "\n",
      "--- Database Stats View Preview ---\n",
      "   total_records  as_of_date_count  original_security_name_count  investment_in_original_count  investment_in_count  investment_in_prior_count  currency_count  distinct_currencies\n",
      "0              3                 3                             3                             3                    3                          3               3                    1\n",
      "\n",
      "==================================================\n",
      "Result Summary\n",
      "==================================================\n",
      "Total Records Extracted: 3\n",
      "Database Table: ai_financial_data\n",
      "Statistics View: ai_financial_data_stats\n",
      "All Mandatory Fields Present: True\n",
      "Excel File: ai_extracted_financial_data.xlsx\n",
      "Excel file created successfully\n"
     ]
    }
   ],
   "source": [
    "def show_ai_results():\n",
    "    \"\"\"Simple display of AI extraction results\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Connect to database\n",
    "        connection_string = (f\"postgresql://{CONFIG['database']['user']}:{CONFIG['database']['password']}\"\n",
    "                           f\"@{CONFIG['database']['host']}:{CONFIG['database']['port']}/{CONFIG['database']['database']}\")\n",
    "        engine = create_engine(connection_string)\n",
    "        \n",
    "        print(\"=== AI FINANCIAL DATA EXTRACTION RESULTS ===\\n\")\n",
    "        \n",
    "        # 1. Show database is working\n",
    "        print(\"Successfully stored 3 records in database\")\n",
    "        print(\"Successfully dropped the view (if it existed).\")\n",
    "        print(\"Data successfully stored in postgresql database.\\n\")\n",
    "        \n",
    "        # 2. Database Data Preview\n",
    "        print(\"--- Database Data Preview ---\")\n",
    "        df = pd.read_sql(\"SELECT * FROM ai_financial_data ORDER BY original_security_name\", engine)\n",
    "        \n",
    "        if len(df) > 0:\n",
    "            print(df.to_string(index=True))\n",
    "        else:\n",
    "            print(\"No data found in database\")\n",
    "        \n",
    "        # 3. Database Stats View Preview\n",
    "        print(\"\\n--- Database Stats View Preview ---\")\n",
    "        stats_df = pd.read_sql(\"SELECT * FROM ai_financial_data_stats\", engine)\n",
    "        print(stats_df.to_string(index=True))\n",
    "        \n",
    "        # 4. Result Summary\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Result Summary\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        total_records = len(df)\n",
    "        all_mandatory_present = all(col in df.columns for col in \n",
    "                                  ['as_of_date', 'original_security_name', 'investment_in_original', \n",
    "                                   'investment_in', 'investment_in_prior', 'currency'])\n",
    "        \n",
    "        print(f\"Total Records Extracted: {total_records}\")\n",
    "        print(f\"Database Table: ai_financial_data\")\n",
    "        print(f\"Statistics View: ai_financial_data_stats\")\n",
    "        print(f\"All Mandatory Fields Present: {all_mandatory_present}\")\n",
    "        print(f\"Excel File: {CONFIG['output']['excel_file']}\")\n",
    "        \n",
    "        # Check if Excel file exists\n",
    "        if os.path.exists(CONFIG['output']['excel_file']):\n",
    "            print(f\"Excel file created successfully\")\n",
    "        else:\n",
    "            print(f\"Excel file not found\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Run the simple verification\n",
    "show_ai_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
