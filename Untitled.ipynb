{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "693562c2-11c6-4608-a867-86a191c52204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import logging\n",
    "from typing import Dict, List, Any, Optional\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass, asdict\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, PatternFill, Alignment\n",
    "from sqlalchemy import create_engine, text\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import docx2txt\n",
    "import PyPDF2\n",
    "from dateutil import parser as date_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "806b1da7-3898-4dcc-a83f-136d025d78cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger('ai_financial_extractor')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb6efe93-3be9-44c2-b789-597eb9ba1d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"database\": {\n",
    "        \"type\": \"postgresql\",\n",
    "        \"host\": \"localhost\",\n",
    "        \"port\": 5432,\n",
    "        \"database\": \"financial_data\",\n",
    "        \"user\": \"postgres\",\n",
    "        \"password\": \"SenkoSQL\"\n",
    "    },\n",
    "    \"openai\": {\n",
    "        \"api_key\": \"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\",\n",
    "        \"model\": \"gpt-4o\", \n",
    "        \"temperature\": 0.1  \n",
    "    },\n",
    "    \"output\": {\n",
    "        \"excel_file\": \"ai_extracted_financial_data.xlsx\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8163af80-aedb-4113-8597-14a3ab9beb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FinancialRecord:\n",
    "    \"\"\"Data class representing a financial investment record\"\"\"\n",
    "    as_of_date: Optional[str] = None\n",
    "    original_security_name: Optional[str] = None\n",
    "    investment_in_original: Optional[float] = None\n",
    "    investment_in: Optional[float] = None\n",
    "    investment_in_prior: Optional[float] = None\n",
    "    currency: Optional[str] = None\n",
    "    # Additional fields\n",
    "    sector: Optional[str] = None\n",
    "    risk_rating: Optional[str] = None\n",
    "    maturity_date: Optional[str] = None\n",
    "    yield_percentage: Optional[float] = None\n",
    "    isin: Optional[str] = None\n",
    "    cusip: Optional[str] = None\n",
    "    asset_class: Optional[str] = None\n",
    "    country: Optional[str] = None\n",
    "    region: Optional[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60213c66-c7f2-49f9-8a4f-36031704b25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIDocumentExtractor:\n",
    "    \"\"\"Extract financial data from documents using OpenAI's API\"\"\"\n",
    "    \n",
    "    def __init__(self, openai_api_key: str, model: str = \"gpt-4o\"):\n",
    "        self.client = OpenAI(api_key=openai_api_key)\n",
    "        self.model = model\n",
    "        self.logger = logging.getLogger(f'{__name__}.AIDocumentExtractor')\n",
    "        \n",
    "    def extract_text_from_file(self, file_path: str) -> str:\n",
    "        \"\"\"Extract text from various file formats\"\"\"\n",
    "        file_extension = os.path.splitext(file_path)[1].lower()\n",
    "        \n",
    "        try:\n",
    "            if file_extension == \".docx\":\n",
    "                return docx2txt.process(file_path)\n",
    "            elif file_extension == \".pdf\":\n",
    "                text = \"\"\n",
    "                with open(file_path, \"rb\") as file:\n",
    "                    pdf_reader = PyPDF2.PdfReader(file)\n",
    "                    for page in pdf_reader.pages:\n",
    "                        text += page.extract_text()\n",
    "                return text\n",
    "            elif file_extension == \".txt\":\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as file:\n",
    "                    return file.read()\n",
    "            elif file_extension == \".csv\":\n",
    "                # For CSV, we'll convert to a readable format for the AI\n",
    "                df = pd.read_csv(file_path)\n",
    "                return df.to_string()\n",
    "            elif file_extension == \".json\":\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                    data = json.load(file)\n",
    "                    return json.dumps(data, indent=2)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported file format: {file_extension}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error extracting text from {file_path}: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def extract_financial_data(self, file_path: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Extract financial data using AI\"\"\"\n",
    "        self.logger.info(f\"Starting AI extraction for {file_path}\")\n",
    "        \n",
    "        # Extract text from file\n",
    "        document_text = self.extract_text_from_file(file_path)\n",
    "        \n",
    "        # Create the extraction prompt\n",
    "        prompt = self._create_extraction_prompt(document_text)\n",
    "        \n",
    "        try:\n",
    "            # Call OpenAI API\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an expert financial data analyst specializing in extracting structured data from financial documents.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=CONFIG[\"openai\"][\"temperature\"]\n",
    "            )\n",
    "            \n",
    "            # Parse the response\n",
    "            extracted_data = self._parse_ai_response(response.choices[0].message.content)\n",
    "            \n",
    "            self.logger.info(f\"Successfully extracted {len(extracted_data)} records using AI\")\n",
    "            return extracted_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in AI extraction: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _create_extraction_prompt(self, document_text: str) -> str:\n",
    "        \"\"\"Create a detailed prompt for the AI to extract financial data\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "Please analyze the following financial document and extract all investment records. \n",
    "Return the data as a JSON array where each object represents one investment record.\n",
    "\n",
    "For each record, extract the following fields (if available):\n",
    "- as_of_date: The date when the data was recorded (format as MM/DD/YYYY)\n",
    "- original_security_name: The name of the investment/security\n",
    "- investment_in_original: Original investment amount (as a number, no currency symbols)\n",
    "- investment_in: Current investment value (as a number, no currency symbols)\n",
    "- investment_in_prior: Previous period investment value (as a number, no currency symbols)\n",
    "- currency: Three-letter currency code (e.g., USD, EUR)\n",
    "- sector: Investment sector (e.g., Technology, Government)\n",
    "- risk_rating: Risk level (e.g., Low, Moderate, High)\n",
    "- maturity_date: When the investment matures (format as MM/DD/YYYY)\n",
    "- yield_percentage: Yield or return percentage (as a number without % sign)\n",
    "- isin: ISIN code if available\n",
    "- cusip: CUSIP code if available\n",
    "- asset_class: Type of asset (e.g., Bond, Equity)\n",
    "- country: Country of origin\n",
    "- region: Geographic region\n",
    "\n",
    "IMPORTANT RULES:\n",
    "1. Only include fields that are actually present in the document\n",
    "2. Convert all dates to MM/DD/YYYY format\n",
    "3. Extract numeric values without currency symbols or commas\n",
    "4. If a field is not found, omit it from the record\n",
    "5. Look for variations in field names (e.g., \"Market Value\" might mean \"investment_in\")\n",
    "6. Return valid JSON only, no additional text\n",
    "\n",
    "Document to analyze:\n",
    "\n",
    "{document_text}\n",
    "\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def _parse_ai_response(self, response_text: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Parse the AI response into structured data\"\"\"\n",
    "        try:\n",
    "            # Clean the response text to extract JSON\n",
    "            json_start = response_text.find('[')\n",
    "            json_end = response_text.rfind(']') + 1\n",
    "            json_text = response_text[json_start:json_end]\n",
    "            \n",
    "            # Parse JSON\n",
    "            extracted_data = json.loads(json_text)\n",
    "            \n",
    "            # Validate and clean the data\n",
    "            cleaned_data = []\n",
    "            for record in extracted_data:\n",
    "                cleaned_record = self._clean_record(record)\n",
    "                if cleaned_record:\n",
    "                    cleaned_data.append(cleaned_record)\n",
    "            \n",
    "            return cleaned_data\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            self.logger.error(f\"Error parsing AI response as JSON: {str(e)}\")\n",
    "            self.logger.debug(f\"Raw response: {response_text}\")\n",
    "            # Attempt to extract JSON using regex as fallback\n",
    "            return self._extract_json_fallback(response_text)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing AI response: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _extract_json_fallback(self, text: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Fallback method to extract JSON from response\"\"\"\n",
    "        try:\n",
    "            # Try to find JSON objects in the text\n",
    "            json_objects = re.findall(r'\\{[^{}]*\\}', text)\n",
    "            results = []\n",
    "            for obj_str in json_objects:\n",
    "                try:\n",
    "                    obj = json.loads(obj_str)\n",
    "                    results.append(obj)\n",
    "                except:\n",
    "                    continue\n",
    "            return results if results else []\n",
    "        except:\n",
    "            return []\n",
    "    \n",
    "    def _clean_record(self, record: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Clean and validate a single record\"\"\"\n",
    "        cleaned = {}\n",
    "        \n",
    "        # Map of field conversions\n",
    "        field_mapping = {\n",
    "            'security_name': 'original_security_name',\n",
    "            'instrument_name': 'original_security_name',\n",
    "            'asset_name': 'original_security_name',\n",
    "            'original_investment': 'investment_in_original',\n",
    "            'initial_investment': 'investment_in_original',\n",
    "            'market_value': 'investment_in',\n",
    "            'current_value': 'investment_in',\n",
    "            'previous_value': 'investment_in_prior',\n",
    "            'prior_value': 'investment_in_prior',\n",
    "            'yield': 'yield_percentage',\n",
    "            'yield_rate': 'yield_percentage',\n",
    "            'currency_code': 'currency',\n",
    "            'risk_level': 'risk_rating'\n",
    "        }\n",
    "        \n",
    "        # Clean and map fields\n",
    "        for key, value in record.items():\n",
    "            # Normalize key name\n",
    "            clean_key = field_mapping.get(key.lower(), key.lower())\n",
    "            \n",
    "            # Clean and convert values\n",
    "            if value is not None and value != \"\":\n",
    "                if clean_key in ['investment_in_original', 'investment_in', 'investment_in_prior', 'yield_percentage']:\n",
    "                    # Convert to float, removing any non-numeric characters except decimal point\n",
    "                    try:\n",
    "                        cleaned_value = re.sub(r'[^\\d.-]', '', str(value))\n",
    "                        cleaned[clean_key] = float(cleaned_value) if cleaned_value else None\n",
    "                    except:\n",
    "                        cleaned[clean_key] = None\n",
    "                elif clean_key in ['as_of_date', 'maturity_date']:\n",
    "                    # Format dates\n",
    "                    try:\n",
    "                        if isinstance(value, str) and value.lower() not in ['n/a', 'na', 'none']:\n",
    "                            date_obj = date_parser.parse(value, fuzzy=True)\n",
    "                            cleaned[clean_key] = date_obj.strftime('%m/%d/%Y')\n",
    "                        else:\n",
    "                            cleaned[clean_key] = value\n",
    "                    except:\n",
    "                        cleaned[clean_key] = value\n",
    "                else:\n",
    "                    cleaned[clean_key] = str(value).strip()\n",
    "        \n",
    "        # Only return records with at least one meaningful field\n",
    "        return cleaned if len(cleaned) > 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "933fab31-c107-4760-a93c-4c2222e2417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIDataProcessor:\n",
    "    \"\"\"Process and validate AI-extracted data\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(f'{__name__}.AIDataProcessor')\n",
    "        self.mandatory_fields = [\n",
    "            'as_of_date', 'original_security_name', 'investment_in_original',\n",
    "            'investment_in', 'investment_in_prior', 'currency'\n",
    "        ]\n",
    "    \n",
    "    def process_data(self, raw_data: List[Dict[str, Any]]) -> List[FinancialRecord]:\n",
    "        \"\"\"Convert raw data to FinancialRecord objects\"\"\"\n",
    "        records = []\n",
    "        \n",
    "        for item in raw_data:\n",
    "            try:\n",
    "                # Convert to FinancialRecord\n",
    "                record = FinancialRecord(**item)\n",
    "                records.append(record)\n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"Error creating record from {item}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        self.logger.info(f\"Processed {len(records)} records\")\n",
    "        return records\n",
    "    \n",
    "    def calculate_statistics(self, records: List[FinancialRecord]) -> Dict[str, Any]:\n",
    "        \"\"\"Calculate extraction statistics\"\"\"\n",
    "        total_records = len(records)\n",
    "        if total_records == 0:\n",
    "            return {\n",
    "                'total_records': 0,\n",
    "                'extraction_accuracy': 0,\n",
    "                'mandatory_field_completeness': {},\n",
    "                'field_presence': {},\n",
    "                'missing_fields': [],\n",
    "                'inconsistent_data': []\n",
    "            }\n",
    "        \n",
    "        # Count field presence\n",
    "        field_counts = {}\n",
    "        for record in records:\n",
    "            record_dict = asdict(record)\n",
    "            for field, value in record_dict.items():\n",
    "                if value is not None:\n",
    "                    field_counts[field] = field_counts.get(field, 0) + 1\n",
    "        \n",
    "        # Calculate mandatory field completeness\n",
    "        mandatory_completeness = {}\n",
    "        missing_fields = []\n",
    "        for field in self.mandatory_fields:\n",
    "            count = field_counts.get(field, 0)\n",
    "            percentage = (count / total_records) * 100\n",
    "            mandatory_completeness[field] = {\n",
    "                'count': count,\n",
    "                'percentage': percentage\n",
    "            }\n",
    "            if count < total_records:\n",
    "                missing_fields.append(f\"{field} ({total_records - count} missing)\")\n",
    "        \n",
    "        # Check for inconsistencies\n",
    "        inconsistencies = []\n",
    "        currencies = set()\n",
    "        date_formats = set()\n",
    "        \n",
    "        for record in records:\n",
    "            if record.currency:\n",
    "                currencies.add(record.currency)\n",
    "            if record.as_of_date:\n",
    "                date_formats.add(self._identify_date_format(record.as_of_date))\n",
    "        \n",
    "        if len(currencies) > 1:\n",
    "            inconsistencies.append(f\"Multiple currencies: {', '.join(currencies)}\")\n",
    "        if len(date_formats) > 1:\n",
    "            inconsistencies.append(f\"Multiple date formats: {', '.join(date_formats)}\")\n",
    "        \n",
    "        # Calculate overall accuracy\n",
    "        total_mandatory_fields = len(self.mandatory_fields) * total_records\n",
    "        filled_mandatory_fields = sum(counts['count'] for counts in mandatory_completeness.values())\n",
    "        accuracy = (filled_mandatory_fields / total_mandatory_fields) * 100 if total_mandatory_fields > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'total_records': total_records,\n",
    "            'extraction_accuracy': accuracy,\n",
    "            'mandatory_field_completeness': mandatory_completeness,\n",
    "            'field_presence': field_counts,\n",
    "            'missing_fields': missing_fields,\n",
    "            'inconsistent_data': inconsistencies\n",
    "        }\n",
    "    \n",
    "    def _identify_date_format(self, date_str: str) -> str:\n",
    "        \"\"\"Identify the format of a date string\"\"\"\n",
    "        if re.match(r'\\d{1,2}/\\d{1,2}/\\d{4}', date_str):\n",
    "            return \"MM/DD/YYYY\"\n",
    "        elif re.match(r'\\d{4}-\\d{1,2}-\\d{1,2}', date_str):\n",
    "            return \"YYYY-MM-DD\"\n",
    "        elif re.match(r'[A-Za-z]+ \\d{1,2},?\\s+\\d{4}', date_str):\n",
    "            return \"Month DD, YYYY\"\n",
    "        return \"Unknown format\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9f2451d-ef50-47b0-ad96-39ab21319b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIDataStorage:\n",
    "    \"\"\"Store processed data in database and Excel\"\"\"\n",
    "    \n",
    "    def __init__(self, db_config: Dict[str, Any], excel_file: str):\n",
    "        self.db_config = db_config\n",
    "        self.excel_file = excel_file\n",
    "        self.logger = logging.getLogger(f'{__name__}.AIDataStorage')\n",
    "    \n",
    "    def store_in_database(self, records: List[FinancialRecord]) -> bool:\n",
    "        \"\"\"Store records in PostgreSQL database\"\"\"\n",
    "        try:\n",
    "            # Convert records to DataFrame\n",
    "            df = pd.DataFrame([asdict(record) for record in records])\n",
    "            \n",
    "            # Create database connection\n",
    "            connection_string = (f\"postgresql://{self.db_config['user']}:{self.db_config['password']}\"\n",
    "                               f\"@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}\")\n",
    "            engine = create_engine(connection_string)\n",
    "            \n",
    "            # Drop existing table/view\n",
    "            with engine.connect() as connection:\n",
    "                connection.execute(text(\"DROP VIEW IF EXISTS ai_financial_data_stats CASCADE;\"))\n",
    "                connection.execute(text(\"DROP TABLE IF EXISTS ai_financial_data CASCADE;\"))\n",
    "                connection.commit()\n",
    "            \n",
    "            # Store data\n",
    "            df.to_sql('ai_financial_data', engine, if_exists='replace', index=False)\n",
    "            \n",
    "            # Create statistics view\n",
    "            self._create_stats_view(engine)\n",
    "            \n",
    "            self.logger.info(f\"Successfully stored {len(records)} records in database\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Database storage error: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def _create_stats_view(self, engine):\n",
    "        \"\"\"Create database view with statistics\"\"\"\n",
    "        view_sql = \"\"\"\n",
    "        CREATE OR REPLACE VIEW ai_financial_data_stats AS\n",
    "        SELECT\n",
    "            COUNT(*) AS total_records,\n",
    "            SUM(CASE WHEN as_of_date IS NOT NULL THEN 1 ELSE 0 END) AS as_of_date_count,\n",
    "            SUM(CASE WHEN original_security_name IS NOT NULL THEN 1 ELSE 0 END) AS original_security_name_count,\n",
    "            SUM(CASE WHEN investment_in_original IS NOT NULL THEN 1 ELSE 0 END) AS investment_in_original_count,\n",
    "            SUM(CASE WHEN investment_in IS NOT NULL THEN 1 ELSE 0 END) AS investment_in_count,\n",
    "            SUM(CASE WHEN investment_in_prior IS NOT NULL THEN 1 ELSE 0 END) AS investment_in_prior_count,\n",
    "            SUM(CASE WHEN currency IS NOT NULL THEN 1 ELSE 0 END) AS currency_count,\n",
    "            COUNT(DISTINCT currency) AS distinct_currencies\n",
    "        FROM ai_financial_data;\n",
    "        \"\"\"\n",
    "        \n",
    "        with engine.connect() as connection:\n",
    "            connection.execute(text(view_sql))\n",
    "            connection.commit()\n",
    "    \n",
    "    def store_in_excel(self, records: List[FinancialRecord], stats: Dict[str, Any]) -> bool:\n",
    "        \"\"\"Store records and statistics in Excel file\"\"\"\n",
    "        try:\n",
    "            # Convert records to DataFrame\n",
    "            df = pd.DataFrame([asdict(record) for record in records])\n",
    "            \n",
    "            # Create Excel writer\n",
    "            with pd.ExcelWriter(self.excel_file, engine='openpyxl') as writer:\n",
    "                # Write data sheet\n",
    "                df.to_excel(writer, sheet_name='Extracted Data', index=False)\n",
    "                \n",
    "                # Create statistics DataFrame\n",
    "                stats_data = {\n",
    "                    'Metric': [\n",
    "                        'Total Records',\n",
    "                        'Overall Extraction Accuracy (%)',\n",
    "                        'Missing Fields',\n",
    "                        'Inconsistent Data'\n",
    "                    ],\n",
    "                    'Value': [\n",
    "                        stats['total_records'],\n",
    "                        f\"{stats['extraction_accuracy']:.2f}%\",\n",
    "                        ', '.join(stats['missing_fields']) if stats['missing_fields'] else 'None',\n",
    "                        ', '.join(stats['inconsistent_data']) if stats['inconsistent_data'] else 'None'\n",
    "                    ]\n",
    "                }\n",
    "                \n",
    "                # Add mandatory field completeness\n",
    "                for field, completeness in stats['mandatory_field_completeness'].items():\n",
    "                    stats_data['Metric'].append(f'{field} completeness')\n",
    "                    stats_data['Value'].append(f\"{completeness['count']}/{stats['total_records']} ({completeness['percentage']:.1f}%)\")\n",
    "                \n",
    "                stats_df = pd.DataFrame(stats_data)\n",
    "                stats_df.to_excel(writer, sheet_name='Statistics', index=False)\n",
    "                \n",
    "                # Apply formatting\n",
    "                self._format_excel(writer)\n",
    "            \n",
    "            self.logger.info(f\"Successfully stored data in Excel file: {self.excel_file}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Excel storage error: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def _format_excel(self, writer):\n",
    "        \"\"\"Apply formatting to Excel file\"\"\"\n",
    "        workbook = writer.book\n",
    "        \n",
    "        # Format data sheet\n",
    "        worksheet = workbook['Extracted Data']\n",
    "        for cell in worksheet[1]:\n",
    "            cell.font = Font(bold=True)\n",
    "            cell.fill = PatternFill(start_color=\"DDDDDD\", end_color=\"DDDDDD\", fill_type=\"solid\")\n",
    "            cell.alignment = Alignment(horizontal='center')\n",
    "        \n",
    "        # Format statistics sheet\n",
    "        worksheet = workbook['Statistics']\n",
    "        for cell in worksheet[1]:\n",
    "            cell.font = Font(bold=True)\n",
    "            cell.fill = PatternFill(start_color=\"DDDDDD\", end_color=\"DDDDDD\", fill_type=\"solid\")\n",
    "            cell.alignment = Alignment(horizontal='center')\n",
    "        \n",
    "        # Adjust column widths\n",
    "        for sheet_name in ['Extracted Data', 'Statistics']:\n",
    "            worksheet = workbook[sheet_name]\n",
    "            for column in worksheet.columns:\n",
    "                max_length = 0\n",
    "                column_letter = column[0].column_letter\n",
    "                for cell in column:\n",
    "                    try:\n",
    "                        if len(str(cell.value)) > max_length:\n",
    "                            max_length = len(str(cell.value))\n",
    "                    except:\n",
    "                        pass\n",
    "                worksheet.column_dimensions[column_letter].width = max(max_length + 2, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ac7e1b6-2167-4829-a59b-62788aac66b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_financial_document(doc_type: str = \"txt\") -> str:\n",
    "    \"\"\"Create sample financial documents for testing\"\"\"\n",
    "    if doc_type == \"txt\":\n",
    "        content = \"\"\"Financial Investment Report\n",
    "Date: March 31, 2024\n",
    "\n",
    "PORTFOLIO SUMMARY\n",
    "\n",
    "Investment 1:\n",
    "Security Name: Apple Inc. Common Stock\n",
    "Original Investment: $50,000.00\n",
    "Current Market Value: $57,500.00\n",
    "Prior Quarter Value: $52,000.00\n",
    "Currency: USD\n",
    "Sector: Technology\n",
    "Risk Rating: Moderate\n",
    "Yield: 0.50%\n",
    "\n",
    "Investment 2:\n",
    "Security Name: US Treasury Bond 2030\n",
    "Original Investment: $100,000.00\n",
    "Current Market Value: $98,500.00\n",
    "Prior Quarter Value: $99,200.00\n",
    "Currency: USD\n",
    "Sector: Government\n",
    "Risk Rating: Low\n",
    "Maturity Date: 12/31/2030\n",
    "Yield: 4.25%\n",
    "\n",
    "Investment 3:\n",
    "Security Name: Emerging Markets ETF\n",
    "Original Investment: $25,000.00\n",
    "Current Market Value: $27,800.00\n",
    "Prior Quarter Value: $26,100.00\n",
    "Currency: USD\n",
    "Sector: International\n",
    "Risk Rating: High\n",
    "Yield: 2.85%\n",
    "\"\"\"\n",
    "        filename = \"sample_financial_report.txt\"\n",
    "        \n",
    "    elif doc_type == \"csv\":\n",
    "        content = \"\"\"Security Name,Original Investment,Current Value,Prior Value,Currency,Sector,Risk Rating,Yield %\n",
    "Apple Inc. Common Stock,50000,57500,52000,USD,Technology,Moderate,0.50\n",
    "US Treasury Bond 2030,100000,98500,99200,USD,Government,Low,4.25\n",
    "Emerging Markets ETF,25000,27800,26100,USD,International,High,2.85\n",
    "\"\"\"\n",
    "        filename = \"sample_financial_data.csv\"\n",
    "        \n",
    "    elif doc_type == \"json\":\n",
    "        data = {\n",
    "            \"report_date\": \"2024-03-31\",\n",
    "            \"investments\": [\n",
    "                {\n",
    "                    \"security_name\": \"Apple Inc. Common Stock\",\n",
    "                    \"original_investment\": 50000,\n",
    "                    \"current_value\": 57500,\n",
    "                    \"prior_value\": 52000,\n",
    "                    \"currency\": \"USD\",\n",
    "                    \"sector\": \"Technology\",\n",
    "                    \"risk_rating\": \"Moderate\",\n",
    "                    \"yield_percentage\": 0.50\n",
    "                },\n",
    "                {\n",
    "                    \"security_name\": \"US Treasury Bond 2030\",\n",
    "                    \"original_investment\": 100000,\n",
    "                    \"current_value\": 98500,\n",
    "                    \"prior_value\": 99200,\n",
    "                    \"currency\": \"USD\",\n",
    "                    \"sector\": \"Government\",\n",
    "                    \"risk_rating\": \"Low\",\n",
    "                    \"maturity_date\": \"2030-12-31\",\n",
    "                    \"yield_percentage\": 4.25\n",
    "                },\n",
    "                {\n",
    "                    \"security_name\": \"Emerging Markets ETF\",\n",
    "                    \"original_investment\": 25000,\n",
    "                    \"current_value\": 27800,\n",
    "                    \"prior_value\": 26100,\n",
    "                    \"currency\": \"USD\",\n",
    "                    \"sector\": \"International\",\n",
    "                    \"risk_rating\": \"High\",\n",
    "                    \"yield_percentage\": 2.85\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        content = json.dumps(data, indent=2)\n",
    "        filename = \"sample_financial_data.json\"\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29a8549d-dbc9-4b4e-954d-6b9187137627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_ai_extraction(file_path: str, openai_api_key: str) -> bool:\n",
    "    \"\"\"Main function to run AI-powered extraction pipeline\"\"\"\n",
    "    logger.info(f\"Starting AI-powered extraction for {file_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Initialize AI extractor\n",
    "        extractor = AIDocumentExtractor(openai_api_key, CONFIG[\"openai\"][\"model\"])\n",
    "        \n",
    "        # Extract data using AI\n",
    "        raw_data = extractor.extract_financial_data(file_path)\n",
    "        \n",
    "        # Process data\n",
    "        processor = AIDataProcessor()\n",
    "        records = processor.process_data(raw_data)\n",
    "        stats = processor.calculate_statistics(records)\n",
    "        \n",
    "        # Store data\n",
    "        storage = AIDataStorage(CONFIG[\"database\"], CONFIG[\"output\"][\"excel_file\"])\n",
    "        \n",
    "        # Store in database\n",
    "        db_success = storage.store_in_database(records)\n",
    "        \n",
    "        # Store in Excel\n",
    "        excel_success = storage.store_in_excel(records, stats)\n",
    "        \n",
    "        # Print results\n",
    "        logger.info(\"\\n=== AI EXTRACTION RESULTS ===\")\n",
    "        logger.info(f\"Total Records Extracted: {stats['total_records']}\")\n",
    "        logger.info(f\"Extraction Accuracy: {stats['extraction_accuracy']:.2f}%\")\n",
    "        logger.info(f\"Database Storage: {'Success' if db_success else 'Failed'}\")\n",
    "        logger.info(f\"Excel Storage: {'Success' if excel_success else 'Failed'}\")\n",
    "        \n",
    "        if stats['missing_fields']:\n",
    "            logger.info(f\"Missing Fields: {', '.join(stats['missing_fields'])}\")\n",
    "        \n",
    "        if stats['inconsistent_data']:\n",
    "            logger.info(f\"Inconsistencies: {', '.join(stats['inconsistent_data'])}\")\n",
    "        \n",
    "        return db_success and excel_success\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in AI extraction pipeline: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd58dcf5-cbe0-4feb-924e-f769e3eabcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 15:37:44,727 - ai_financial_extractor - INFO - \n",
      "==================================================\n",
      "2025-05-13 15:37:44,727 - ai_financial_extractor - INFO - Testing AI extraction with TXT document\n",
      "2025-05-13 15:37:44,729 - ai_financial_extractor - INFO - ==================================================\n",
      "2025-05-13 15:37:44,730 - ai_financial_extractor - INFO - Created sample txt file: sample_financial_report.txt\n",
      "2025-05-13 15:37:44,730 - ai_financial_extractor - INFO - Starting AI-powered extraction for sample_financial_report.txt\n",
      "2025-05-13 15:37:44,934 - __main__.AIDocumentExtractor - INFO - Starting AI extraction for sample_financial_report.txt\n",
      "2025-05-13 15:37:48,080 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-13 15:37:48,097 - __main__.AIDocumentExtractor - INFO - Successfully extracted 3 records using AI\n",
      "2025-05-13 15:37:48,098 - __main__.AIDataProcessor - INFO - Processed 3 records\n",
      "2025-05-13 15:37:48,149 - __main__.AIDataStorage - INFO - Successfully stored 3 records in database\n",
      "2025-05-13 15:37:48,161 - __main__.AIDataStorage - INFO - Successfully stored data in Excel file: ai_extracted_financial_data.xlsx\n",
      "2025-05-13 15:37:48,161 - ai_financial_extractor - INFO - \n",
      "=== AI EXTRACTION RESULTS ===\n",
      "2025-05-13 15:37:48,162 - ai_financial_extractor - INFO - Total Records Extracted: 3\n",
      "2025-05-13 15:37:48,162 - ai_financial_extractor - INFO - Extraction Accuracy: 100.00%\n",
      "2025-05-13 15:37:48,163 - ai_financial_extractor - INFO - Database Storage: Success\n",
      "2025-05-13 15:37:48,163 - ai_financial_extractor - INFO - Excel Storage: Success\n",
      "2025-05-13 15:37:48,164 - ai_financial_extractor - INFO - ✅ AI extraction completed successfully for txt\n",
      "2025-05-13 15:37:48,164 - ai_financial_extractor - INFO - \n",
      "==================================================\n",
      "2025-05-13 15:37:48,164 - ai_financial_extractor - INFO - Testing AI extraction with CSV document\n",
      "2025-05-13 15:37:48,165 - ai_financial_extractor - INFO - ==================================================\n",
      "2025-05-13 15:37:48,165 - ai_financial_extractor - INFO - Created sample csv file: sample_financial_data.csv\n",
      "2025-05-13 15:37:48,166 - ai_financial_extractor - INFO - Starting AI-powered extraction for sample_financial_data.csv\n",
      "2025-05-13 15:37:48,380 - __main__.AIDocumentExtractor - INFO - Starting AI extraction for sample_financial_data.csv\n",
      "2025-05-13 15:37:51,540 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-13 15:37:51,541 - __main__.AIDocumentExtractor - INFO - Successfully extracted 3 records using AI\n",
      "2025-05-13 15:37:51,542 - __main__.AIDataProcessor - INFO - Processed 3 records\n",
      "2025-05-13 15:37:51,599 - __main__.AIDataStorage - INFO - Successfully stored 3 records in database\n",
      "2025-05-13 15:37:51,623 - __main__.AIDataStorage - INFO - Successfully stored data in Excel file: ai_extracted_financial_data.xlsx\n",
      "2025-05-13 15:37:51,624 - ai_financial_extractor - INFO - \n",
      "=== AI EXTRACTION RESULTS ===\n",
      "2025-05-13 15:37:51,624 - ai_financial_extractor - INFO - Total Records Extracted: 3\n",
      "2025-05-13 15:37:51,625 - ai_financial_extractor - INFO - Extraction Accuracy: 83.33%\n",
      "2025-05-13 15:37:51,625 - ai_financial_extractor - INFO - Database Storage: Success\n",
      "2025-05-13 15:37:51,625 - ai_financial_extractor - INFO - Excel Storage: Success\n",
      "2025-05-13 15:37:51,626 - ai_financial_extractor - INFO - Missing Fields: as_of_date (3 missing)\n",
      "2025-05-13 15:37:51,626 - ai_financial_extractor - INFO - ✅ AI extraction completed successfully for csv\n",
      "2025-05-13 15:37:51,627 - ai_financial_extractor - INFO - \n",
      "==================================================\n",
      "2025-05-13 15:37:51,628 - ai_financial_extractor - INFO - Testing AI extraction with JSON document\n",
      "2025-05-13 15:37:51,628 - ai_financial_extractor - INFO - ==================================================\n",
      "2025-05-13 15:37:51,629 - ai_financial_extractor - INFO - Created sample json file: sample_financial_data.json\n",
      "2025-05-13 15:37:51,630 - ai_financial_extractor - INFO - Starting AI-powered extraction for sample_financial_data.json\n",
      "2025-05-13 15:37:51,842 - __main__.AIDocumentExtractor - INFO - Starting AI extraction for sample_financial_data.json\n",
      "2025-05-13 15:37:55,712 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-13 15:37:55,713 - __main__.AIDocumentExtractor - INFO - Successfully extracted 3 records using AI\n",
      "2025-05-13 15:37:55,713 - __main__.AIDataProcessor - INFO - Processed 3 records\n",
      "2025-05-13 15:37:55,768 - __main__.AIDataStorage - INFO - Successfully stored 3 records in database\n",
      "2025-05-13 15:37:55,780 - __main__.AIDataStorage - INFO - Successfully stored data in Excel file: ai_extracted_financial_data.xlsx\n",
      "2025-05-13 15:37:55,781 - ai_financial_extractor - INFO - \n",
      "=== AI EXTRACTION RESULTS ===\n",
      "2025-05-13 15:37:55,781 - ai_financial_extractor - INFO - Total Records Extracted: 3\n",
      "2025-05-13 15:37:55,782 - ai_financial_extractor - INFO - Extraction Accuracy: 100.00%\n",
      "2025-05-13 15:37:55,782 - ai_financial_extractor - INFO - Database Storage: Success\n",
      "2025-05-13 15:37:55,783 - ai_financial_extractor - INFO - Excel Storage: Success\n",
      "2025-05-13 15:37:55,783 - ai_financial_extractor - INFO - ✅ AI extraction completed successfully for json\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Set your OpenAI API key here\n",
    "    OPENAI_API_KEY = CONFIG[\"openai\"][\"api_key\"]  # Use the key from CONFIG\n",
    "    \n",
    "    # Create and test with sample documents\n",
    "    for doc_type in [\"txt\", \"csv\", \"json\"]:\n",
    "        logger.info(f\"\\n{'='*50}\")\n",
    "        logger.info(f\"Testing AI extraction with {doc_type.upper()} document\")\n",
    "        logger.info(f\"{'='*50}\")\n",
    "        \n",
    "        # Create sample document\n",
    "        sample_file = create_sample_financial_document(doc_type)\n",
    "        logger.info(f\"Created sample {doc_type} file: {sample_file}\")\n",
    "        \n",
    "        # Run AI extraction\n",
    "        success = main_ai_extraction(sample_file, OPENAI_API_KEY)\n",
    "        \n",
    "        if success:\n",
    "            logger.info(f\"✅ AI extraction completed successfully for {doc_type}\")\n",
    "        else:\n",
    "            logger.error(f\"❌ AI extraction failed for {doc_type}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
